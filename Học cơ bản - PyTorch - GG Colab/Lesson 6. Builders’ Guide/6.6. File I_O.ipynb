{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKTqHzFoQyAIXHQ7eNsl97"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Cho đến giờ, chúng ta đã thảo luận về cách xử lý dữ liệu cũng như cách xây dựng, đào tạo và thử nghiệm các mô hình học sâu. Tuy nhiên, tại một thời điểm nào đó, chúng tôi hy vọng sẽ đủ hài lòng với các mô hình đã học mà chúng tôi sẽ muốn lưu kết quả để sử dụng sau này trong các ngữ cảnh khác nhau (thậm chí có thể đưa ra dự đoán khi triển khai). Ngoài ra, khi chạy một quy trình đào tạo dài, cách tốt nhất là lưu định kỳ các kết quả trung gian (điểm kiểm tra) để đảm bảo rằng chúng tôi không mất giá trị tính toán trong vài ngày nếu chúng tôi vấp phải dây nguồn của máy chủ. Vì vậy, đã đến lúc tìm hiểu cách tải và lưu trữ cả vectơ trọng số riêng lẻ và toàn bộ mô hình. Phần này giải quyết cả hai vấn đề."],"metadata":{"id":"2eaIPVquGGg1"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"I_N_sF-uF7Wf","executionInfo":{"status":"ok","timestamp":1678025253484,"user_tz":-420,"elapsed":5714,"user":{"displayName":"vu tung","userId":"03394210267989276557"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F"]},{"cell_type":"markdown","source":["# 6.6.1. Loading và Saving Tensor\n","\n","Đối với các tenxơ riêng lẻ, chúng ta có thể gọi trực tiếp các hàm `load` và `save` để đọc và ghi chúng tương ứng. Cả hai chức năng đều yêu cầu chúng tôi cung cấp tên và `save` yêu cầu đầu vào là biến được lưu."],"metadata":{"id":"DltXos0YGUfH"}},{"cell_type":"code","source":["x = torch.arange(4)\n","torch.save(x, 'x-file')"],"metadata":{"id":"9HoqInZRGghQ","executionInfo":{"status":"ok","timestamp":1678025313935,"user_tz":-420,"elapsed":331,"user":{"displayName":"vu tung","userId":"03394210267989276557"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Bây giờ chúng ta có thể đọc dữ liệu từ tệp được lưu trữ trở lại bộ nhớ."],"metadata":{"id":"C1zus_-WGlYu"}},{"cell_type":"code","source":["x2 = torch.load('x-file')\n","x2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZQS9f0wGl0G","executionInfo":{"status":"ok","timestamp":1678025335825,"user_tz":-420,"elapsed":3,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"177557e7-4107-47c1-f787-2b776fd44031"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Chúng ta có thể lưu trữ một danh sách các tenxơ và đọc lại chúng vào bộ nhớ."],"metadata":{"id":"VFlgZQ7MGrfn"}},{"cell_type":"code","source":["y = torch.zeros(4)\n","torch.save([x, y],'x-files')\n","x2, y2 = torch.load('x-files')\n","(x2, y2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpV1I8MfGtXV","executionInfo":{"status":"ok","timestamp":1678025350734,"user_tz":-420,"elapsed":3,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"5d80f6f3-a070-45eb-ab96-264f0f30e4e6"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Thậm chí chúng ta có thể viết và đọc một từ điển ánh xạ từ các chuỗi đến các tenxơ. Điều này thuận tiện khi chúng ta muốn đọc hoặc ghi tất cả các trọng số trong một mô hình."],"metadata":{"id":"hTdJkwiBGyLT"}},{"cell_type":"code","source":["mydict = {'x': x, 'y': y}\n","torch.save(mydict, 'mydict')\n","mydict2 = torch.load('mydict')\n","mydict2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTeMhUTqGymj","executionInfo":{"status":"ok","timestamp":1678025373868,"user_tz":-420,"elapsed":3,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"b4b9dd6b-96cc-4953-baec-40d1d378bc8f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# 6.6.2. Loading and Saving thông số mô hình\n","\n","Việc lưu các vectơ trọng số riêng lẻ (hoặc các tenxơ khác) là hữu ích, nhưng sẽ rất tẻ nhạt nếu chúng ta muốn lưu (và sau đó tải) toàn bộ mô hình. Xét cho cùng, chúng ta có thể có hàng trăm nhóm thông số rải rác khắp nơi. Vì lý do này, khung học sâu cung cấp các chức năng tích hợp để tải và lưu toàn bộ mạng. Một chi tiết quan trọng cần lưu ý là điều này lưu các tham số mô hình chứ không phải toàn bộ mô hình. Ví dụ: nếu chúng tôi có MLP 3 lớp, chúng tôi cần chỉ định kiến ​​trúc riêng. Lý do cho điều này là bản thân các mô hình có thể chứa mã tùy ý, do đó chúng không thể được đánh số tự nhiên. Vì vậy, để khôi phục một mô hình, chúng ta cần tạo kiến ​​trúc bằng mã và sau đó tải các tham số từ đĩa. Hãy bắt đầu với MLP quen thuộc của chúng ta."],"metadata":{"id":"x48dyQTYG1DV"}},{"cell_type":"code","source":["class MLP(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.hidden = nn.LazyLinear(256)\n","    self.output = nn.LazyLinear(10)\n","\n","  def forward(self, x):\n","    return self.output(F.relu(self.hidden(x)))\n","\n","net = MLP()\n","X = torch.randn(size=(2,20))\n","Y = net(X)\n","net.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRUFA1pMHBKF","executionInfo":{"status":"ok","timestamp":1678026228701,"user_tz":-420,"elapsed":357,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"b8052bc0-bc87-4e00-90c6-91d0619113aa"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('hidden.weight',\n","              tensor([[-0.0399, -0.2167, -0.1513,  ...,  0.2095, -0.0620,  0.1744],\n","                      [ 0.1475,  0.0790, -0.2067,  ..., -0.2166,  0.0103, -0.1407],\n","                      [ 0.0548,  0.0513,  0.1175,  ..., -0.1218,  0.1777, -0.0839],\n","                      ...,\n","                      [ 0.1123, -0.1863,  0.1180,  ..., -0.2068, -0.0705, -0.1864],\n","                      [ 0.2023,  0.0134, -0.1631,  ...,  0.1258,  0.0777, -0.2234],\n","                      [-0.1739,  0.1357,  0.1811,  ..., -0.1831, -0.0864,  0.1021]])),\n","             ('hidden.bias',\n","              tensor([ 0.1606,  0.0514,  0.1713,  0.0453, -0.1621,  0.0519, -0.1876, -0.1140,\n","                       0.0497,  0.0616, -0.0619,  0.2085,  0.0622,  0.0805,  0.0650,  0.1001,\n","                      -0.1270, -0.0401, -0.0405, -0.1237,  0.0212, -0.0677,  0.0022, -0.1901,\n","                      -0.1643, -0.0652, -0.1665,  0.1109,  0.1602, -0.2090, -0.0933,  0.0628,\n","                       0.1633,  0.1811, -0.1140, -0.1862, -0.0446,  0.0429,  0.1826,  0.1639,\n","                      -0.2141,  0.1335,  0.1958, -0.0750, -0.0279, -0.0030,  0.0771,  0.2150,\n","                       0.2077,  0.1208, -0.0980,  0.0662, -0.2109,  0.0433,  0.0392, -0.0513,\n","                      -0.1885, -0.0669, -0.2065,  0.0028,  0.1118, -0.1081,  0.0423, -0.1783,\n","                       0.1115,  0.2097, -0.1005,  0.0408,  0.2143, -0.0852, -0.2087, -0.1076,\n","                      -0.0521, -0.0559, -0.1465, -0.0652,  0.0540, -0.1982,  0.1679,  0.0625,\n","                      -0.1155, -0.0724, -0.0272, -0.1811,  0.1792, -0.0827, -0.1198, -0.0345,\n","                      -0.0632,  0.1220, -0.1876,  0.2151,  0.0061, -0.2102,  0.1763,  0.1701,\n","                      -0.0628, -0.1077, -0.0521, -0.1340, -0.2104, -0.2094, -0.0618,  0.1624,\n","                       0.1972, -0.0154, -0.1317,  0.1901, -0.1514, -0.1023, -0.1808, -0.1578,\n","                       0.0253, -0.1838, -0.2121,  0.0714, -0.1743,  0.1016,  0.0886,  0.1552,\n","                      -0.1205,  0.1704,  0.1959, -0.1207,  0.1209, -0.1445, -0.1820,  0.0547,\n","                      -0.0036,  0.1565, -0.2177,  0.1571,  0.0574,  0.0780, -0.1989, -0.0371,\n","                      -0.1133,  0.0665, -0.0497,  0.2019, -0.0290,  0.1923, -0.1620, -0.0487,\n","                       0.1625,  0.2000, -0.1094, -0.0756,  0.1810, -0.0983, -0.2093,  0.1510,\n","                       0.1407, -0.0875,  0.1215, -0.0051, -0.1114,  0.0263, -0.0923,  0.1358,\n","                      -0.1367, -0.0547,  0.1679,  0.1579, -0.0879, -0.2229,  0.0716, -0.0892,\n","                       0.1399,  0.1679, -0.0883, -0.1042,  0.1068, -0.0369, -0.0135,  0.0485,\n","                      -0.1552,  0.1924,  0.1275,  0.1875,  0.0656,  0.2074,  0.1917, -0.1122,\n","                       0.1833,  0.0177, -0.1870, -0.1776,  0.0119,  0.1495,  0.0874, -0.0475,\n","                       0.0628,  0.0442,  0.0249,  0.2215, -0.0974, -0.1513,  0.1689,  0.1032,\n","                      -0.0456, -0.0921, -0.1675,  0.0608, -0.0426, -0.1057, -0.1543,  0.1254,\n","                       0.1825,  0.1079, -0.2199, -0.1862, -0.0010,  0.1258, -0.0667,  0.0403,\n","                       0.1911,  0.1745, -0.1602,  0.1782,  0.2224,  0.0142,  0.1805, -0.0525,\n","                      -0.2110, -0.0621, -0.0949, -0.1910, -0.1926, -0.1169,  0.0140,  0.0439,\n","                       0.0239, -0.0746,  0.0508, -0.0838, -0.1783, -0.0071,  0.1724,  0.0573,\n","                      -0.0535, -0.1867,  0.0567, -0.0148,  0.0565, -0.1853, -0.0708,  0.1792,\n","                      -0.1788,  0.0892,  0.1824, -0.1641,  0.1167,  0.0024,  0.0729, -0.0909])),\n","             ('output.weight',\n","              tensor([[-0.0332, -0.0423, -0.0437,  ...,  0.0467, -0.0423, -0.0584],\n","                      [ 0.0003,  0.0254,  0.0369,  ...,  0.0149,  0.0536, -0.0413],\n","                      [-0.0589,  0.0061,  0.0360,  ..., -0.0348,  0.0483, -0.0277],\n","                      ...,\n","                      [-0.0249,  0.0071,  0.0047,  ...,  0.0544, -0.0328,  0.0275],\n","                      [-0.0548,  0.0425, -0.0297,  ...,  0.0367,  0.0289, -0.0029],\n","                      [-0.0067,  0.0247,  0.0623,  ..., -0.0312,  0.0473,  0.0419]])),\n","             ('output.bias',\n","              tensor([-0.0295,  0.0308, -0.0608, -0.0386,  0.0254, -0.0123, -0.0358, -0.0061,\n","                       0.0456, -0.0258]))])"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["Tiếp theo, chúng tôi lưu trữ các tham số của mô hình dưới dạng tệp có tên “mlp.params”."],"metadata":{"id":"2eQfKAwJJsH4"}},{"cell_type":"code","source":["torch.save(net.state_dict(), 'mlp.params')"],"metadata":{"id":"YV3imMf0Jsdh","executionInfo":{"status":"ok","timestamp":1678026231709,"user_tz":-420,"elapsed":2,"user":{"displayName":"vu tung","userId":"03394210267989276557"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["Để khôi phục mô hình, chúng tôi khởi tạo một bản sao của mô hình MLP ban đầu. Thay vì khởi tạo ngẫu nhiên các tham số mô hình, chúng tôi đọc trực tiếp các tham số được lưu trữ trong tệp."],"metadata":{"id":"3LPOAIDVJ01B"}},{"cell_type":"code","source":["clone = MLP()\n","clone.load_state_dict(torch.load('mlp.params'))\n","clone.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clGtio4VJ4g3","executionInfo":{"status":"ok","timestamp":1678026233992,"user_tz":-420,"elapsed":598,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"f9be4d6f-6dad-4028-973d-2cab2b637e02"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLP(\n","  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n","  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["Vì cả hai trường hợp đều có các tham số mô hình giống nhau nên kết quả tính toán của cùng một đầu vào X sẽ giống nhau. Hãy kiểm chứng điều này."],"metadata":{"id":"KEWX8-yPKA7p"}},{"cell_type":"code","source":["Y_clone = clone(X)\n","Y_clone == Y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yUyKRN9jKB9f","executionInfo":{"status":"ok","timestamp":1678026235192,"user_tz":-420,"elapsed":2,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"c3b7e914-013b-4bea-f494-0eb99add88b9"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[True, True, True, True, True, True, True, True, True, True],\n","        [True, True, True, True, True, True, True, True, True, True]])"]},"metadata":{},"execution_count":33}]}]}