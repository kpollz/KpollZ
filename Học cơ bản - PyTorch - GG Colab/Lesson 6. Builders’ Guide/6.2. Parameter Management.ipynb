{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXn4qZz7/MF5cGU++YQYll"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Khi chúng ta đã chọn một kiến ​​​​trúc và đặt siêu tham số của mình, chúng tôi sẽ tiến hành vòng lặp huấn luyện, trong đó mục tiêu của chúng ta là tìm các giá trị tham số giúp giảm thiểu hàm mất mát của chúng ta. Sau khi đào tạo, chúng ta sẽ cần các tham số này để đưa ra dự đoán trong tương lai. Ngoài ra, đôi khi chúng ta muốn trích xuất các tham số để sử dụng lại chúng trong một số ngữ cảnh khác, để lưu mô hình của chúng ta vào đĩa để nó có thể được thực thi trong phần mềm khác hoặc để kiểm tra với hy vọng đạt được hiểu biết khoa học.\n","\n","Hầu hết thời gian, chúng ta sẽ có thể bỏ qua các chi tiết cơ bản về cách khai báo và thao tác các tham số, dựa vào các khung học sâu để thực hiện công việc nặng nhọc. Tuy nhiên, khi chúng ta rời xa các kiến ​​trúc xếp chồng lên nhau với các lớp tiêu chuẩn, đôi khi chúng ta sẽ cần phải đi sâu vào việc khai báo và thao tác các tham số. Trong phần này, chúng ta bao gồm những điều sau đây:\n","- Truy cập các tham số để gỡ lỗi, chẩn đoán và trực quan hóa.\n","- Chia sẻ tham số giữa các thành phần mô hình khác nhau."],"metadata":{"id":"qXiqqxBa3oy9"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"YEaQkgAb2JaA","executionInfo":{"status":"ok","timestamp":1678021560390,"user_tz":-420,"elapsed":6146,"user":{"displayName":"vu tung","userId":"03394210267989276557"}}},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"markdown","source":["Chúng ta bắt đầu bằng cách tập trung vào MLP với một lớp ẩn."],"metadata":{"id":"6bMK2tV54Hea"}},{"cell_type":"code","source":["net = nn.Sequential(nn.LazyLinear(8),\n","                    nn.ReLU(),\n","                    nn.LazyLinear(1))\n","\n","X = torch.rand(size=(2, 4))\n","net(X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ww8CTdF14JGm","executionInfo":{"status":"ok","timestamp":1678021560391,"user_tz":-420,"elapsed":4,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"9cc2f2ee-550c-48bd-ead8-3e730c8217b8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 1])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# 6.2.1. Truy cập thông số\n","\n","Hãy bắt đầu với cách truy cập các tham số từ các mô hình mà bạn đã biết.\n","\n","Khi một mô hình được xác định thông qua class Sequential, trước tiên chúng ta có thể truy cập bất kỳ lớp nào bằng cách lập chỉ mục vào mô hình như thể đó là một danh sách. Các tham số của mỗi lớp được định vị thuận tiện trong thuộc tính của nó.\n","\n","Chúng ta có thể kiểm tra các tham số của lớp được kết nối đầy đủ thứ hai như sau."],"metadata":{"id":"Zd0yDzra4Tp9"}},{"cell_type":"code","source":["net[2].state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5aCkTbq4zsn","executionInfo":{"status":"ok","timestamp":1678021754006,"user_tz":-420,"elapsed":2,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"a9ef2c32-85f7-4cf0-d5b4-29946acd340a"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3220,  0.1359, -0.1583,  0.2529,  0.0986,  0.1812, -0.3453, -0.2230]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Chúng ta có thể thấy rằng lớp được kết nối đầy đủ này chứa hai tham số, tương ứng với trọng số và độ lệch của lớp đó."],"metadata":{"id":"v-iB1dhJ5DDN"}},{"cell_type":"markdown","source":["## 6.2.1.1. Tham số được chọn\n","\n","Lưu ý rằng mỗi tham số được biểu diễn dưới dạng một thể hiện của lớp tham số. Để làm bất cứ điều gì hữu ích với các tham số, trước tiên chúng ta cần truy cập các giá trị số cơ bản. Có nhiều hướng khác nhau để làm điều đó. Một số đơn giản hơn trong khi những cái khác tổng quát hơn. Đoạn mã sau trích xuất độ lệch từ lớp mạng thần kinh thứ hai, lớp này trả về một thể hiện của lớp tham số và tiếp tục truy cập giá trị của tham số đó."],"metadata":{"id":"nBiaNvnl5DuJ"}},{"cell_type":"code","source":["type(net[2].bias), net[2].bias.data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhtGXOmY5NdI","executionInfo":{"status":"ok","timestamp":1678021822627,"user_tz":-420,"elapsed":4,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"26948e6a-af53-49cf-fb7c-64e70bf6094a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.nn.parameter.Parameter, tensor([0.2637]))"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["Tham số là các đối tượng phức tạp, chứa các giá trị, độ dốc và thông tin bổ sung. Đó là lý do tại sao chúng ta cần yêu cầu giá trị một cách rõ ràng.\n","\n","Ngoài giá trị, mỗi tham số còn cho phép chúng ta truy cập vào gradient. Bởi vì chúng ta chưa gọi lan truyền ngược cho mạng này, nên nó đang ở trạng thái ban đầu."],"metadata":{"id":"WiDE4M_L5w5x"}},{"cell_type":"code","source":["net[2].weight.grad == None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8gX9NJb5yiO","executionInfo":{"status":"ok","timestamp":1678021965833,"user_tz":-420,"elapsed":5,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"9e8d8ea1-dcbd-49df-87ba-90786aee97f0"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## 6.2.1.2. Tất cả các tham số\n","\n","Khi chúng ta cần thực hiện các thao tác trên tất cả các tham số, việc truy cập từng tham số có thể trở nên tẻ nhạt. Tình huống có thể trở nên đặc biệt khó sử dụng khi chúng ta làm việc với các mô-đun phức tạp hơn (ví dụ: các mô-đun lồng nhau), vì chúng ta sẽ cần lặp lại toàn bộ cây để trích xuất các tham số của từng mô-đun con. Dưới đây chúng tôi chứng minh việc truy cập các tham số của tất cả các lớp."],"metadata":{"id":"NY53vEG052Ta"}},{"cell_type":"code","source":["[(name, param.shape) for name, param in net.named_parameters()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17PVVHIh59pk","executionInfo":{"status":"ok","timestamp":1678022011876,"user_tz":-420,"elapsed":3,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"4f58d4ae-8bfb-47d7-9709-581904594759"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('0.weight', torch.Size([8, 4])),\n"," ('0.bias', torch.Size([8])),\n"," ('2.weight', torch.Size([1, 8])),\n"," ('2.bias', torch.Size([1]))]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["[(name, param.data) for name, param in net.named_parameters()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyXPxv7g5_I8","executionInfo":{"status":"ok","timestamp":1678022018374,"user_tz":-420,"elapsed":3,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"6a2cdfd4-36ee-4199-89c2-98322c5b88dc"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('0.weight', tensor([[-0.3899, -0.1978, -0.2126,  0.2613],\n","          [ 0.4009,  0.0756, -0.3550,  0.3520],\n","          [-0.1100,  0.4854,  0.0811,  0.1440],\n","          [-0.0711, -0.3631,  0.4948, -0.1113],\n","          [ 0.1633,  0.1130, -0.1368,  0.4097],\n","          [-0.2619,  0.1581, -0.4891, -0.4490],\n","          [-0.2164, -0.1625,  0.3084,  0.2617],\n","          [ 0.4812, -0.0942,  0.2676,  0.3508]])),\n"," ('0.bias',\n","  tensor([ 0.3032, -0.1512, -0.2374, -0.4392,  0.0437,  0.4895, -0.2958,  0.4790])),\n"," ('2.weight',\n","  tensor([[ 0.3220,  0.1359, -0.1583,  0.2529,  0.0986,  0.1812, -0.3453, -0.2230]])),\n"," ('2.bias', tensor([0.2637]))]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# 6.2.2. Tham số ràng buộc\n","\n","Thông thường, chúng ta muốn chia sẻ các tham số trên nhiều lớp. Hãy xem làm thế nào để làm điều này một cách thanh lịch. Trong phần tiếp theo, chúng ta phân bổ một lớp được kết nối đầy đủ và sau đó sử dụng các tham số cụ thể của nó để đặt các tham số của lớp khác. Ở đây chúng ta cần chạy lan truyền về phía trước net(X) trước khi truy cập các tham số."],"metadata":{"id":"tkaB6oz26VxF"}},{"cell_type":"code","source":["shared = nn.LazyLinear(8)\n","net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(),\n","                    shared, nn.ReLU(),\n","                    shared, nn.ReLU(),\n","                    nn.LazyLinear(1))\n","net(X)\n","\n","print(net[2].weight.data[0] == net[4].weight.data[0])\n","net[2].weight.data[0, 0] = 100\n","print(net[2].weight.data[0] == net[4].weight.data[0])\n","\n","\"\"\"\n","###Thắc mắc###\n","  Tạo sao vì các tham số mô hình có chứa độ dốc, \n","nên độ dốc của lớp ẩn thứ hai và lớp ẩn thứ ba được cộng lại với \n","nhau trong quá trình lan truyền ngược.\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cOzkRDr623I","executionInfo":{"status":"ok","timestamp":1678022403560,"user_tz":-420,"elapsed":293,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"43e4684c-f412-47c9-a006-c3e2bc67fcb3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([True, True, True, True, True, True, True, True])\n","tensor([True, True, True, True, True, True, True, True])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]}]},{"cell_type":"markdown","source":["Ví dụ này cho thấy các tham số của lớp thứ hai và thứ ba được gắn với nhau. Chúng không chỉ bằng nhau, chúng được biểu diễn bằng cùng một tensor chính xác. Do đó, nếu chúng ta thay đổi một trong các tham số thì tham số kia cũng thay đổi theo."],"metadata":{"id":"74BauOjb7gMl"}}]}