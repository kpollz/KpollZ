{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1HF28ZrREdAd8LNiSBrjr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Trước khi tìm hiểu chi tiết về mạng nơ-ron sâu, chúng ta cần nắm vững những kiến thức căn bản của việc huấn luyện mạng nơ-ron. Chương này sẽ đề cập đến toàn bộ quá trình huấn luyện, bao gồm xác định kiến trúc mạng nơ-ron đơn giản, xử lý dữ liệu, chỉ rõ hàm mất mát và huấn luyện mô hình. Để mọi thứ dễ dàng hơn, ta sẽ bắt đầu với một số khái niệm đơn giản nhất. May thay, một số phương pháp học thống kê cổ điển như hồi quy tuyến tính, hồi quy logistic có thể được xem như những mạng nơ-ron nông. Hãy bắt đầu bằng những thuật toán cổ điển này, chúng ta sẽ được giới thiệu những nội dung căn bản nhằm tạo nền tảng cho những kỹ thuật phức tạp hơn như Hồi quy Softmax (sẽ được giới thiệu ở cuối chương này) và Perceptron đa tầng (sẽ được giới thiệu ở chương sau)."],"metadata":{"id":"q4Zbt-wsqjVx"}},{"cell_type":"code","source":["!pip install d2l==1.0.0-beta0"],"metadata":{"id":"jS7kdvi79B7B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3.1. Hồi quy Tuyến tính\n","\n","Hồi quy ám chỉ các phương pháp để xây dựng mối quan hệ giữa điểm dữ liệu  **x**  và mục tiêu với giá trị số thực  *y* . Trong khoa học tự nhiên và khoa học xã hội, mục tiêu của hồi quy thường là đặc trưng hóa mối quan hệ của đầu vào và đầu ra. Mặt khác, học máy lại thường quan tâm đến việc dự đoán.\n","\n","Bài toán hồi quy xuất hiện mỗi khi chúng ta muốn dự đoán một giá trị số. Các ví dụ phổ biến bao gồm dự đoán giá cả (nhà, cổ phiếu, …), thời gian bệnh nhân nằm viện, nhu cầu trong ngành bán lẻ và vô vàn thứ khác. Không phải mọi bài toán dự đoán đều là bài toán hồi quy cổ điển. Trong các phần tiếp theo, chúng ta sẽ được giới thiệu bài toán phân loại, khi mục tiêu là dự đoán lớp đúng trong một tập các lớp cho trước."],"metadata":{"id":"izmXgGG7qv62"}},{"cell_type":"code","source":["%matplotlib inline\n","import math\n","import time\n","import numpy as np\n","import torch\n","from d2l import torch as d2l"],"metadata":{"id":"8LkF8_lC9ElP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676967330569,"user_tz":-420,"elapsed":6597,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"147aa3a7-561c-4900-a076-e8e4af228207"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]}]},{"cell_type":"markdown","source":["##3.1.1. Các thành phần cơ bản của Hồi quy Tuyến tính\n","\n","Hồi quy tuyến tính có lẽ là công cụ tiêu chuẩn đơn giản và phổ biến nhất được sử dụng cho bài toán hồi quy. Xuất hiện từ đầu thế kỉ 19, hồi quy tuyến tính được phát triển từ một vài giả thuyết đơn giản. Đầu tiên, ta giả sử quan hệ giữa các đặc trưng  **x**  và mục tiêu  *y*  là tuyến tính, do đó  *y*  có thể được biểu diễn bằng tổng trọng số của đầu vào  **x** , cộng hoặc trừ thêm nhiễu của các quan sát. Thứ hai, ta giả sử nhiễu có quy tắc (tuân theo phân phối Gauss). Để tạo động lực, hãy bắt đầu với một ví dụ. Giả sử ta muốn ước lượng giá nhà (bằng đô la) dựa vào diện tích (đơn vị feet vuông) và tuổi đời (theo năm).\n","\n","Để khớp một mô hình dự đoán giá nhà, chúng ta cần một tập dữ liệu các giao dịch mà trong đó ta biết giá bán, diện tích, tuổi đời cho từng căn nhà. Trong thuật ngữ của học máy, tập dữ liệu này được gọi là *dữ liệu huấn luyện* hoặc *tập huấn luyện*, và mỗi hàng (tương ứng với dữ liệu của một giao dịch) được gọi là một *ví dụ* hoặc *mẫu*. Thứ mà chúng ta muốn dự đoán (giá nhà) được gọi là *mục tiêu* hoặc *nhãn*. Các biến (tuổi đời và diện tích) mà những dự đoán dựa vào được gọi là các *đặc trưng* hoặc *hiệp biến*.\n","\n","Thông thường, chúng ta sẽ sử dụng $n$ để biểu thị số ví dụ trong tập dữ liệu của chúng ta. Chúng ta lập chỉ mục các ví dụ dữ liệu bằng $i$, biểu thị mỗi đầu vào là $\\mathbf{x}^{(i)} = [x_1^{(i)}, x_2^{(i)}]^\\top$ và nhãn tương ứng là $y^{(i)}$. \n","\n","###3.1.1.1 Mô hình Tuyến tính\n","Giả định tuyến tính chỉ nói rằng mục tiêu (giá) có thể được biểu thị dưới dạng tổng trọng số của các tính năng (diện tích và tuổi): \n","\n","$$\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b.$$\n","\n","Ở đây, $w_{\\mathrm{area}}$ và $w_{\\mathrm{age}}$ được gọi là *trọng số*, và $b$ được gọi là *bias - hệ số điều chỉnh* (còn được gọi là *offset - độ dời* hoặc *intercept*). Các trọng số xác định mức độ đóng góp của mỗi đặc trưng tới đầu ra, còn hệ số điều chỉnh là dự đoán của giá nhà khi tất cả các đặc trưng đều bằng  **0** . Ngay cả khi không bao giờ có một ngôi nhà có diện tích hoặc tuổi đời bằng không, ta vẫn cần sử dụng hệ số điều chỉnh; nếu không khả năng biểu diễn của mô hình tuyến tính sẽ bị suy giảm.\n","\n","Cho một tập dữ liệu, mục đích của chúng ta là chọn được các trọng số  $w$  và hệ số điều chỉnh  $b$  sao cho dự đoán của mô hình khớp nhất với giá nhà thực tế quan sát được trong dữ liệu.\n","\n","Trong các bài toán mà tập dữ liệu thường chỉ có một vài đặc trưng, biễu diễn tường minh mô hình ở dạng biểu thức dài như trên khá là phổ biến. Trong học máy, chúng ta thường làm việc với các tập dữ liệu nhiều chiều, vì vậy sẽ tốt hơn nếu ta tận dụng các ký hiệu trong đại số tuyến tính. Khi đầu vào của mô hình có  $d$  đặc trưng, ta biễu diễn dự đoán  $\\hat{y}$  bởi\n","\n","$$\\hat{y} = w_1  x_1 + ... + w_d  x_d + b.$$\n","\n","Thu thập toàn bộ các đặc trưng vào một vector  $x$  và toàn bộ các trọng số vào một vector  $w$ , ta có thể biễu diễn mô hình một cách gọn gàng bằng tích vô hướng:\n","\n","$$\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b.$$\n","\n","Ở đây, vector  $x$ tương ứng với một điểm dữ liệu. Chúng ta sẽ thấy rằng việc truy cập đến toàn bộ tập dữ liệu sẽ tiện hơn nếu ta biểu diễn tập dữ liệu bằng ma trận  $X$ . Mỗi hàng của ma trận  $X$  thể hiện một mẫu và mỗi cột thể hiện một đặc trưng.\n","\n","Với một tập hợp điểm dữ liệu  $X$ , kết quả dự đoán  $\\hat{y}$  có thể được biểu diễn bằng phép nhân giữa ma trận và vector:\n","\n","$${\\hat{\\mathbf{y}}} = \\mathbf{X} \\mathbf{w} + b,$$\n","\n","Cho một tập dữ liệu huấn luyện  $X$  và các giá trị mục tiêu đã biết trước  $y$ , mục tiêu của hồi quy tuyến tính là tìm vector trọng số  w  và hệ số điều chỉnh  b  sao cho với một điểm dữ liệu mới  $x_i$  được lấy mẫu từ cùng phân phối của tập huấn luyện, giá trị mục tiêu  $y_i$  sẽ được dự đoán với sai số nhỏ nhất (theo kỳ vọng).\n","\n","Kể cả khi biết rằng mô hình tuyến tính là lựa chọn tốt nhất để dự đoán  $y$  từ  $x$ , chúng ta cũng không kỳ vọng tìm được dữ liệu thực tế mà ở đó  $y$  đúng bằng  $\\mathbf{w}^\\top \\mathbf{x} + b$  với mọi điểm $(x,y)$ . Để dễ hình dung, mọi thiết bị đo lường dùng để quan sát đặc trưng  $X$  và nhãn  $y$  đều có sai số nhất định. Chính vì vậy, kể cả khi ta chắc chắn rằng mối quan hệ ẩn sau tập dữ liệu là tuyến tính, chúng ta sẽ thêm một thành phần nhiễu để giải thích các sai số đó.\n","\n","Trước khi tiến hành tìm các giá trị tốt nhất cho  $w$  và  $b$ , chúng ta sẽ cần thêm hai thứ nữa: (i) một phép đo đánh giá chất lượng mô hình và (ii) quy trình cập nhật mô hình để cải thiện chất lượng."],"metadata":{"id":"UfOjLt5GsxZU"}},{"cell_type":"markdown","source":["### 3.1.1.2. Hàm mất mát\n","\n","Trước khi suy nghĩ về việc làm thế nào để khớp mô hình với dữ liệu, ta cần phải xác định một phương pháp để đo mức độ khớp. Hàm mất mát định lượng khoảng cách giữa giá trị thực và giá trị dự đoán của mục tiêu. Độ mất mát thường là một số không âm và có giá trị càng nhỏ càng tốt. Khi các dự đoán hoàn hảo, chúng sẽ có độ mất mát sẽ bằng  0 . Hàm mất mát thông dụng nhất trong các bài toán hồi quy là hàm tổng bình phương các lỗi. Khi giá trị dự đoán của một điểm dữ liệu huấn luyện  $i$  là  $\\hat{y}^{(i)}$  và nhãn tương ứng là  $y^{(i)}$ , bình phương của lỗi được xác định như sau:\n","\n","$$l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2.$$\n","\n","Hằng số  $1/2$  không tạo ra sự khác biệt thực sự nào nhưng sẽ giúp ký hiệu thuận tiện hơn: nó sẽ được triệt tiêu khi lấy đạo hàm của hàm mất mát. Vì các dữ liệu trong tập huấn luyện đã được xác định trước và không thể thay đổi, sai số thực nghiệm chỉ là một hàm của các tham số mô hình. Để tìm hiểu cụ thể hơn, hãy xét ví dụ dưới đây về một bài toán hồi quy cho trường hợp một chiều trong hình dưới.\n","\n","![image.png](data:image/png;base64,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)"],"metadata":{"id":"E7YFunPyCM6s"}},{"cell_type":"markdown","source":["Lưu ý rằng khi hiệu giữa giá trị ước lượng  $\\hat{y}^{(i)}$  và giá trị quan sát  $y^{(i)}$  lớn, giá trị hàm mất mát sẽ tăng một lượng còn lớn hơn thế do sự phụ thuộc bậc hai. Để đo chất lượng của mô hình trên toàn bộ tập dữ liệu, ta đơn thuần lấy trung bình (hay tương đương là lấy tổng) các giá trị mất mát của từng mẫu trong tập huấn luyện.\n","\n","$$L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.$$\n","\n","Khi huấn luyện mô hình, ta muốn tìm các tham số $( w^∗,b^∗ )$ sao cho tổng độ mất mát trên toàn bộ các mẫu huấn luyện được cực tiểu hóa:\n","\n","$$\\mathbf{w}^*, b^* = \\operatorname*{argmin}_{\\mathbf{w}, b}\\  L(\\mathbf{w}, b).$$\n","\n"],"metadata":{"id":"vVsizknXDEau"}},{"cell_type":"markdown","source":["### 3.1.1.3. Nghiệm theo Công thức\n","\n","Hóa ra hồi quy tuyến tính chỉ là một bài toán tối ưu hóa đơn giản. Khác với hầu hết các mô hình được giới thiệu trong cuốn sách này, hồi quy tuyến tính có thể được giải bằng cách áp dụng một công thức đơn giản, cho một nghiệm tối ưu toàn cục. Để bắt đầu, chúng ta có thể gộp hệ số điều chỉnh  $b$  vào tham số  $w$  bằng cách thêm một cột toàn $1$ vào ma trận dữ liệu. Khi đó bài toán dự đoán trở thành bài toán cực tiểu hóa  $||y−Xw||$ . Bởi vì biểu thức này có dạng toàn phương, nó là một hàm số lồi, và miễn là bài toán này không suy biến (các đặc trưng độc lập tuyến tính), nó là một hàm số lồi chặt.\n","\n","Bởi vậy chỉ có một điểm cực trị trên mặt mất mát và nó tương ứng với giá trị mất mát nhỏ nhất. Lấy đạo hàm của hàm mất mát theo  w  và giải phương trình đạo hàm này bằng  0 , ta sẽ được nghiệm theo công thức:\n","\n","$$\\mathbf{w}^* = (\\mathbf X^\\top \\mathbf X)^{-1}\\mathbf X^\\top \\mathbf{y}$$\n","\n","Tuy những bài toán đơn giản như hồi quy tuyến tính có thể có nghiệm theo công thức, bạn không nên làm quen với sự may mắn này. Mặc dù các nghiệm theo công thức giúp ta phân tích toán học một cách thuận tiện, các điều kiện để có được nghiệm này chặt chẽ đến nỗi không có phương pháp học sâu nào thoả mãn được."],"metadata":{"id":"6UMF9LEGutTr"}},{"cell_type":"markdown","source":["### 3.1.1.4 Hạ Gradient\n","\n","Trong nhiều trường hợp ở đó ta không thể giải quyết các mô hình theo phép phân tích, và thậm chí khi mặt mất mát là các mặt bậc cao và không lồi, trên thực tế ta vẫn có thể huấn luyện các mô hình này một cách hiệu quả. Hơn nữa, trong nhiều tác vụ, những mô hình khó để tối ưu hóa này hoá ra lại tốt hơn các phương pháp khác nhiều, vậy nên việc bỏ công sức để tìm cách tối ưu chúng là hoàn toàn xứng đáng.\n","\n","Kỹ thuật chính để tối ưu hóa gần như bất kỳ mô hình học sâu nào, sẽ được sử dụng xuyên suốt cuốn sách này, bao gồm việc giảm thiểu lỗi qua các vòng lặp bằng cách cập nhật tham số theo hướng làm giảm dần hàm mất mát. Thuật toán này được gọi là hạ gradient. Trên các mặt mất mát lồi, giá trị mất mát cuối cùng sẽ hội tụ về giá trị nhỏ nhất. Tuy điều tương tự không thể áp dụng cho các mặt không lồi, ít nhất thuật toán sẽ dẫn tới một cực tiểu (hy vọng là tốt).\n","\n","Ứng dụng đơn giản nhất của hạ gradient bao gồm việc tính đạo hàm của hàm mất mát, tức trung bình của các giá trị mất mát được tính trên mỗi mẫu của tập dữ liệu. Trong thực tế, việc này có thể cực kì chậm. Chúng ta phải duyệt qua toàn bộ tập dữ liệu trước khi thực hiện một lần cập nhật. Vì thế, thường ta chỉ muốn lấy một minibatch ngẫu nhiên các mẫu mỗi khi ta cần tính bước cập nhật. Phương pháp biến thể này được gọi là hạ gradient ngẫu nhiên.\n","\n","Trong mỗi vòng lặp, đầu tiên chúng ta lấy ngẫu nhiên một minibatch $\\mathcal{B}$ dữ liệu huấn luyện với kích thước cố định. Sau đó, chúng ta tính đạo hàm (gradient) của hàm mất mát trên minibatch đó theo các tham số của mô hình. Cuối cùng, gradient này được nhân với tốc độ học  $η>0$  và kết quả này được trừ đi từ các giá trị tham số hiện tại.\n","\n","Chúng ta có thể biểu diễn việc cập nhật bằng công thức toán như sau ( $∂$  là ký hiệu đạo hàm riêng của hàm số) :\n","\n","$$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}_t} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b).$$\n","\n","Tổng kết lại, các bước của thuật toán như sau: \n","- (i) khởi tạo các giá trị tham số của mô hình, thường thì sẽ được chọn ngẫu nhiên. \n","- (ii) tại mỗi vòng lặp, ta lấy ngẫu nhiên từng batch từ tập dữ liệu (nhiều lần), rồi tiến hành cập nhật các tham số của mô hình theo hướng ngược với gradient.\n","\n","Khi sử dụng hàm mất mát bậc hai và mô hình tuyến tính, chúng ta có thể biểu diễn bước này một cách tường minh như sau: Lưu ý rằng  $w$  và  $x$  là các vector. Ở đây, việc ký hiệu bằng các vector giúp công thức dễ đọc hơn nhiều so với việc biểu diễn bằng các hệ số như  $w_1,w_2,…,w_d$.\n","\n","$$\\begin{aligned} \\mathbf{w} & \\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}_t} \\partial_{\\mathbf{w}} l^{(i)}(\\mathbf{w}, b) && = \\mathbf{w} - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}_t} \\mathbf{x}^{(i)} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)\\\\ b &\\leftarrow b -  \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}_t} \\partial_b l^{(i)}(\\mathbf{w}, b) &&  = b - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}_t} \\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right). \\end{aligned}$$\n","\n"],"metadata":{"id":"uE0zdjUR1ehD"}},{"cell_type":"markdown","source":["Trong phương trình trên, $|\\mathcal{B}|$ là số ví dụ trong mỗi minibatch (kích thước batch) và $η$ là tốc độ học. Cũng cần phải nhấn mạnh rằng các giá trị của kích thước batch và tốc độ học được lựa chọn trước một cách thủ công và thường không được học thông qua quá trình huấn luyện mô hình. Các tham số này tuy điều chỉnh được nhưng không được cập nhật trong vòng huấn luyện, và được gọi là siêu tham số. Điều chỉnh siêu tham số là quá trình lựa chọn chúng, thường dựa trên kết quả của vòng lặp huấn luyện được đánh giá trên một tập kiểm định riêng biệt.\n","\n","Sau khi huấn luyện đủ số vòng lặp được xác định trước (hoặc đạt được một tiêu chí dừng khác), ta sẽ ghi lại các tham số mô hình đã được ước lượng, ký hiệu là  $\\hat{w},\\hat{b}$  (ký hiệu “mũ” thường thể hiện các giá trị ước lượng). Lưu ý rằng ngay cả khi hàm số thực sự tuyến tính và không có nhiễu, các tham số này sẽ không cực tiểu hóa được hàm mất mát. Mặc dù thuật toán dần dần hội tụ đến một điểm cực tiểu, nó vẫn không thể tới chính xác được cực tiểu đó với số bước hữu hạn.\n","\n","Hồi quy tuyến tính thực ra là một bài toán tối ưu lồi, do đó chỉ có một cực tiểu (toàn cục). Tuy nhiên, đối với các mô hình phức tạp hơn, như mạng sâu, mặt của hàm mất mát sẽ có nhiều cực tiểu. May mắn thay, vì một lý do nào đó mà những người làm về học sâu hiếm khi phải vật lộn để tìm ra các tham số cực tiểu hóa hàm mất mát trên dữ liệu huấn luyện. Nhiệm vụ khó khăn hơn là tìm ra các tham số dẫn đến giá trị mất mát thấp trên dữ liệu mà mô hình chưa từng thấy trước đây, một thử thách được gọi là sự khái quát hóa. Chúng ta sẽ gặp lại chủ đề này xuyên suốt cuốn sách.\n"],"metadata":{"id":"guBraGe7Au3T"}},{"cell_type":"markdown","source":["### 3.1.1.5. Dự đoán bằng Mô hình đã được Huấn luyện\n","\n","Với mô hình hồi quy tuyến tính đã được huấn luyện  $\\hat{w}^⊤x+\\hat{b}$ , ta có thể ước lượng giá của một căn nhà mới (ngoài bộ dữ liệu dùng để huấn luyện) với diện tích  $x_1$  và tuổi đời  $x_2$  của nó. Việc ước lượng mục tiêu khi biết trước những đặc trưng thường được gọi là dự đoán hay suy luận (inference).\n","\n","Ở đây ta sẽ dùng từ dự đoán thay vì suy luận, dù suy luận là một thuật ngữ khá phổ biến trong học sâu, áp dụng thuật ngữ này ở đây lại không phù hợp. Trong thống kê, suy luận thường được dùng cho việc ước lượng thông số dựa trên tập dữ liệu. Việc dùng sai thuật ngữ này là nguyên nhân gây ra sự hiểu nhầm giữa những người làm học sâu và các nhà thống kê."],"metadata":{"id":"G0IjiE0hBnV5"}},{"cell_type":"markdown","source":["### 3.1.1.6. Vector hóa để tăng Tốc độ Tính toán\n","\n","Khi huấn luyện mô hình, chúng ta thường muốn xử lý đồng thời các mẫu dữ liệu trong minibatch. Để làm được điều này một cách hiệu quả, chúng ta phải vector hóa việc tính toán bằng cách sử dụng các thư viện đại số tuyến tính thay vì sử dụng các vòng lặp for trong Python.\n","\n","Chúng ta sẽ sử dụng hai phương pháp cộng vector dưới đây để hiểu được tại sao vector hóa là cần thiết trong học máy. Đầu tiên, ta khởi tạo hai vector  10000  chiều chứa toàn giá trị một. Chúng ta sẽ sử dụng vòng lặp for trong Python ở phương pháp thứ nhất và một hàm trong thư viện np ở phương pháp thứ hai."],"metadata":{"id":"TFDhpPfBB-dz"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"or5UKF2WqfLr","executionInfo":{"status":"ok","timestamp":1676967534606,"user_tz":-420,"elapsed":749,"user":{"displayName":"vu tung","userId":"03394210267989276557"}}},"outputs":[],"source":["n = 1000\n","a = torch.ones(n)\n","b = torch.ones(n)"]},{"cell_type":"markdown","source":["Ta sẽ bấm giờ với phương pháp chạy vòng for"],"metadata":{"id":"0861iqpEC2n7"}},{"cell_type":"code","source":["c = torch.zeros(n)\n","t=time.time()\n","for i in range(n):\n","  c[i] = a[i] + b[i]\n","f'{time.time() - t:.5f} sec'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9rdxCn0fDQnM","executionInfo":{"status":"ok","timestamp":1676967536968,"user_tz":-420,"elapsed":327,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"0e0d7920-c496-4732-b5aa-af3b799f065c"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.03875 sec'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Với toán tử cộng"],"metadata":{"id":"qsLqzJYNDfPX"}},{"cell_type":"code","source":["t = time.time()\n","d = a + b\n","f'{time.time() - t:.5f} sec'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"sFbrpnQdDhQd","executionInfo":{"status":"ok","timestamp":1676967588394,"user_tz":-420,"elapsed":918,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"2fbe6d1c-1625-4f1a-a334-bb897ad72391"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.00122 sec'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Bạn có thể nhận thấy rằng, phương pháp thứ hai nhanh hơn rất nhiều lần so với phương pháp thứ nhất. Việc vector hóa thường tăng tốc độ tính toán lên nhiều bậc. Ngoài ra, giao phó công việc tính toán cho thư viện để tránh phải tự viết lại sẽ giảm thiểu khả năng phát sinh lỗi."],"metadata":{"id":"VvY7IKCYDw8M"}},{"cell_type":"markdown","source":["## 3.1.2. Phân phối Chuẩn và Hàm mất mát Bình phương\n","\n","Mặc dù bạn đã có thể thực hành với kiến thức được trình bày phía trên, trong phần tiếp theo chúng ta sẽ làm rõ hơn nguồn gốc của hàm mất mát bình phương thông qua các giả định về phân phối của nhiễu.\n","\n","Nhắc lại ở trên rằng hàm mất mát bình phương  $l(y,\\hat{y})=\\frac{1}{2}(y−\\hat{y})^2$  có nhiều thuộc tính tiện lợi. Việc nó có đạo hàm đơn giản  $∂_\\hat{y}l(y,y^)=(\\hat{y}−y)$  là một trong số đó.\n","\n","Như được đề cập trước đó, hồi quy tuyến tính được phát minh bởi Gauss vào năm 1795. Ông cũng là người khám phá ra phân phối chuẩn (còn được gọi là phân phối Gauss). Hóa ra là mối liên hệ giữa phân phối chuẩn và hồi quy tuyến tính không chỉ dừng lại ở việc chúng có chung cha đẻ. Để gợi nhớ lại cho bạn, mật độ xác suất của phân phối chuẩn với trung bình  $μ$  và phương sai  $σ^2$  được cho bởi:\n","\n","\n","$$p(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (x - \\mu)^2\\right).$$\n","\n","Dưới đây ta định nghĩa một hàm Python để tính toán phân phối chuẩn."],"metadata":{"id":"E1bSAUB3Dxmg"}},{"cell_type":"code","source":["def normal(x, mu, sigma):\n","  p = 1/math.sqrt(2*math.pi*sigma**2)\n","  return p*np.exp(-0.5*(x - mu)**2/sigma**2)"],"metadata":{"id":"AzBxBkNlE8cA","executionInfo":{"status":"ok","timestamp":1676968231159,"user_tz":-420,"elapsed":285,"user":{"displayName":"vu tung","userId":"03394210267989276557"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Giờ ta có thể trực quan hóa các phân phối chuẩn."],"metadata":{"id":"ibS3HMDeGK2f"}},{"cell_type":"code","source":["x = np.arange(-7, 7, 0.01)\n","\n","params = [(0,1), (0,2), (3,1)]\n","d2l.plot(x, [normal(x, mu, sigma) for mu,sigma in params], xlabel = 'x',\n","         ylabel = 'p(x)', figsize = (4.5, 2.5),\n","         legend=[f'mean {mu}, std{sigma}' for mu, sigma in params])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"BQbSb2bdGMYr","executionInfo":{"status":"ok","timestamp":1676968499308,"user_tz":-420,"elapsed":777,"user":{"displayName":"vu tung","userId":"03394210267989276557"}},"outputId":"7b1d3aff-8bd0-4242-aafb-42bc82fd306e"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 324x180 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 302.08125 180.65625\" width=\"302.08125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 302.08125 180.65625 \nL 302.08125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 143.1 \nL 294.88125 143.1 \nL 294.88125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 71.511736 143.1 \nL 71.511736 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m51ba97e7ee\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"71.511736\" xlink:href=\"#m51ba97e7ee\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −6 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(64.140642 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 104.145435 143.1 \nL 104.145435 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"104.145435\" xlink:href=\"#m51ba97e7ee\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(96.774342 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 136.779135 143.1 \nL 136.779135 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.779135\" xlink:href=\"#m51ba97e7ee\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(129.408041 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 169.412834 143.1 \nL 169.412834 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"169.412834\" xlink:href=\"#m51ba97e7ee\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(166.231584 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 202.046534 143.1 \nL 202.046534 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"202.046534\" xlink:href=\"#m51ba97e7ee\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2 -->\n      <g transform=\"translate(198.865284 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 234.680233 143.1 \nL 234.680233 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.680233\" xlink:href=\"#m51ba97e7ee\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 4 -->\n      <g transform=\"translate(231.498983 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 267.313932 143.1 \nL 267.313932 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"267.313932\" xlink:href=\"#m51ba97e7ee\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 6 -->\n      <g transform=\"translate(264.132682 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- x -->\n     <defs>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n     </defs>\n     <g transform=\"translate(166.371875 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-120\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 43.78125 136.922727 \nL 294.88125 136.922727 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4a939b7cb6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m4a939b7cb6\" y=\"136.922727\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 140.721946)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 43.78125 105.954474 \nL 294.88125 105.954474 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m4a939b7cb6\" y=\"105.954474\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(20.878125 109.753693)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 43.78125 74.986221 \nL 294.88125 74.986221 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m4a939b7cb6\" y=\"74.986221\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 78.78544)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 43.78125 44.017968 \nL 294.88125 44.017968 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m4a939b7cb6\" y=\"44.017968\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(20.878125 47.817187)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p9332c27531)\" d=\"M 43.78125 13.049715 \nL 294.88125 13.049715 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m4a939b7cb6\" y=\"13.049715\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 16.848934)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- p(x) -->\n     <defs>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(14.798438 85.185156)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"102.490234\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"161.669922\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#p9332c27531)\" d=\"M 55.194886 136.922727 \nL 108.224648 136.813535 \nL 113.609208 136.566288 \nL 117.198915 136.184417 \nL 119.97278 135.668952 \nL 122.257139 135.025186 \nL 124.215161 134.257847 \nL 126.010014 133.330368 \nL 127.804868 132.138334 \nL 129.436552 130.779445 \nL 131.068237 129.113085 \nL 132.699922 127.093512 \nL 134.331607 124.67477 \nL 135.963292 121.812692 \nL 137.594977 118.467288 \nL 139.226662 114.605495 \nL 141.021516 109.733818 \nL 142.816369 104.197078 \nL 144.774391 97.412516 \nL 146.895582 89.247632 \nL 149.506278 78.224523 \nL 153.259153 61.239305 \nL 157.501534 42.275258 \nL 159.785893 33.113056 \nL 161.580746 26.820515 \nL 163.049263 22.424523 \nL 164.354611 19.173268 \nL 165.49679 16.884633 \nL 166.475801 15.362585 \nL 167.454812 14.263605 \nL 168.270655 13.679589 \nL 169.086497 13.401979 \nL 169.739171 13.401979 \nL 170.391845 13.599455 \nL 171.207688 14.122466 \nL 172.02353 14.948577 \nL 173.002541 16.331186 \nL 173.981552 18.12656 \nL 175.123732 20.717347 \nL 176.42908 24.286979 \nL 177.897596 29.000684 \nL 179.69245 35.615359 \nL 181.81364 44.367165 \nL 184.913841 58.245076 \nL 190.46157 83.161144 \nL 192.909098 93.115047 \nL 195.030288 100.899673 \nL 196.98831 107.299489 \nL 198.783164 112.473243 \nL 200.578017 116.986089 \nL 202.209702 120.534567 \nL 203.841387 123.5855 \nL 205.473072 126.176453 \nL 207.104757 128.35023 \nL 208.736442 130.152334 \nL 210.368127 131.628806 \nL 211.999812 132.824481 \nL 213.794665 133.865803 \nL 215.752687 134.73293 \nL 217.873878 135.421686 \nL 220.321405 135.97206 \nL 223.258438 136.389278 \nL 227.011314 136.67952 \nL 232.395874 136.850878 \nL 243.001826 136.917995 \nL 283.467614 136.922727 \nL 283.467614 136.922727 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path clip-path=\"url(#p9332c27531)\" d=\"M 55.194886 136.7876 \nL 65.800839 136.522951 \nL 73.143421 136.126434 \nL 79.017487 135.590287 \nL 83.912542 134.926494 \nL 88.318091 134.105229 \nL 92.234135 133.153577 \nL 95.823842 132.06316 \nL 99.250381 130.798749 \nL 102.51375 129.367709 \nL 105.77712 127.695008 \nL 109.04049 125.764111 \nL 112.30386 123.563438 \nL 115.56723 121.087897 \nL 118.993769 118.196043 \nL 122.583476 114.860886 \nL 126.49952 110.903144 \nL 131.068237 105.948686 \nL 138.247651 97.770807 \nL 144.611223 90.644946 \nL 148.527267 86.589675 \nL 151.790637 83.530672 \nL 154.564501 81.224436 \nL 157.175197 79.344214 \nL 159.459556 77.957408 \nL 161.743915 76.832365 \nL 163.865105 76.036198 \nL 165.823127 75.522597 \nL 167.781149 75.227168 \nL 169.739171 75.153089 \nL 171.697193 75.301158 \nL 173.655215 75.66978 \nL 175.613237 76.254995 \nL 177.734428 77.126088 \nL 179.855618 78.233161 \nL 182.139977 79.673625 \nL 184.587504 81.48006 \nL 187.361369 83.820867 \nL 190.46157 86.751111 \nL 194.051277 90.469337 \nL 198.783164 95.721751 \nL 211.673475 110.215093 \nL 215.752687 114.383393 \nL 219.505563 117.90542 \nL 222.932101 120.82526 \nL 226.195471 123.328273 \nL 229.458841 125.556324 \nL 232.722211 127.513772 \nL 235.985581 129.211619 \nL 239.248951 130.665971 \nL 242.675489 131.95258 \nL 246.265196 133.063568 \nL 250.18124 134.034481 \nL 254.423621 134.846714 \nL 259.155508 135.514669 \nL 264.540068 136.040363 \nL 270.903639 136.432354 \nL 279.225233 136.707949 \nL 283.467614 136.785216 \nL 283.467614 136.785216 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#p9332c27531)\" d=\"M 55.194886 136.922727 \nL 157.175197 136.813535 \nL 162.559757 136.566288 \nL 166.149464 136.184417 \nL 168.923329 135.668952 \nL 171.207688 135.025186 \nL 173.16571 134.257847 \nL 174.960563 133.330368 \nL 176.755417 132.138334 \nL 178.387102 130.779445 \nL 180.018787 129.113085 \nL 181.650472 127.093512 \nL 183.282156 124.67477 \nL 184.913841 121.812692 \nL 186.545526 118.467288 \nL 188.177211 114.605495 \nL 189.972065 109.733818 \nL 191.766918 104.197078 \nL 193.72494 97.412516 \nL 195.846131 89.247632 \nL 198.456827 78.224523 \nL 202.209702 61.239305 \nL 206.452083 42.275258 \nL 208.736442 33.113056 \nL 210.531295 26.820515 \nL 211.999812 22.424523 \nL 213.30516 19.173268 \nL 214.447339 16.884633 \nL 215.42635 15.362585 \nL 216.405361 14.263605 \nL 217.221204 13.679589 \nL 218.037046 13.401979 \nL 218.68972 13.401979 \nL 219.342394 13.599455 \nL 220.158237 14.122466 \nL 220.974079 14.948577 \nL 221.95309 16.331186 \nL 222.932101 18.12656 \nL 224.074281 20.717347 \nL 225.379629 24.286979 \nL 226.848145 29.000684 \nL 228.642999 35.615359 \nL 230.764189 44.367165 \nL 233.864391 58.245076 \nL 239.412119 83.161144 \nL 241.859647 93.115047 \nL 243.980837 100.899673 \nL 245.938859 107.299489 \nL 247.733713 112.473243 \nL 249.528566 116.986089 \nL 251.160251 120.534567 \nL 252.791936 123.5855 \nL 254.423621 126.176453 \nL 256.055306 128.35023 \nL 257.686991 130.152334 \nL 259.318676 131.628806 \nL 260.950361 132.824481 \nL 262.745215 133.865803 \nL 264.703236 134.73293 \nL 266.824427 135.421686 \nL 269.271954 135.97206 \nL 272.208987 136.389278 \nL 275.961863 136.67952 \nL 281.346423 136.850878 \nL 283.467614 136.879593 \nL 283.467614 136.879593 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 143.1 \nL 43.78125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 294.88125 143.1 \nL 294.88125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 143.1 \nL 294.88125 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 294.88125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 50.78125 59.234375 \nL 148.878125 59.234375 \nQ 150.878125 59.234375 150.878125 57.234375 \nL 150.878125 14.2 \nQ 150.878125 12.2 148.878125 12.2 \nL 50.78125 12.2 \nQ 48.78125 12.2 48.78125 14.2 \nL 48.78125 57.234375 \nQ 48.78125 59.234375 50.78125 59.234375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_28\">\n     <path d=\"M 52.78125 20.298438 \nL 72.78125 20.298438 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_29\"/>\n    <g id=\"text_15\">\n     <!-- mean 0, std1 -->\n     <defs>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 11.71875 12.40625 \nL 22.015625 12.40625 \nL 22.015625 4 \nL 14.015625 -11.625 \nL 7.71875 -11.625 \nL 11.71875 4 \nz\n\" id=\"DejaVuSans-44\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     </defs>\n     <g transform=\"translate(80.78125 23.798438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"158.935547\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"220.214844\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"283.59375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"315.380859\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"379.003906\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"410.791016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"442.578125\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"494.677734\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"533.886719\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"597.363281\" xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n    <g id=\"line2d_30\">\n     <path d=\"M 52.78125 34.976562 \nL 72.78125 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_31\"/>\n    <g id=\"text_16\">\n     <!-- mean 0, std2 -->\n     <g transform=\"translate(80.78125 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"158.935547\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"220.214844\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"283.59375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"315.380859\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"379.003906\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"410.791016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"442.578125\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"494.677734\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"533.886719\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"597.363281\" xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n    <g id=\"line2d_32\">\n     <path d=\"M 52.78125 49.654688 \nL 72.78125 49.654688 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_33\"/>\n    <g id=\"text_17\">\n     <!-- mean 3, std1 -->\n     <g transform=\"translate(80.78125 53.154688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"158.935547\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"220.214844\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"283.59375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"315.380859\" xlink:href=\"#DejaVuSans-51\"/>\n      <use x=\"379.003906\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"410.791016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"442.578125\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"494.677734\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"533.886719\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"597.363281\" xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9332c27531\">\n   <rect height=\"135.9\" width=\"251.1\" x=\"43.78125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Có thể thấy rằng, thay đổi giá trị trung bình tương ứng với việc dịch chuyển phân phối dọc theo trục x, tăng giá trị phương sai sẽ trải rộng phân phối và hạ thấp đỉnh của nó.\n","\n","Để thấy rõ hơn mối quan hệ giữa hồi quy tuyến tính và hàm mất mát trung bình bình phương sai số (MSE), ta có thể giả định rằng các quan sát bắt nguồn từ những quan sát nhiễu, và giá trị nhiễu này tuân theo phân phối chuẩn như sau:\n","\n","$$y = \\mathbf{w}^\\top \\mathbf{x} + b + \\epsilon \\text{ where } \\epsilon \\sim \\mathcal{N}(0, \\sigma^2).$$\n","\n","Do đó, chúng ta có thể viết khả năng thu được một giá trị cụ thể của  y  khi biết trước  x  là\n","\n","$$P(y \\mid \\mathbf{x}) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2 \\sigma^2} (y - \\mathbf{w}^\\top \\mathbf{x} - b)^2\\right).$$\n","\n","Dựa vào nguyên lý hợp lý cực đại, giá trị tốt nhất của  b  và  w  là những giá trị giúp cực đại hóa sự hợp lý của toàn bộ tập dữ liệu:\n","\n","$$P(\\mathbf y \\mid \\mathbf X) = \\prod_{i=1}^{n} p(y^{(i)} \\mid \\mathbf{x}^{(i)}).$$\n","\n","Bộ ước lượng được chọn theo nguyên lý hợp lý cực đại được gọi là bộ ước lượng hợp lý cực đại (Maximum Likelihood Estimators – MLE). Dù việc cực đại hóa tích của nhiều hàm mũ trông có vẻ khó khăn, chúng ta có thể khiến mọi thứ đơn giản hơn nhiều mà không làm thay đổi mục tiêu ban đầu bằng cách cực đại hóa log của hàm hợp lý. Vì lý do lịch sử, các bài toán tối ưu thường được biểu diễn dưới dạng bài toán cực tiểu hóa thay vì cực đại hóa. Do đó chúng ta có thể cực tiểu hóa hàm đối log hợp lý (Negative Log-Likelihood - NLL)  −logp(y|X)  mà không cần thay đổi gì thêm. Kết nối các công thức trên, ta có:\n","\n","$$-\\log P(\\mathbf y \\mid \\mathbf X) = \\sum_{i=1}^n \\frac{1}{2} \\log(2 \\pi \\sigma^2) + \\frac{1}{2 \\sigma^2} \\left(y^{(i)} - \\mathbf{w}^\\top \\mathbf{x}^{(i)} - b\\right)^2.$$\n","\n","Giờ ta chỉ cần thêm một giả định nữa:  $σ$  là một hằng số cố định. Do đó, ta có thể bỏ qua số hạng đầu tiên bởi nó không phụ thuộc vào  $w$  hoặc  $b$ . Còn số hạng thứ hai thì giống hệt hàm bình phương sai số đã được giới thiệu ở trên, nhưng được nhân thêm với hằng số  $\\frac{1}{σ^2}$ . May mắn thay, nghiệm không phụ thuộc vào  $σ$ . Điều này dẫn tới việc cực tiểu hóa bình phương sai số tương đương với việc ước lượng hợp lý cực đại cho mô hình tuyến tính dưới giả định có nhiễu cộng Gauss."],"metadata":{"id":"qSnGfmyVHPhP"}},{"cell_type":"markdown","source":["## 3.1.3. Từ Hồi quy Tuyến tính tới Mạng Học sâu\n","\n","Cho đến nay, chúng ta mới chỉ đề cập về các hàm tuyến tính. Trong khi mạng nơ-ron có thể xấp xỉ rất nhiều họ mô hình, ta có thể bắt đầu coi mô hình tuyến tính như một mạng nơ-ron và biểu diễn nó theo ngôn ngữ của mạng nơ-ron. Để bắt đầu, hãy cùng viết lại mọi thứ theo ký hiệu ‘tầng’ (layer)."],"metadata":{"id":"glho0C_PJVBS"}},{"cell_type":"markdown","source":["### 3.1.3.1. Giản đồ Mạng Nơ ron\n","\n","Những người làm học sâu thích vẽ giản đồ để trực quan hóa những gì đang xảy ra trong mô hình của họ. Trong hình dưới đây, mô hình tuyến tính được minh họa như một mạng nơ-ron. Những giản đồ này chỉ ra cách kết nối (ở đây, mỗi đầu vào được kết nối tới đầu ra) nhưng không có giá trị của các trọng số và các hệ số điều chỉnh.\n","\n","![Linear regression is a single-layer neural network.](http://d2l.ai/_images/singleneuron.svg)\n","\n","Vì chỉ có một nơ-ron tính toán (một nút) trong đồ thị (các giá trị đầu vào không cần tính mà được cho trước), chúng ta có thể coi mô hình tuyến tính như mạng nơ-ron với chỉ một nơ-ron nhân tạo duy nhất. Với mô hình này, mọi đầu vào đều được kết nối tới mọi đầu ra (trong trường hợp này chỉ có một đầu ra!), ta có thể coi phép biến đổi này là một tầng kết nối đầy đủ, hay còn gọi là tầng kết nối dày đặc. Chúng ta sẽ nói nhiều hơn về các mạng nơ-ron cấu tạo từ những tầng như vậy trong chương kế tiếp về mạng perceptron đa tầng."],"metadata":{"id":"m8qwpdAEJcLY"}},{"cell_type":"markdown","source":["### 3.1.3.2. Sinh vật học\n","\n","Vì hồi quy tuyến tính (được phát minh vào năm 1795) được phát triển trước ngành khoa học thần kinh tính toán, nên việc mô tả hồi quy tuyến tính như một mạng nơ-ron có vẻ hơi ngược thời. Để hiểu tại sao nhà nghiên cứu sinh vật học/thần kinh học Warren McCulloch và Walter Pitts tìm đến các mô hình tuyến tính để làm điểm khởi đầu nghiên cứu và phát triển các mô hình nơ-ron nhân tạo, hãy xem ảnh của một nơ-ron sinh học tại hình dưới. Mô hình này bao gồm sợi nhánh (cổng đầu vào), nhân tế bào (bộ xử lý trung tâm), sợi trục (dây đầu ra), và đầu cuối sợi trục (cổng đầu ra), cho phép kết nối với các tế bào thần kinh khác thông qua synapses.\n","\n","![The real neuron.](http://d2l.ai/_images/neuron.svg)\n","\n","Thông tin  $x_i$  đến từ các nơ-ron khác (hoặc các cảm biến môi trường như võng mạc) được tiếp nhận tại các sợi nhánh. Cụ thể, thông tin đó được nhân với các trọng số của synapses  $w_i$  để xác định mức ảnh hưởng của từng đầu vào (ví dụ: kích hoạt hoặc ức chế thông qua tích  $x_iw_i$ ). Các đầu vào có trọng số đến từ nhiều nguồn được tổng hợp trong nhân tế bào dưới dạng tổng có trọng số  $y= sum_ix_iw_i+b$  và thông tin này sau đó được gửi đi để xử lý thêm trong sợi trục  y , thường là sau một vài xử lý phi tuyến tính qua  $σ(y)$ . Từ đó, nó có thể được gửi đến đích (ví dụ, cơ bắp) hoặc được đưa vào một tế bào thần kinh khác thông qua các sợi nhánh."],"metadata":{"id":"fTqLnhXyJuS1"}},{"cell_type":"markdown","source":["## 3.1.4. Bài tập"],"metadata":{"id":"Q7lOpnWSMSJz"}}]}