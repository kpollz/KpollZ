<!DOCTYPE html>
<!-- saved from url=(0140)https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M -->
<html lang="en-US" class="scroll-smooth" style="--vh: 9.48px;"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Video generation models as world simulators</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="facebook-domain-verification" content="5y9s3n362dmfwvfk3gl7xf9qw0fqlq">
<link rel="preconnect" href="https://github.githubassets.com/" crossorigin="">
<link rel="preconnect" href="https://fonts.googleapis.com/" crossorigin="">
<script src="./Video generation models as world simulators_files/beacon.min.js.tải xuống" data-cf-beacon="{&quot;token&quot;: &quot;393a70f7207446539b84da589836560a&quot;}"></script><style></style>
<meta name="description" content="We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.">
<meta property="og:title" content="Video generation models as world simulators">
<meta property="og:description" content="We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.">
<meta property="og:image" content="https://images.openai.com/blob/28bcbcb2-563a-432b-bb30-d74f66a087fe/young-tiger.jpg?trim=0%2C0%2C0%2C0&amp;width=1000&amp;quality=80">
<meta property="og:image:alt" content="Young Tiger">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@OpenAI">
<meta name="twitter:image" content="https://images.openai.com/blob/28bcbcb2-563a-432b-bb30-d74f66a087fe/young-tiger.jpg?trim=0%2C0%2C0%2C0&amp;width=1000&amp;quality=80"><link rel="modulepreload" href="https://openai.com/research/video-generation-models-as-world-simulators/_payload.js"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/entry.3fed4871.js.tải xuống"><link rel="preload" as="style" href="./Video generation models as world simulators_files/entry.08e0417e.css"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/app.241b6099.js.tải xuống"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/usePageTransition.7314f674.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/useAsyncNavigationData.7fe8956a.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/usePageLoading.037fe9a5.js"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/_slug_.78f59fd3.js.tải xuống"><link rel="preload" as="style" href="./Video generation models as world simulators_files/Detail.befef1e5.css"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/Footer.fe671c3d.js"><link rel="preload" as="style" href="./Video generation models as world simulators_files/Footer.6cdd2dae.css"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/HeroMeta.d0c6e46a.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/Blocks.cdfff5b8.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/BlockTimedTabs.vue.6d03a11a.js"><link rel="preload" as="style" href="./Video generation models as world simulators_files/BlockTimedTabs.b12ff6e9.css"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/Listing.d3b0b0d0.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/slugify.068b7bc9.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/useResourceIndexData.03569f0e.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/useHeadSeo.d7f34089.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/Landing.1e1005c5.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/List.84c8f7be.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/ResearchPublications.9ecce282.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/usePreviewToken.5c6e66f6.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/useErrorPage.4d46afb9.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/lang.4a9029fb.js"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/Sync.149551cd.js.tải xuống"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/VideoTwoUpSync.2e5acc7b.js.tải xuống"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/InlineVideo.ceb7cabc.js.tải xuống"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/snippets.3042dd9d.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/LazyAutoPausingVimeo.05ddfc43.js"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/VideoGrid.038c23ff.js.tải xuống"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/Turtles.0af69134.js.tải xuống"><link rel="modulepreload" as="script" crossorigin="" href="./Video generation models as world simulators_files/Madlib.770b9bbb.js.tải xuống"><link rel="prefetch" as="script" crossorigin="" href="https://openai.com/_nuxt/error-component.b41a03df.js"><link rel="stylesheet" href="./Video generation models as world simulators_files/entry.08e0417e.css"><link rel="stylesheet" href="./Video generation models as world simulators_files/Detail.befef1e5.css"><link rel="stylesheet" href="./Video generation models as world simulators_files/Footer.6cdd2dae.css"><link rel="stylesheet" href="./Video generation models as world simulators_files/BlockTimedTabs.b12ff6e9.css"><style>.--savior-overlay-transform-reset {
  transform: none !important;
}
.--savior-overlay-z-index-top {
  z-index: 2147483643 !important;
}
.--savior-overlay-position-relative {
  position: relative;
}
.--savior-overlay-position-static {
  position: static !important;
}
.--savior-overlay-overflow-hidden {
  overflow: hidden !important;
}
.--savior-overlay-overflow-x-visible {
  overflow-x: visible !important;
}
.--savior-overlay-overflow-y-visible {
  overflow-y: visible !important;
}
.--savior-overlay-z-index-reset {
  z-index: auto !important;
}
.--savior-overlay-display-none {
  display: none !important;
}
.--savior-overlay-clearfix {
  clear: both;
}
.--savior-overlay-reset-filter {
  filter: none !important;
  backdrop-filter: none !important;
}
.--savior-tooltip-host {
  z-index: 9999;
  position: absolute;
  top: 0;
}
/*Override css styles for Twitch.tv*/
main.--savior-overlay-z-index-reset {
  z-index: auto !important;
}
.modal__backdrop.--savior-overlay-z-index-reset {
  position: static !important;
}
main.--savior-overlay-z-index-top {
  z-index: auto !important;
}
main.--savior-overlay-z-index-top .channel-root__player-container + div,
main.--savior-overlay-z-index-top .video-player-hosting-ui__container + div {
  opacity: 0.1;
}
/*Dirty hack for facebook big video page e.g: https://www.facebook.com/abc/videos/...*/
.--savior-backdrop {
  position: fixed !important;
  z-index: 2147483642 !important;
  top: 0;
  left: 0;
  height: 100vh;
  width: 100vw !important;
  background-color: rgba(0,0,0,0.9);
}
.--savior-overlay-twitter-video-player {
  position: fixed;
  width: 80%;
  height: 80%;
  top: 10%;
  left: 10%;
}
.--savior-overlay-z-index-reset [class*="DivSideNavContainer"],
.--savior-overlay-z-index-reset [class*="DivHeaderContainer"],
.--savior-overlay-z-index-reset [class*="DivBottomContainer"],
.--savior-overlay-z-index-reset [class*="DivCategoryListWrapper"],
.--savior-overlay-z-index-reset [data-testid="sidebarColumn"],
.--savior-overlay-z-index-reset header[role="banner"],
.--savior-overlay-z-index-reset [data-testid="cellInnerDiv"]:not(.--savior-overlay-z-index-reset),
.--savior-overlay-z-index-reset [aria-label="Home timeline"]>div:first-child,
.--savior-overlay-z-index-reset [aria-label="Home timeline"]>div:nth-child(3) {
  z-index: -1 !important;
}
.--savior-overlay-z-index-reset [data-testid="cellInnerDiv"] .--savior-backdrop+div {
  z-index: 2147483643 !important;
}
.--savior-overlay-z-index-reset [data-testid="primaryColumn"]>[aria-label="Home timeline"] {
  z-index: 0 !important;
}
.--savior-overlay-z-index-reset#mtLayer,
.--savior-overlay-z-index-reset.media-layer {
  z-index: 3000 !important;
}
.--savior-overlay-position-relative [class*="SecBar_secBar_"],
.--savior-overlay-position-relative .woo-box-flex [class*="Frame_top_"] {
  z-index: 0 !important;
}
.--savior-overlay-position-relative .vue-recycle-scroller__item-view:not(.--savior-overlay-z-index-reset),
.--savior-overlay-position-relative .woo-panel-main[class*="BackTop_main_"],
.--savior-overlay-position-relative [class*="Main_side_"] {
  z-index: -1 !important;
}
/* Fix conflict css with zingmp3 */
.zm-video-modal.--savior-overlay-z-index-reset {
  position: absolute;
}
/* Dirty hack for xvideos99 */
#page #main.--savior-overlay-z-index-reset {
  z-index: auto !important;
}
/* Overlay for ok.ru */
#vp_w.--savior-overlay-z-index-reset.media-layer.media-layer__video {
  overflow-y: hidden;
  z-index: 2147483643 !important;
}
/* Fix missing controller for tv.naver.com */
.--savior-overlay-z-index-top.rmc_controller,
.--savior-overlay-z-index-top.rmc_setting_intro,
.--savior-overlay-z-index-top.rmc_highlight,
.--savior-overlay-z-index-top.rmc_control_settings {
  z-index: 2147483644 !important;
}
/* Dirty hack for douyi.com */
.swiper-wrapper.--savior-overlay-z-index-reset .swiper-slide:not(.swiper-slide-active),
.swiper-wrapper.--savior-overlay-transform-reset .swiper-slide:not(.swiper-slide-active) {
  display: none;
}
.videoWrap + div > div {
  pointer-events: unset;
}
/* Dirty hack for fpt.ai */
.mfp-wrap.--savior-overlay-z-index-top {
  position: relative;
}
.mfp-wrap.--savior-overlay-z-index-top .mfp-close {
  display: none;
}
.mfp-wrap.--savior-overlay-z-index-top .mfp-content {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
}
section.--savior-overlay-z-index-reset>main[role="main"].--savior-overlay-z-index-reset + nav {
  z-index: -1 !important;
}
section.--savior-overlay-z-index-reset>main[role="main"].--savior-overlay-z-index-reset section.--savior-overlay-z-index-reset div.--savior-overlay-z-index-reset ~ div {
  position: relative;
}
div[class^="tiktok"].--savior-overlay-z-index-reset {
  z-index: 2147483644 !important;
}
.--savior-lightoff-fix section:not(:has([class*="--savior-overlay-"])),
.--savior-lightoff-fix section.section_video ~ section {
  z-index: -1;
  position: relative;
}
.--savior-lightoff-fix header,
.--savior-lightoff-fix footer,
.--savior-lightoff-fix .top-header,
.--savior-lightoff-fix .swiper-container,
.--savior-lightoff-fix #to_top,
.--savior-lightoff-fix #button-adblock {
  z-index: -1 !important;
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-o-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
</style><link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%0A                  &lt;svg%0A                    width=&quot;96&quot;%0A                    height=&quot;96&quot;%0A                    viewBox=&quot;0 0 96 96&quot;%0A                    fill=&quot;none&quot;%0A                    style=&quot;color:rgba(0,0,0,1);fill:rgba(255,255,255,1)&quot;%0A                    xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;%0A                  &lt;rect width=&quot;96&quot; height=&quot;96&quot;/&gt;%0A                  &lt;path d=&quot;M78.8303 41.4616C79.637 39.0379 79.9168 36.4697 79.651 33.9291C79.3852 31.3885 78.5798 28.9339 77.2888 26.7296C75.3745 23.3959 72.4506 20.7564 68.9389 19.1921C65.4273 17.6277 61.5095 17.2193 57.7507 18.0258C56.0552 16.1152 53.9712 14.5888 51.6382 13.5487C49.3051 12.5086 46.7768 11.9788 44.2224 11.9948C40.3794 11.9857 36.6328 13.1972 33.5226 15.4546C30.4125 17.7119 28.0995 20.8985 26.917 24.5551C24.4136 25.0679 22.0486 26.1094 19.9801 27.61C17.9117 29.1105 16.1876 31.0355 14.923 33.2561C12.9938 36.5809 12.1704 40.4326 12.5717 44.2556C12.973 48.0787 14.5782 51.6755 17.1558 54.5272C16.3487 56.9509 16.0686 59.519 16.3342 62.0596C16.5998 64.6003 17.405 67.0549 18.6958 69.2592C20.6102 72.593 23.5341 75.2325 27.0457 76.7968C30.5573 78.3612 34.4752 78.7695 38.2339 77.963C39.9291 79.874 42.0131 81.4007 44.3462 82.4408C46.6793 83.4809 49.2078 84.0105 51.7623 83.9941C55.6081 84.0053 59.358 82.794 62.4706 80.5351C65.5832 78.2762 67.8974 75.0865 69.079 71.4267C71.5826 70.9144 73.9478 69.8731 76.0163 68.3725C78.0849 66.8719 79.8089 64.9467 81.073 62.7257C82.9995 59.4007 83.8204 55.5498 83.4173 51.7282C83.0143 47.9065 81.4081 44.3116 78.8303 41.4616ZM51.9099 79.2873C48.3273 79.2873 45.5538 78.1873 43.1309 76.1646C43.2402 76.105 43.4318 76 43.5567 75.9233L57.8927 67.6425C58.2527 67.438 58.5517 67.1412 58.7587 66.7827C58.9658 66.4242 59.0735 66.0169 59.0708 65.6029V45.392L65.1316 48.8908C65.1633 48.9068 65.1905 48.9303 65.211 48.9593C65.2316 48.9882 65.2447 49.0217 65.2494 49.0569V65.7902C65.248 73.3826 58.9274 79.2873 51.9099 79.2873ZM22.778 66.9059C21.197 64.1743 20.6272 60.9736 21.1684 57.8643C21.2749 57.9281 21.4608 58.0417 21.5942 58.1183L35.9302 66.3991C36.2874 66.6082 36.6938 66.7184 37.1076 66.7184C37.5215 66.7184 37.9279 66.6082 38.285 66.3991L55.7877 56.293V63.2906C55.7898 63.3264 55.783 63.3621 55.7679 63.3946C55.7528 63.427 55.7298 63.4552 55.7011 63.4766L41.209 71.844C38.1091 73.6293 34.4277 74.112 30.9724 73.1862C27.517 72.2604 24.5701 70.0018 22.778 66.9059ZM19.001 35.6094C20.5754 32.8745 23.0615 30.7803 26.0242 29.6933C26.0242 29.8168 26.0242 30.0354 26.0242 30.1873V46.7489C26.0212 47.1626 26.1287 47.5696 26.3356 47.9279C26.5424 48.2862 26.8411 48.5828 27.2009 48.7872L44.7021 58.8919L38.6427 62.3907C38.6127 62.4103 38.5784 62.4222 38.5428 62.4254C38.5072 62.4287 38.4713 62.4231 38.4383 62.4092L23.9448 54.0347C20.8494 52.2436 18.5907 49.2981 17.6639 45.8441C16.7371 42.39 17.218 38.7094 19.001 35.6094ZM68.7909 47.196L51.2882 37.0899L57.3476 33.5925C57.3776 33.5729 57.4119 33.561 57.4475 33.5577C57.4832 33.5545 57.519 33.5601 57.552 33.574L72.0455 41.9442C74.2647 43.2275 76.0724 45.1162 77.2572 47.3894C78.4421 49.6626 78.955 52.2263 78.7359 54.7804C78.5169 57.3344 77.575 59.7733 76.0204 61.8116C74.4658 63.8498 72.3628 65.4032 69.9576 66.2898V49.2329C69.961 48.8204 69.8548 48.4145 69.6498 48.0566C69.4448 47.6987 69.1483 47.4017 68.7909 47.196ZM74.8219 38.1118C74.7154 38.0465 74.5295 37.9344 74.3961 37.8578L60.0601 29.577C59.7027 29.3685 59.2964 29.2586 58.8827 29.2586C58.469 29.2586 58.0627 29.3685 57.7053 29.577L40.2026 39.6831V32.6855C40.2006 32.6497 40.2075 32.6141 40.2226 32.5816C40.2377 32.5492 40.2606 32.521 40.2892 32.4995L54.7813 24.1392C57.0015 22.859 59.5404 22.2375 62.1008 22.3474C64.6613 22.4574 67.1375 23.2941 69.2398 24.7599C71.3421 26.2257 72.9836 28.2598 73.9721 30.6243C74.9606 32.9888 75.2554 35.5859 74.8219 38.1118ZM36.9082 50.5898L30.8473 47.091C30.8152 47.0756 30.7876 47.0522 30.767 47.0232C30.7464 46.9941 30.7335 46.9603 30.7295 46.9249V30.1873C30.7312 27.6237 31.463 25.1137 32.8394 22.951C34.2158 20.7882 36.1797 19.0623 38.5014 17.9752C40.823 16.8881 43.4063 16.4848 45.9488 16.8125C48.4914 17.1402 50.8879 18.1854 52.858 19.8256C52.7487 19.8853 52.5585 19.9903 52.4322 20.0669L38.0962 28.3478C37.7367 28.5525 37.4381 28.8491 37.2311 29.2073C37.0241 29.5655 36.9161 29.9723 36.9181 30.386L36.9082 50.5898ZM40.1998 43.4928L47.9952 38.9904L55.7905 43.49V52.4918L47.9952 56.9899L40.1998 52.4904V43.4928Z&quot; fill=&quot;currentColor&quot;/&gt;%0A                  &lt;/svg&gt;"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/index.eb5e9675.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/_slug_.305554a7.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/Product.fc8c41a7.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/index.f55e9c93.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/Research.5dc2e7f0.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/indexComponents.cbf37e73.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/_...slug_.b4dd8a18.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/index.be78620f.js"><link rel="modulepreload" as="script" crossorigin="" href="https://openai.com/_nuxt/Blog.529f0eb4.js"></head>
<body><div id="__nuxt"><!--[--><div class="fixed inset-0" aria-hidden="true" data-document-bg="" style="background: linear-gradient(rgb(255, 255, 255) 50%, rgb(0, 0, 0) 50%);"></div><div class="relative bg-[color:var(--gray-000)]"><!--[--><div class="simple-transition"><!--[--><div class="Page" id="research-publications-video-generation-models-as-world-simulators"><div class="relative"><!--[--><!--[--><!--[--><div aria-hidden="true" class="h-screen w-screen top-0 fixed bg-[color:rgba(0,0,0,0.75)] theme-dark-gray transition-opacity xs:hidden md:block opacity-0 invisible pointer-events-none"><div class="w-full h-[333px] bg-primary pb-gutter"><div class="container relative flex flex-col justify-end h-full"><a href="https://openai.com/" class="ui-link absolute top-[22px] left-0 z-10 w-[126px] inline-block" aria-label="OpenAI"><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1180 320" class="a-icon--logo-text flex h-32" style="width:118;height:32;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><g fill="currentColor" data-v-e1bdab2c=""><path d="m367.44 153.84c0 52.32 33.6 88.8 80.16 88.8s80.16-36.48 80.16-88.8-33.6-88.8-80.16-88.8-80.16 36.48-80.16 88.8zm129.6 0c0 37.44-20.4 61.68-49.44 61.68s-49.44-24.24-49.44-61.68 20.4-61.68 49.44-61.68 49.44 24.24 49.44 61.68z"></path><path d="m614.27 242.64c35.28 0 55.44-29.76 55.44-65.52s-20.16-65.52-55.44-65.52c-16.32 0-28.32 6.48-36.24 15.84v-13.44h-28.8v169.2h28.8v-56.4c7.92 9.36 19.92 15.84 36.24 15.84zm-36.96-69.12c0-23.76 13.44-36.72 31.2-36.72 20.88 0 32.16 16.32 32.16 40.32s-11.28 40.32-32.16 40.32c-17.76 0-31.2-13.2-31.2-36.48z"></path><path d="m747.65 242.64c25.2 0 45.12-13.2 54-35.28l-24.72-9.36c-3.84 12.96-15.12 20.16-29.28 20.16-18.48 0-31.44-13.2-33.6-34.8h88.32v-9.6c0-34.56-19.44-62.16-55.92-62.16s-60 28.56-60 65.52c0 38.88 25.2 65.52 61.2 65.52zm-1.44-106.8c18.24 0 26.88 12 27.12 25.92h-57.84c4.32-17.04 15.84-25.92 30.72-25.92z"></path><path d="m823.98 240h28.8v-73.92c0-18 13.2-27.6 26.16-27.6 15.84 0 22.08 11.28 22.08 26.88v74.64h28.8v-83.04c0-27.12-15.84-45.36-42.24-45.36-16.32 0-27.6 7.44-34.8 15.84v-13.44h-28.8z"></path><path d="m1014.17 67.68-65.28 172.32h30.48l14.64-39.36h74.4l14.88 39.36h30.96l-65.28-172.32zm16.8 34.08 27.36 72h-54.24z"></path><path d="m1163.69 68.18h-30.72v172.32h30.72z"></path><path d="m297.06 130.97c7.26-21.79 4.76-45.66-6.85-65.48-17.46-30.4-52.56-46.04-86.84-38.68-15.25-17.18-37.16-26.95-60.13-26.81-35.04-.08-66.13 22.48-76.91 55.82-22.51 4.61-41.94 18.7-53.31 38.67-17.59 30.32-13.58 68.54 9.92 94.54-7.26 21.79-4.76 45.66 6.85 65.48 17.46 30.4 52.56 46.04 86.84 38.68 15.24 17.18 37.16 26.95 60.13 26.8 35.06.09 66.16-22.49 76.94-55.86 22.51-4.61 41.94-18.7 53.31-38.67 17.57-30.32 13.55-68.51-9.94-94.51zm-120.28 168.11c-14.03.02-27.62-4.89-38.39-13.88.49-.26 1.34-.73 1.89-1.07l63.72-36.8c3.26-1.85 5.26-5.32 5.24-9.07v-89.83l26.93 15.55c.29.14.48.42.52.74v74.39c-.04 33.08-26.83 59.9-59.91 59.97zm-128.84-55.03c-7.03-12.14-9.56-26.37-7.15-40.18.47.28 1.3.79 1.89 1.13l63.72 36.8c3.23 1.89 7.23 1.89 10.47 0l77.79-44.92v31.1c.02.32-.13.63-.38.83l-64.41 37.19c-28.69 16.52-65.33 6.7-81.92-21.95zm-16.77-139.09c7-12.16 18.05-21.46 31.21-26.29 0 .55-.03 1.52-.03 2.2v73.61c-.02 3.74 1.98 7.21 5.23 9.06l77.79 44.91-26.93 15.55c-.27.18-.61.21-.91.08l-64.42-37.22c-28.63-16.58-38.45-53.21-21.95-81.89zm221.26 51.49-77.79-44.92 26.93-15.54c.27-.18.61-.21.91-.08l64.42 37.19c28.68 16.57 38.51 53.26 21.94 81.94-7.01 12.14-18.05 21.44-31.2 26.28v-75.81c.03-3.74-1.96-7.2-5.2-9.06zm26.8-40.34c-.47-.29-1.3-.79-1.89-1.13l-63.72-36.8c-3.23-1.89-7.23-1.89-10.47 0l-77.79 44.92v-31.1c-.02-.32.13-.63.38-.83l64.41-37.16c28.69-16.55 65.37-6.7 81.91 22 6.99 12.12 9.52 26.31 7.15 40.1zm-168.51 55.43-26.94-15.55c-.29-.14-.48-.42-.52-.74v-74.39c.02-33.12 26.89-59.96 60.01-59.94 14.01 0 27.57 4.92 38.34 13.88-.49.26-1.33.73-1.89 1.07l-63.72 36.8c-3.26 1.85-5.26 5.31-5.24 9.06l-.04 89.79zm14.63-31.54 34.65-20.01 34.65 20v40.01l-34.65 20-34.65-20z"></path></g></svg></a><div class="absolute top-[27px] right-0"><button aria-label="Close search panel" class="ui-link group f-ui-1 inline-block relative text-[currentColor] relative"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Close</span><!----><!--]--></span></button></div><form class="w-full flex relative" action="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M"><div class="lg:w-10/12 flex-1"><input class="block ui-input f-ui-1 z-10 w-full appearance-none border border-secondary bg-primary py-10 h-44 lg:h-48 px-14 focus:border-primary focus:outline-0 rounded-[0.2em]" type="search" autocomplete="off" placeholder="Search for anything"></div><div class="w-60 absolute top-0 bottom-0 right-0 md:relative lg:w-2/12 h-full md:ml-gutter md:w-1/6"><button aria-label="Search" class="ui-button relative inline-block px-16 xs:pt-9 xs:pb-10 lg:pt-10 lg:pb-12 h-44 lg:h-48 border border-primary text-primary hover-hover:hover:bg-inverse hover-hover:hover:text-inverse active:bg-inverse active:text-inverse md:block md:w-full xs:w-60 xs:border-0 md:border h-48 f-ui-1 f-ui-1 block absolute top-0 bottom-0 right-0 w-full lg:pt-11" type="submit"><span class="flex items-center justify-center"><!--[--><span class="flex items-center justify-center w-full">Search</span><!--]--></span></button><button aria-hidden="true" type="submit" class="hidden"> Submit </button></div></form></div></div></div><header class="top-0 left-0 w-full z-[90] py-16 md:py-22 xs:h-64 md:h-80 sticky theme-light-gray transition-all duration-300" style=""><div class="container"><div class="cols-container items-center"><div class="relative flex align-baseline xs:w-3-cols md:w-3-cols lg:w-2-cols"><div class="absolute top-[50%] left-0"><a aria-current="page" href="https://openai.com/research/video-generation-models-as-world-simulators#content" class="router-link-active router-link-exact-active ui-button relative inline-block px-16 xs:pt-9 xs:pb-10 lg:pt-10 lg:pb-12 h-44 lg:h-48 text-primary bg-primary hover-hover:hover:bg-inverse hover-hover:hover:text-inverse active:bg-inverse active:text-inverse f-ui-1 pointer-events-none outline-none -z-10 flex -translate-y-1/2 border-0 bg-primary opacity-0 transition-all focus-within:z-40 focus-within:opacity-100 focus:pointer-events-auto"><span class="flex items-center justify-center"><!--[--><!----><span class="block">Skip to main content</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-down400 a-icon--text relative only:ml-0 a-icon--no-align top-[0.05em] f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="11.75 7.76 8.7 10.81 8.7 2 7.3 2 7.3 10.81 4.25 7.76 3.26 8.75 8 13.49 12.74 8.75 11.75 7.76" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></div><a href="https://openai.com/" class="ui-link relative z-10 w-[126px] inline-block outline-none" aria-label="OpenAI"><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1180 320" class="a-icon--logo-text flex h-32" style="width:118;height:32;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><g fill="currentColor" data-v-e1bdab2c=""><path d="m367.44 153.84c0 52.32 33.6 88.8 80.16 88.8s80.16-36.48 80.16-88.8-33.6-88.8-80.16-88.8-80.16 36.48-80.16 88.8zm129.6 0c0 37.44-20.4 61.68-49.44 61.68s-49.44-24.24-49.44-61.68 20.4-61.68 49.44-61.68 49.44 24.24 49.44 61.68z"></path><path d="m614.27 242.64c35.28 0 55.44-29.76 55.44-65.52s-20.16-65.52-55.44-65.52c-16.32 0-28.32 6.48-36.24 15.84v-13.44h-28.8v169.2h28.8v-56.4c7.92 9.36 19.92 15.84 36.24 15.84zm-36.96-69.12c0-23.76 13.44-36.72 31.2-36.72 20.88 0 32.16 16.32 32.16 40.32s-11.28 40.32-32.16 40.32c-17.76 0-31.2-13.2-31.2-36.48z"></path><path d="m747.65 242.64c25.2 0 45.12-13.2 54-35.28l-24.72-9.36c-3.84 12.96-15.12 20.16-29.28 20.16-18.48 0-31.44-13.2-33.6-34.8h88.32v-9.6c0-34.56-19.44-62.16-55.92-62.16s-60 28.56-60 65.52c0 38.88 25.2 65.52 61.2 65.52zm-1.44-106.8c18.24 0 26.88 12 27.12 25.92h-57.84c4.32-17.04 15.84-25.92 30.72-25.92z"></path><path d="m823.98 240h28.8v-73.92c0-18 13.2-27.6 26.16-27.6 15.84 0 22.08 11.28 22.08 26.88v74.64h28.8v-83.04c0-27.12-15.84-45.36-42.24-45.36-16.32 0-27.6 7.44-34.8 15.84v-13.44h-28.8z"></path><path d="m1014.17 67.68-65.28 172.32h30.48l14.64-39.36h74.4l14.88 39.36h30.96l-65.28-172.32zm16.8 34.08 27.36 72h-54.24z"></path><path d="m1163.69 68.18h-30.72v172.32h30.72z"></path><path d="m297.06 130.97c7.26-21.79 4.76-45.66-6.85-65.48-17.46-30.4-52.56-46.04-86.84-38.68-15.25-17.18-37.16-26.95-60.13-26.81-35.04-.08-66.13 22.48-76.91 55.82-22.51 4.61-41.94 18.7-53.31 38.67-17.59 30.32-13.58 68.54 9.92 94.54-7.26 21.79-4.76 45.66 6.85 65.48 17.46 30.4 52.56 46.04 86.84 38.68 15.24 17.18 37.16 26.95 60.13 26.8 35.06.09 66.16-22.49 76.94-55.86 22.51-4.61 41.94-18.7 53.31-38.67 17.57-30.32 13.55-68.51-9.94-94.51zm-120.28 168.11c-14.03.02-27.62-4.89-38.39-13.88.49-.26 1.34-.73 1.89-1.07l63.72-36.8c3.26-1.85 5.26-5.32 5.24-9.07v-89.83l26.93 15.55c.29.14.48.42.52.74v74.39c-.04 33.08-26.83 59.9-59.91 59.97zm-128.84-55.03c-7.03-12.14-9.56-26.37-7.15-40.18.47.28 1.3.79 1.89 1.13l63.72 36.8c3.23 1.89 7.23 1.89 10.47 0l77.79-44.92v31.1c.02.32-.13.63-.38.83l-64.41 37.19c-28.69 16.52-65.33 6.7-81.92-21.95zm-16.77-139.09c7-12.16 18.05-21.46 31.21-26.29 0 .55-.03 1.52-.03 2.2v73.61c-.02 3.74 1.98 7.21 5.23 9.06l77.79 44.91-26.93 15.55c-.27.18-.61.21-.91.08l-64.42-37.22c-28.63-16.58-38.45-53.21-21.95-81.89zm221.26 51.49-77.79-44.92 26.93-15.54c.27-.18.61-.21.91-.08l64.42 37.19c28.68 16.57 38.51 53.26 21.94 81.94-7.01 12.14-18.05 21.44-31.2 26.28v-75.81c.03-3.74-1.96-7.2-5.2-9.06zm26.8-40.34c-.47-.29-1.3-.79-1.89-1.13l-63.72-36.8c-3.23-1.89-7.23-1.89-10.47 0l-77.79 44.92v-31.1c-.02-.32.13-.63.38-.83l64.41-37.16c28.69-16.55 65.37-6.7 81.91 22 6.99 12.12 9.52 26.31 7.15 40.1zm-168.51 55.43-26.94-15.55c-.29-.14-.48-.42-.52-.74v-74.39c.02-33.12 26.89-59.96 60.01-59.94 14.01 0 27.57 4.92 38.34 13.88-.49.26-1.33.73-1.89 1.07l-63.72 36.8c-3.26 1.85-5.26 5.31-5.24 9.06l-.04 89.79zm14.63-31.54 34.65-20.01 34.65 20v40.01l-34.65 20-34.65-20z"></path></g></svg></a></div><div class="xs:hidden lg:w-6-cols lg:block"><nav aria-label="Site"><h2 id="navHeading" class="sr-only">Site Navigation</h2><ul aria-labelledby="navHeading" class="flex flex-row flex-wrap items-baseline"><!--[--><li class="ml-24 first:ml-0 mt-1"><button class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" id="navListLabel0" aria-expanded="false"><span class="flex items-center"><!--[--><span class="flex items-center group"><span class="f-ui-1 pb-4 leading-none underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit underline-transparent">Research</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--chevron-down400 a-icon--text f-ui-1 a-icon--no-align flex" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="8 10.98 3.51 6.49 4.49 5.51 8 9.02 11.51 5.51 12.49 6.49 8 10.98" data-v-e1bdab2c=""></polygon></svg></span><!--]--></span></button><ul id="navList0" aria-labelledby="navListLabel0" class="absolute -ml-12 mt-4 p-12 transition-[background] duration-300 bg-primary text-primary hidden"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/research/overview" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Overview"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Overview</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/research" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Index"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Index</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/gpt-4" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="GPT-4"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">GPT-4</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/dall-e-3" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="DALL·E 3"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">DALL·E 3</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/sora" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Sora"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Sora</span><!----><!--]--></span></a></li><!--]--></ul></li><li class="ml-24 first:ml-0 mt-1"><button class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" id="navListLabel1" aria-expanded="false"><span class="flex items-center"><!--[--><span class="flex items-center group"><span class="f-ui-1 pb-4 leading-none underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit underline-transparent">API</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--chevron-down400 a-icon--text f-ui-1 a-icon--no-align flex" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="8 10.98 3.51 6.49 4.49 5.51 8 9.02 11.51 5.51 12.49 6.49 8 10.98" data-v-e1bdab2c=""></polygon></svg></span><!--]--></span></button><ul id="navList1" aria-labelledby="navListLabel1" class="absolute -ml-12 mt-4 p-12 transition-[background] duration-300 bg-primary text-primary hidden"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/product" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Overview"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Overview</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/pricing" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Pricing"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Pricing</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://platform.openai.com/docs/introduction" rel="noopener" target="_blank" aria-label="Docs" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Docs</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></li><li class="ml-24 first:ml-0 mt-1"><button class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" id="navListLabel2" aria-expanded="false"><span class="flex items-center"><!--[--><span class="flex items-center group"><span class="f-ui-1 pb-4 leading-none underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit underline-transparent">ChatGPT</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--chevron-down400 a-icon--text f-ui-1 a-icon--no-align flex" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="8 10.98 3.51 6.49 4.49 5.51 8 9.02 11.51 5.51 12.49 6.49 8 10.98" data-v-e1bdab2c=""></polygon></svg></span><!--]--></span></button><ul id="navList2" aria-labelledby="navListLabel2" class="absolute -ml-12 mt-4 p-12 transition-[background] duration-300 bg-primary text-primary hidden"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Overview"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Overview</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt/team" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Team"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Team</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt/enterprise" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Enterprise"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Enterprise</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt/pricing" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Pricing"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Pricing</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://chat.openai.com/auth/login" rel="noopener" target="_blank" aria-label="Try ChatGPT" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Try ChatGPT</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></li><li class="ml-24 first:ml-0 mt-1"><a href="https://openai.com/safety" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" id="navListLabel3"><span class="flex items-center"><!--[--><span class="flex items-center group"><span class="f-ui-1 pb-4 leading-none underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit underline-transparent">Safety</span><!----></span><!--]--></span></a><!----></li><li class="ml-24 first:ml-0 mt-1"><button class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" id="navListLabel4" aria-expanded="false"><span class="flex items-center"><!--[--><span class="flex items-center group"><span class="f-ui-1 pb-4 leading-none underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit underline-transparent">Company</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--chevron-down400 a-icon--text f-ui-1 a-icon--no-align flex" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="8 10.98 3.51 6.49 4.49 5.51 8 9.02 11.51 5.51 12.49 6.49 8 10.98" data-v-e1bdab2c=""></polygon></svg></span><!--]--></span></button><ul id="navList4" aria-labelledby="navListLabel4" class="absolute -ml-12 mt-4 p-12 transition-[background] duration-300 bg-primary text-primary hidden"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/about" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="About"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">About</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/blog" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Blog"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Blog</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/careers" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Careers"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Careers</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/residency" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Residency"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Residency</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/charter" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Charter"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Charter</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/security" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Security"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Security</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/customer-stories" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative" aria-label="Customer stories"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Customer stories</span><!----><!--]--></span></a></li><!--]--></ul></li><!--]--></ul></nav></div><div class="flex flex-row flex-wrap justify-end xs:w-3-cols md:w-5-cols lg:w-4-cols"><div class="hidden items-center lg:flex mt-1"><button aria-label="Search" class="ui-link group f-ui-1 inline-block relative ui-link--inherit relative"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Search</span><!----><!--]--></span></button><nav aria-label="Navigation quick links"><h2 id="quicklinksHeading" class="sr-only"> Navigation quick links </h2><ul aria-labelledby="quicklinksHeading" class="flex flex-row flex-wrap items-center"><!--[--><li class="ml-24"><a href="https://platform.openai.com/login?launch" rel="noopener" target="_blank" aria-label="Log in" class="ui-link group f-ui-1 inline-block relative ui-link--inherit"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Log in</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><li class="ml-24"><a href="https://chat.openai.com/" rel="noopener" target="_blank" aria-label="Try ChatGPT" class="ui-link group f-ui-1 inline-block pt-3 pb-5 px-10 border hover-hover:hover:bg-inverse hover-hover:hover:text-inverse hover-hover:hover:border-primary relative ui-link--inherit"><span class="flex items-center"><!--[--><!----><span class="">Try ChatGPT</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></nav></div><button aria-label="Menu" class="ui-link group f-ui-1 inline-block relative ui-link--inherit group f-ui-1 lg:hidden relative"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Menu</span><!----><!--]--></span></button></div></div></div><div aria-hidden="true" role="dialog" aria-labelledby="mobileNavModalHeading" aria-modal="true" class="invisible opacity-0 fixed top-0 right-0 bottom-0 left-0 z-[100] bg-[rgba(0,0,0,0.5)] transition-all ease-in-out"><div class="theme-dark-gray fixed top-0 right-0 bottom-0 left-0 text-primary md:left-auto md:w-[400px] lg:hidden"><div class="overflow-y-auto h-full transition-height"><h1 id="mobileNavModalHeading" tabindex="-1" class="sr-only"> Mobile Navigation </h1><div class="h-full pb-8"><div class="container flex h-full flex-col"><div class="flex w-full flex-row items-center py-16 md:pt-22"><a href="https://openai.com/" class="" aria-label="OpenAI"><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1180 320" class="a-icon--logo-text block w-[118px] h-32 md:opacity-0" style="width:118px;height:32px;" data-new="" data-v-e1bdab2c=""><g fill="currentColor" data-v-e1bdab2c=""><path d="m367.44 153.84c0 52.32 33.6 88.8 80.16 88.8s80.16-36.48 80.16-88.8-33.6-88.8-80.16-88.8-80.16 36.48-80.16 88.8zm129.6 0c0 37.44-20.4 61.68-49.44 61.68s-49.44-24.24-49.44-61.68 20.4-61.68 49.44-61.68 49.44 24.24 49.44 61.68z"></path><path d="m614.27 242.64c35.28 0 55.44-29.76 55.44-65.52s-20.16-65.52-55.44-65.52c-16.32 0-28.32 6.48-36.24 15.84v-13.44h-28.8v169.2h28.8v-56.4c7.92 9.36 19.92 15.84 36.24 15.84zm-36.96-69.12c0-23.76 13.44-36.72 31.2-36.72 20.88 0 32.16 16.32 32.16 40.32s-11.28 40.32-32.16 40.32c-17.76 0-31.2-13.2-31.2-36.48z"></path><path d="m747.65 242.64c25.2 0 45.12-13.2 54-35.28l-24.72-9.36c-3.84 12.96-15.12 20.16-29.28 20.16-18.48 0-31.44-13.2-33.6-34.8h88.32v-9.6c0-34.56-19.44-62.16-55.92-62.16s-60 28.56-60 65.52c0 38.88 25.2 65.52 61.2 65.52zm-1.44-106.8c18.24 0 26.88 12 27.12 25.92h-57.84c4.32-17.04 15.84-25.92 30.72-25.92z"></path><path d="m823.98 240h28.8v-73.92c0-18 13.2-27.6 26.16-27.6 15.84 0 22.08 11.28 22.08 26.88v74.64h28.8v-83.04c0-27.12-15.84-45.36-42.24-45.36-16.32 0-27.6 7.44-34.8 15.84v-13.44h-28.8z"></path><path d="m1014.17 67.68-65.28 172.32h30.48l14.64-39.36h74.4l14.88 39.36h30.96l-65.28-172.32zm16.8 34.08 27.36 72h-54.24z"></path><path d="m1163.69 68.18h-30.72v172.32h30.72z"></path><path d="m297.06 130.97c7.26-21.79 4.76-45.66-6.85-65.48-17.46-30.4-52.56-46.04-86.84-38.68-15.25-17.18-37.16-26.95-60.13-26.81-35.04-.08-66.13 22.48-76.91 55.82-22.51 4.61-41.94 18.7-53.31 38.67-17.59 30.32-13.58 68.54 9.92 94.54-7.26 21.79-4.76 45.66 6.85 65.48 17.46 30.4 52.56 46.04 86.84 38.68 15.24 17.18 37.16 26.95 60.13 26.8 35.06.09 66.16-22.49 76.94-55.86 22.51-4.61 41.94-18.7 53.31-38.67 17.57-30.32 13.55-68.51-9.94-94.51zm-120.28 168.11c-14.03.02-27.62-4.89-38.39-13.88.49-.26 1.34-.73 1.89-1.07l63.72-36.8c3.26-1.85 5.26-5.32 5.24-9.07v-89.83l26.93 15.55c.29.14.48.42.52.74v74.39c-.04 33.08-26.83 59.9-59.91 59.97zm-128.84-55.03c-7.03-12.14-9.56-26.37-7.15-40.18.47.28 1.3.79 1.89 1.13l63.72 36.8c3.23 1.89 7.23 1.89 10.47 0l77.79-44.92v31.1c.02.32-.13.63-.38.83l-64.41 37.19c-28.69 16.52-65.33 6.7-81.92-21.95zm-16.77-139.09c7-12.16 18.05-21.46 31.21-26.29 0 .55-.03 1.52-.03 2.2v73.61c-.02 3.74 1.98 7.21 5.23 9.06l77.79 44.91-26.93 15.55c-.27.18-.61.21-.91.08l-64.42-37.22c-28.63-16.58-38.45-53.21-21.95-81.89zm221.26 51.49-77.79-44.92 26.93-15.54c.27-.18.61-.21.91-.08l64.42 37.19c28.68 16.57 38.51 53.26 21.94 81.94-7.01 12.14-18.05 21.44-31.2 26.28v-75.81c.03-3.74-1.96-7.2-5.2-9.06zm26.8-40.34c-.47-.29-1.3-.79-1.89-1.13l-63.72-36.8c-3.23-1.89-7.23-1.89-10.47 0l-77.79 44.92v-31.1c-.02-.32.13-.63.38-.83l64.41-37.16c28.69-16.55 65.37-6.7 81.91 22 6.99 12.12 9.52 26.31 7.15 40.1zm-168.51 55.43-26.94-15.55c-.29-.14-.48-.42-.52-.74v-74.39c.02-33.12 26.89-59.96 60.01-59.94 14.01 0 27.57 4.92 38.34 13.88-.49.26-1.33.73-1.89 1.07l-63.72 36.8c-3.26 1.85-5.26 5.31-5.24 9.06l-.04 89.79zm14.63-31.54 34.65-20.01 34.65 20v40.01l-34.65 20-34.65-20z"></path></g></svg></a><button aria-label="Close" class="ui-link group f-ui-1 inline-block relative text-[currentColor] f-ui-1 group ml-auto hover-none:focus:before:invisible"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Close</span><!----><!--]--></span></button></div><nav aria-label="Site" class="mt-48 border-b border-primary"><h2 id="mobileNavHeading" class="sr-only">Site Navigation</h2><!--[--><!--[--><div class="accordion-item w-full border-t border-[currentColor] text-[currentColor]"><h3><button id="accordion32Label0" aria-expanded="false" aria-controls="accordion320" class="ui-accordion-btn relative z-10 flex w-full flex-row items-center border-0 focus:outline-none before:absolute before:-top-8 before:-bottom-8 before:-left-8 before:-right-8 before:-z-10 before:hidden before:border-4 before:border-primary before:content-[&#39;&#39;] focus:before:block f-ui-1 py-8"><span class="text-left"><!--[--><!--]--><span>Research</span></span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--plus400 a-icon--text a-icon--no-align ml-auto flex-none" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="14 7.31 8.69 7.31 8.69 2 7.31 2 7.31 7.31 2 7.31 2 8.69 7.31 8.69 7.31 14 8.69 14 8.69 8.69 14 8.69 14 7.31" data-v-e1bdab2c=""></polygon></svg></button></h3><div id="accordion320" role="region" aria-labelledby="accordion32Label0" style="height:0px;" class="-mx-10 px-10 f-body-1 overflow-hidden transition-height" aria-hidden="true"><div class="pt-8"><div class="pb-spacing-5"><ul aria-labelledby="accordion32Label0"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/research/overview" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Overview" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Overview</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/research" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Index" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Index</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/gpt-4" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="GPT-4" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">GPT-4</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/dall-e-3" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="DALL·E 3" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">DALL·E 3</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/sora" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Sora" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Sora</span><!----><!--]--></span></a></li><!--]--></ul></div></div></div></div><!--]--><!--[--><div class="accordion-item w-full border-t border-[currentColor] text-[currentColor]"><h3><button id="accordion33Label1" aria-expanded="false" aria-controls="accordion331" class="ui-accordion-btn relative z-10 flex w-full flex-row items-center border-0 focus:outline-none before:absolute before:-top-8 before:-bottom-8 before:-left-8 before:-right-8 before:-z-10 before:hidden before:border-4 before:border-primary before:content-[&#39;&#39;] focus:before:block f-ui-1 py-8"><span class="text-left"><!--[--><!--]--><span>API</span></span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--plus400 a-icon--text a-icon--no-align ml-auto flex-none" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="14 7.31 8.69 7.31 8.69 2 7.31 2 7.31 7.31 2 7.31 2 8.69 7.31 8.69 7.31 14 8.69 14 8.69 8.69 14 8.69 14 7.31" data-v-e1bdab2c=""></polygon></svg></button></h3><div id="accordion331" role="region" aria-labelledby="accordion33Label1" style="height:0px;" class="-mx-10 px-10 f-body-1 overflow-hidden transition-height" aria-hidden="true"><div class="pt-8"><div class="pb-spacing-5"><ul aria-labelledby="accordion33Label1"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/product" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Overview" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Overview</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/pricing" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Pricing" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Pricing</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://platform.openai.com/docs/introduction" rel="noopener" target="_blank" aria-label="Docs" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Docs</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></div></div></div></div><!--]--><!--[--><div class="accordion-item w-full border-t border-[currentColor] text-[currentColor]"><h3><button id="accordion34Label2" aria-expanded="false" aria-controls="accordion342" class="ui-accordion-btn relative z-10 flex w-full flex-row items-center border-0 focus:outline-none before:absolute before:-top-8 before:-bottom-8 before:-left-8 before:-right-8 before:-z-10 before:hidden before:border-4 before:border-primary before:content-[&#39;&#39;] focus:before:block f-ui-1 py-8"><span class="text-left"><!--[--><!--]--><span>ChatGPT</span></span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--plus400 a-icon--text a-icon--no-align ml-auto flex-none" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="14 7.31 8.69 7.31 8.69 2 7.31 2 7.31 7.31 2 7.31 2 8.69 7.31 8.69 7.31 14 8.69 14 8.69 8.69 14 8.69 14 7.31" data-v-e1bdab2c=""></polygon></svg></button></h3><div id="accordion342" role="region" aria-labelledby="accordion34Label2" style="height:0px;" class="-mx-10 px-10 f-body-1 overflow-hidden transition-height" aria-hidden="true"><div class="pt-8"><div class="pb-spacing-5"><ul aria-labelledby="accordion34Label2"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Overview" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Overview</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt/team" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Team" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Team</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt/enterprise" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Enterprise" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Enterprise</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/chatgpt/pricing" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Pricing" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Pricing</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://chat.openai.com/auth/login" rel="noopener" target="_blank" aria-label="Try ChatGPT" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Try ChatGPT</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></div></div></div></div><!--]--><!--[--><div class="w-full border-t border-primary py-6"><a href="https://openai.com/safety" class="ui-link group f-ui-1 inline-block relative w-full relative text-[currentColor]" aria-label="Safety"><span class="flex items-center w-full justify-between"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Safety</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-right400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4 !mr-0" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="8.75 3.27 7.77 4.25 10.83 7.31 2 7.31 2 8.69 10.83 8.69 7.77 11.75 8.75 12.73 13.48 8 8.75 3.27" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></div><!--]--><!--[--><div class="accordion-item w-full border-t border-[currentColor] text-[currentColor]"><h3><button id="accordion35Label4" aria-expanded="false" aria-controls="accordion354" class="ui-accordion-btn relative z-10 flex w-full flex-row items-center border-0 focus:outline-none before:absolute before:-top-8 before:-bottom-8 before:-left-8 before:-right-8 before:-z-10 before:hidden before:border-4 before:border-primary before:content-[&#39;&#39;] focus:before:block f-ui-1 py-8"><span class="text-left"><!--[--><!--]--><span>Company</span></span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--plus400 a-icon--text a-icon--no-align ml-auto flex-none" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="14 7.31 8.69 7.31 8.69 2 7.31 2 7.31 7.31 2 7.31 2 8.69 7.31 8.69 7.31 14 8.69 14 8.69 8.69 14 8.69 14 7.31" data-v-e1bdab2c=""></polygon></svg></button></h3><div id="accordion354" role="region" aria-labelledby="accordion35Label4" style="height:0px;" class="-mx-10 px-10 f-body-1 overflow-hidden transition-height" aria-hidden="true"><div class="pt-8"><div class="pb-spacing-5"><ul aria-labelledby="accordion35Label4"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/about" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="About" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">About</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/blog" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Blog" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Blog</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/careers" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Careers" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Careers</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/residency" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Residency" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Residency</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/charter" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Charter" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Charter</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/security" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Security" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Security</span><!----><!--]--></span></a></li><li class="mt-4 first:mt-0"><a href="https://openai.com/customer-stories" class="ui-link group f-ui-1 inline-block relative text-[currentColor]" aria-label="Customer stories" tabindex="-1"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Customer stories</span><!----><!--]--></span></a></li><!--]--></ul></div></div></div></div><!--]--><!--]--></nav><nav aria-label="Quick Links"><h2 id="mobileQuicklinksHeading" class="sr-only"> Quick Links </h2><ul aria-labelledby="mobileQuicklinksHeading"><!--[--><li class="border-b border-primary py-6"><a href="https://platform.openai.com/login?launch" rel="noopener" target="_blank" aria-label="Log in" class="ui-link group f-ui-1 inline-block relative w-full relative text-[currentColor]"><span class="flex items-center w-full justify-between"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Log in</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4 !mr-0" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><li class="border-b border-primary py-6"><a href="https://chat.openai.com/" rel="noopener" target="_blank" aria-label="Try ChatGPT" class="ui-link group f-ui-1 inline-block relative w-full relative text-[currentColor]"><span class="flex items-center w-full justify-between"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Try ChatGPT</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4 !mr-0" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></nav><div class="mt-auto pt-24 pb-40"><form class="relative" action="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M"><input id="mobileSearch" autocomplete="off" type="search" class="f-ui-1 w-full rounded-[0.2em] outline-none appearance-none border border-secondary autofill:bg-primary bg-primary h-44 pr-100 pt-10 pb-11 pl-14 focus:border-primary focus:outline-0" placeholder="Search for anything"><div class="absolute right-16 top-10"><button class="ui-link group f-ui-1 inline-block relative text-[currentColor] f-ui-1 group"><span class="flex items-center"><!--[--><span class="sr-only">Search</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--search400 a-icon--text" style="width:1em;height:1em;" data-new="" data-v-e1bdab2c=""><path fill="currentColor" d="M14.49,13.51l-3.51-3.51c.63-.84,1.02-1.87,1.02-3,0-2.76-2.24-5-5-5S2,4.24,2,7s2.24,5,5,5c1.13,0,2.16-.39,3-1.02l3.51,3.51,.98-.98ZM3.38,7c0-2,1.62-3.62,3.62-3.62s3.62,1.62,3.62,3.62-1.62,3.62-3.62,3.62-3.62-1.62-3.62-3.62Z" data-v-e1bdab2c=""></path></svg><!--]--></span></button><button aria-hidden="true" type="submit" class="hidden"> Submit </button></div></form></div></div></div></div></div></div></header><!----><!--]--><div class="theme-theme-null pb-spacing-7"><div class="ui-hero" style=""><div differencemode="false"><div class="container -top-64 md:-top-80 relative"><div class="cols-container"><!--[--><div class="xs:mt-[180px] md:w-8-cols md:mt-[200px] lg:ml-2-cols lg:w-10-cols lg:mt-[256px]"><div class="lg:pr-48"><div class="relative"><a href="https://openai.com/research" class="ui-link group f-ui-1 inline-block relative text-[currentColor] !absolute top-0 left-0 -translate-y-[calc(100%+8px)]" aria-label="Research"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-text-primary">Research</span><!----><!--]--></span></a><h1 class="f-display-3">Video generation models as world simulators</h1></div></div></div><div class="lg-w-7-cols mt-spacing-4 md:w-8-cols lg:ml-2-cols"><div class="f-summary-1 ui-richtext"><div><p>We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.<br class="softbreak"></p></div></div></div><!--]--></div></div><!----></div></div><div class="container"><div class="xs:mt-96 md:mt-112 lg:mt-128 w-full border-t border-primary pt-8"><div class="cols-container"><div class="xs:w-6-cols md:w-2-cols lg:w-2-cols"><span class="f-meta-2">February 15, 2024</span></div><div class="xs:w-6-cols xs:mt-spacing-4 md:w-3-cols md:mt-0 lg:w-5-cols"><!----><h3 id="metaLinkListHeading" class="sr-only">More resources</h3><ul aria-labelledby="metaLinkListHeading"><!--[--><li class="mt-4 first:mt-0"><a href="https://openai.com/sora" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="View Sora overview"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">View Sora overview</span><!----><!--]--></span></a></li><!--]--></ul></div><div class="md:w-3-cols lg:w-5-cols mt-spacing-4 xs:w-6-cols md:mt-0 md:flex md:flex-row"><div class="md:w-1/2 only:w-full"><!--[--><span class="inline-block"><a href="https://openai.com/research?topics=video-generation" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Video generation"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Video generation</span><!----><!--]--></span></a><!--[-->,&nbsp;<!--]--></span><span class="inline-block"><a href="https://openai.com/research?models=sora" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Sora"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Sora</span><!----><!--]--></span></a><!--[-->,&nbsp;<!--]--></span><span class="inline-block"><a href="https://openai.com/research?contentTypes=milestone" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Milestone"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Milestone</span><!----><!--]--></span></a><!--[-->,&nbsp;<!--]--></span><span class="inline-block"><a href="https://openai.com/research?contentTypes=release" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Release"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Release</span><!----><!--]--></span></a><!----></span><!--]--></div><!----></div></div></div></div><!----><!----></div><div class="relative bg-[color:white]" style=""><!----><div id="content" class="ui-blocks ui-blocks--padded" style=""><!--[--><!--[--><div class="ui-block ui-block--code-snippet" id="InlineVideo-0" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div><video controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/title_0.mp4"></video><!----></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>This technical report focuses on (1) our method for turning visual data of all types into a unified representation that enables large-scale training of generative models, and (2) qualitative evaluation of Sora’s capabilities and limitations. Model and implementation details are not included in this report.</p><p>Much prior work has studied generative modeling of video data using a variety of methods, including recurrent networks,<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-1" id="ref-1-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">1</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-2" id="ref-2-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">2</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-3" id="ref-3-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">3</a></sup><!----></span> generative adversarial networks,<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-4" id="ref-4-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">4</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-5" id="ref-5-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">5</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-6" id="ref-6-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">6</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-7" id="ref-7-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">7</a></sup><!----></span> autoregressive transformers,<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-8" id="ref-8-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">8</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-9" id="ref-9-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">9</a></sup><!----></span> and diffusion models.<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-10" id="ref-10-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">10</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-11" id="ref-11-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">11</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-12" id="ref-12-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">12</a></sup><!----></span> These works often focus on a narrow category of visual data, on shorter videos, or on videos of a fixed size. Sora is a generalist model of visual data—it can generate videos and images spanning diverse durations, aspect ratios and resolutions, up to a full minute of high definition video.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="turning-visual-data-into-patches" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Turning visual data into patches</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>We take inspiration from large language models which acquire generalist capabilities by training on internet-scale data.<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-13" id="ref-13-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">13</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-14" id="ref-14-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">14</a></sup><!----></span> The success of the LLM paradigm is enabled in part by the use of tokens<em> </em>that elegantly unify diverse modalities of text—code, math and various natural languages. In this work, we consider how generative models of visual data can inherit such benefits. Whereas LLMs have text tokens, Sora has visual <em>patches</em>. Patches have previously been shown to be an effective representation for models of visual data.<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-15" id="ref-15-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">15</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-16" id="ref-16-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">16</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-17" id="ref-17-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">17</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-18" id="ref-18-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">18</a></sup><!----></span> We find that patches are a highly-scalable and effective representation for training generative models on diverse types of videos and images.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--image" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><figure class=""><div class=""><img src="./Video generation models as world simulators_files/figure-patches.png" width="2031" height="378" alt="Figure Patches" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" srcset="https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false" class="w-full"></div><figcaption class="f-caption-1 relative mt-8"><!--[--><!--]--></figcaption></figure></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>At a high level, we turn videos into patches by first compressing videos into a lower-dimensional latent space,<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-19" id="ref-19-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">19</a></sup><!----></span> and subsequently decomposing the representation into spacetime patches.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="video-compression-network" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Video compression network</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>We train a network that reduces the dimensionality of visual data.<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-20" id="ref-20-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">20</a></sup><!----></span> This network takes raw video as input and outputs a latent representation that is compressed both temporally and spatially. Sora is trained on and subsequently generates videos within this compressed latent space. We also train a corresponding decoder model that maps generated latents back to pixel space.</p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="spacetime-latent-patches" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Spacetime latent patches</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Given a compressed input video, we extract a sequence of spacetime patches which act as transformer tokens. This scheme works for images too since images are just videos with a single frame. Our patch-based representation enables Sora to train on videos and images of variable resolutions, durations and aspect ratios. At inference time, we can control the size of generated videos by arranging randomly-initialized patches in an appropriately-sized grid.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="scaling-transformers-for-video-generation" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Scaling transformers for video generation</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Sora is a diffusion model<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-21" id="ref-21-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">21</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-22" id="ref-22-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">22</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-23" id="ref-23-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">23</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-24" id="ref-24-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">24</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-25" id="ref-25-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">25</a></sup><!----></span>; given input noisy patches (and conditioning information like text prompts), it’s trained to predict the original “clean” patches. Importantly, Sora is a diffusion <em>transformer</em>.<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-26" id="ref-26-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">26</a></sup><!----></span> Transformers have demonstrated remarkable scaling properties across a variety of domains, including language modeling,<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-13" id="ref-13-1" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">13</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-14" id="ref-14-1" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">14</a></sup><!----></span> computer vision,<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-15" id="ref-15-1" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">15</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-16" id="ref-16-1" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">16</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-17" id="ref-17-1" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">17</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-18" id="ref-18-1" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">18</a></sup><!----></span> and image generation.<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-27" id="ref-27-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">27</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-28" id="ref-28-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">28</a>,</sup><!----></span><span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-29" id="ref-29-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">29</a></sup><!----></span><br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--image" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><figure class=""><div class=""><img src="./Video generation models as world simulators_files/figure-diffusion.png" width="1261" height="312" alt="Figure Diffusion" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" srcset="https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false" class="w-full"></div><figcaption class="f-caption-1 relative mt-8"><!--[--><!--]--></figcaption></figure></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>In this work, we find that diffusion transformers scale effectively as video models as well. Below, we show a comparison of video samples with fixed seeds and inputs as training progresses. Sample quality improves markedly as training compute increases.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-14" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="w-full"><div layout="full-grid"><div class="grid md:grid-cols-3 grid-flow-row gap-[var(--inner-gutter)]"><!--[--><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/scaling_0.mp4"></video><div class="f-caption-1 ui-richtext relative mt-8">Base compute</div></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/scaling_1.mp4"></video><div class="f-caption-1 ui-richtext relative mt-8">4x compute</div></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/scaling_2.mp4"></video><div class="f-caption-1 ui-richtext relative mt-8">32x compute</div></div></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="variable-durations-resolutions-aspect-ratios" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Variable durations, resolutions, aspect ratios</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Past approaches to image and video generation typically resize, crop or trim videos to a standard size—e.g., 4 second videos at 256x256 resolution. We find that instead training on data at its native size provides several benefits.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-6" id="sampling-flexibility" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h3 class="f-heading-4">Sampling flexibility</h3></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-3"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Sora can sample widescreen 1920x1080p videos, vertical 1080x1920 videos and everything inbetween. This lets Sora create content for different devices directly at their native aspect ratios. It also lets us quickly prototype content at lower sizes before generating at full resolution—all with the same model.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraTurtles-19" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="w-full"><section class="flex flex-col md:flex-row gap-[var(--inner-gutter)] md:aspect-[2942/854]" title="Where are the" layout="full-grid"><div class="w-full md:h-full aspect-[480/854] bg-[color:var(--gray-200)]"><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/sampling_0.mp4"></video><!----></div></div><div class="w-full md:h-full aspect-square bg-[color:var(--gray-200)]"><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/sampling_1.mp4"></video><!----></div></div><div class="w-full md:h-full aspect-video bg-[color:var(--gray-200)]"><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/sampling_2.mp4"></video><!----></div></div></section></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="improved-framing-and-composition" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h3 class="f-heading-4">Improved framing and composition</h3></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-3"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>We empirically find that training on videos at their native aspect ratios improves composition and framing. We compare Sora against a version of our model that crops all training videos to be square, which is common practice when training generative models. The model&nbsp;trained on square crops (left) sometimes generates videos where the subject is only partially in view. In comparison, videos from Sora (right) have improved framing.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-22" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/sampling_3.mp4"></video><!----></div></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/sampling_4.mp4"></video><!----></div></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="language-understanding" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Language understanding</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Training text-to-video generation systems requires a large amount of videos with corresponding text captions. We apply the re-captioning technique introduced in DALL·E 3<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-30" id="ref-30-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">30</a></sup><!----></span> to videos. We first train a highly descriptive captioner model and then use it to produce text captions for all videos in our training set. We find that training on highly descriptive video captions improves text fidelity as well as the overall quality of videos.</p><p>Similar to DALL·E 3, we also leverage GPT to turn short user prompts into longer detailed captions that are sent to the video model. This enables Sora to generate high quality videos that accurately follow user prompts.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraMadlib-25" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class=""><div class="w-full"><div class="w-full" layout="full-bleed"><section class="bg-[color:var(--gray-300)] scroll-mt-64 md:scroll-mt-80 relative"><div class="py-spacing-5 lg:py-spacing-7 f-body-1"><div class="container"><div class="grid-layout"><div class="md:grid-col-start-2 lg:grid-col-start-1 md:grid-col-span-4 lg:grid-col-span-5 grid-col-span-8"><div class="flex flex-col items-start grow"><div class="flex flex-col items-start grow w-full"><div class="w-full md:pr-12 lg:pr-24"><!--[--><div class="inline mr-8 md:text-xl lg:text-3xl md:text-right text-secondary leading-relaxed"><div class="inline-block"><div class="relative inline-block"><div class="opacity-0 font-bold whitespace-nowrap">a woman</div><select class="focus:outline-none focus-visible:ring focus-visible:ring-offset-border-primary appearance-none bg-transparent border-none underline p-0 absolute left-0 md:text-xl lg:text-3xl leading-relaxed font-bold top-0"><option value="0">a woman</option><option value="1">an old man</option><option value="2">a toy robot</option><option value="3">an adorable kangaroo</option></select></div></div></div><div class="inline mr-8 md:text-xl lg:text-3xl md:text-right text-secondary leading-relaxed"><div class="inline-block"> wearing </div></div><div class="inline mr-8 md:text-xl lg:text-3xl md:text-right text-secondary leading-relaxed"><div class="inline-block"><div class="relative inline-block"><div class="opacity-0 font-bold whitespace-nowrap">blue jeans and a white t-shirt</div><select class="focus:outline-none focus-visible:ring focus-visible:ring-offset-border-primary appearance-none bg-transparent border-none underline p-0 absolute left-0 md:text-xl lg:text-3xl leading-relaxed font-bold top-0"><option value="0">blue jeans and a white t-shirt</option><option value="1">a green dress and a sun hat</option><option value="2">purple overalls and cowboy boots</option></select></div></div></div><div class="inline mr-8 md:text-xl lg:text-3xl md:text-right text-secondary leading-relaxed"><div class="inline-block"> taking a pleasant stroll in </div></div><div class="inline mr-8 md:text-xl lg:text-3xl md:text-right text-secondary leading-relaxed"><div class="inline-block"><div class="relative inline-block"><div class="opacity-0 font-bold whitespace-nowrap">Johannesburg, South Africa</div><select class="focus:outline-none focus-visible:ring focus-visible:ring-offset-border-primary appearance-none bg-transparent border-none underline p-0 absolute left-0 md:text-xl lg:text-3xl leading-relaxed font-bold top-0"><option value="0">Mumbai, India</option><option value="1">Johannesburg, South Africa</option><option value="2">Antarctica</option></select></div></div></div><div class="inline mr-8 md:text-xl lg:text-3xl md:text-right text-secondary leading-relaxed"><div class="inline-block"> during </div></div><div class="inline mr-8 md:text-xl lg:text-3xl md:text-right text-secondary leading-relaxed"><div class="inline-block"><div class="relative inline-block"><div class="opacity-0 font-bold whitespace-nowrap">a winter storm</div><select class="focus:outline-none focus-visible:ring focus-visible:ring-offset-border-primary appearance-none bg-transparent border-none underline p-0 absolute left-0 md:text-xl lg:text-3xl leading-relaxed font-bold top-0"><option value="0">a beautiful sunset</option><option value="1">a winter storm</option><option value="2">a colorful festival</option></select></div></div></div><!--]--></div></div></div></div><div class="md:grid-col-span-7 md:grid-col-start-6 grid-col-span-8"><div class="h-full w-full object-cover"><video autoplay="" loop="" playsinline="true" src="https://cdn.openai.com/tmp/s/a-woman-wearing-blue-jeans-and-a-white-t-shirt-taking-a-pleasant-stroll-in-Johannesburg-South-Africa-during-a-winter-storm.mp4"></video><!----></div></div></div></div></div></section></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="prompting-with-images-and-videos" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Prompting with images and videos</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>All of the results above and in our <a href="https://openai.com/sora" rel="noopener noreferrer">landing page</a> show text-to-video samples. But Sora can also be prompted with other inputs, such as pre-existing images or video. This capability enables Sora to perform a wide range of image and video editing tasks—creating perfectly looping video, animating static images, extending videos forwards or backwards in time, etc.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-6" id="animating-dall-e-images" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h3 class="f-heading-4">Animating DALL·E images</h3></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-3"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Sora is capable of generating videos provided an image and prompt as input. Below we show example videos generated based on DALL·E 2<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-31" id="ref-31-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">31</a></sup><!----></span> and DALL·E 3<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-30" id="ref-30-1" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">30</a></sup><!----></span> images.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-30" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/prompting_0.png"><!----></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/prompting_1.mp4"></video><!----></div></div></div><!--]--><div class="mt-[calc(-1*var(--inner-gutter))] pt-8 f-caption-1 col-span-full">A Shiba Inu dog wearing a beret and black turtleneck.</div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-31" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/prompting_2.png"><!----></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/prompting_3.mp4"></video><!----></div></div></div><!--]--><div class="mt-[calc(-1*var(--inner-gutter))] pt-8 f-caption-1 col-span-full">Monster Illustration in flat design style of a diverse family of monsters. The group includes a furry brown monster, a sleek black monster with antennas, a spotted green monster, and a tiny polka-dotted monster, all interacting in a playful environment.</div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-32" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/prompting_4.png"><!----></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/prompting_5.mp4"></video><!----></div></div></div><!--]--><div class="mt-[calc(-1*var(--inner-gutter))] pt-8 f-caption-1 col-span-full">An image of a realistic cloud that spells “SORA”.</div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-33" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/prompting_6.png"><!----></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/prompting_7.mp4"></video><!----></div></div></div><!--]--><div class="mt-[calc(-1*var(--inner-gutter))] pt-8 f-caption-1 col-span-full">In an ornate, historical hall, a massive tidal wave peaks and begins to crash. Two surfers, seizing the moment, skillfully navigate the face of the wave.</div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="extending-generated-videos" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h3 class="f-heading-4">Extending generated videos</h3></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-3"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Sora is also capable of extending videos, either forward or backward in time. Below are four videos that were all extended backward in time starting from a segment of a generated video. As a result, each of the four videos starts different from the others, yet all four videos lead to the same ending.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraSync-36" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div class="w-full flex flex-col gap-8 py-24" layout="auto"><div class="grid grid-cols-3 gap-4"><!--[--><div class="aspect-w-16 aspect-h-9 overflow-hidden"><video class="w-full h-full object-cover"><source src="https://cdn.openai.com/tmp/s/extend_1.mp4" type="video/mp4"></video></div><div class="aspect-w-16 aspect-h-9 overflow-hidden"><video class="w-full h-full object-cover"><source src="https://cdn.openai.com/tmp/s/extend_2.mp4" type="video/mp4"></video></div><div class="aspect-w-16 aspect-h-9 overflow-hidden"><video class="w-full h-full object-cover"><source src="https://cdn.openai.com/tmp/s/extend_4.mp4" type="video/mp4"></video></div><!--]--></div><div class="flex items-center gap-8"><span class="tabular-nums text-sm">00:00</span><input type="range" min="0" max="20" step="0.1" value="0" class="flex-1"><span class="tabular-nums text-sm">00:20</span></div><button class="text-primary/80 hover:text-primary/100 p-8 rounded-full inline-block mx-auto bg-interactive-primary-hover"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.24182 2.32181C3.3919 2.23132 3.5784 2.22601 3.73338 2.30781L12.7334 7.05781C12.8974 7.14436 13 7.31457 13 7.5C13 7.68543 12.8974 7.85564 12.7334 7.94219L3.73338 12.6922C3.5784 12.774 3.3919 12.7687 3.24182 12.6782C3.09175 12.5877 3 12.4252 3 12.25V2.75C3 2.57476 3.09175 2.4123 3.24182 2.32181ZM4 3.57925V11.4207L11.4288 7.5L4 3.57925Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>We can use this method to extend a video both forward and backward to produce a seamless infinite loop.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="InlineVideo-38" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div><video controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/bike_1.mp4"></video><!----></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="video-to-video-editing" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h3 class="f-heading-4">Video-to-video editing</h3></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-3"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Diffusion models have enabled a plethora of methods for editing images and videos from text prompts. Below we apply one of these methods, SDEdit,<span class="ui-fn"><sup class="inline-block min-w-[1.5ch] indent-0 not-italic [em_&amp;]:indent-2"><a aria-describedby="referencesTitle" href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#fn-32" id="ref-32-0" class="target:bg-[color:var(--background-interactive-primary-hover)] decoration-transparent">32</a></sup><!----></span> to Sora. This technique enables Sora to transform&nbsp; the styles and environments of input videos zero-shot.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoTwoUpSync-41" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div class="w-full flex flex-col gap-32 py-24" layout="auto"><div class="w-full grid grid-cols-2 gap-24"><div class="flex flex-col aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><div class="f-caption-1 ui-richtext relative mb-8">Input video</div><video class="w-full h-full object-cover"><source src="https://cdn.openai.com/tmp/s/edit/base.mp4" type="video/mp4"></video></div><div class="empty:hidden"><div class=""><select class="whitespace-pre-wrap focus:outline-none focus:ring focus:ring-offset-border-primary appearance-none bg-transparent border-none underline p-0 font-bold f-caption-1 ui-richtext relative mb-8" value="0"><!--[--><option value="0" selected="">change the setting to be in a lush jungle</option><option value="1">change the setting to the 1920s with an old school car. make sure to keep the red color</option><option value="2">make it go underwater</option><option value="3">change the video setting to be different than a mountain? perhaps joshua tree?</option><option value="4">put the video in space with a rainbow road</option><option value="5">keep the video the same but make it be winter</option><option value="6">make it in claymation animation style</option><option value="7">recreate in the style of a charcoal drawing, making sure to be black and white</option><option value="8">change the setting to be cyberpunk</option><option value="9">change the video to a medieval theme</option><option value="10">make it have dinosaurs</option><option value="11">rewrite the video in a pixel art style</option><!--]--></select></div><!--[--><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><video class="w-full h-full object-cover"><source src="https://cdn.openai.com/tmp/s/edit/0.mp4" type="video/mp4"></video></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><div class="aspect-w-16 aspect-h-9 overflow-hidden empty:hidden"><!----></div><!--]--></div></div><div class="flex flex-col gap-24 w-full"><button class="text-primary/80 hover:text-primary/100 p-8 rounded-full inline-block mx-auto bg-interactive-primary-hover"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.24182 2.32181C3.3919 2.23132 3.5784 2.22601 3.73338 2.30781L12.7334 7.05781C12.8974 7.14436 13 7.31457 13 7.5C13 7.68543 12.8974 7.85564 12.7334 7.94219L3.73338 12.6922C3.5784 12.774 3.3919 12.7687 3.24182 12.6782C3.09175 12.5877 3 12.4252 3 12.25V2.75C3 2.57476 3.09175 2.4123 3.24182 2.32181ZM4 3.57925V11.4207L11.4288 7.5L4 3.57925Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="connecting-videos" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h3 class="f-heading-4">Connecting videos</h3></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-3"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>We can also use Sora to gradually interpolate between two input videos, creating seamless transitions between videos with entirely different subjects and scene compositions. In the examples below, the videos in the center interpolate between the corresponding videos on the left and right.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-44" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="w-full"><div layout="full-grid"><div class="grid md:grid-cols-3 grid-flow-row gap-[var(--inner-gutter)]"><!--[--><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/a0.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/a1.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/a2.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/b0.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/b1.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/b2.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/c0.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/c1.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/c2.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/d0.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/d1.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/d2.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/e0.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/e1.mp4"></video><!----></div></div></div><div class=""><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/interp/e2.mp4"></video><!----></div></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="image-generation-capabilities" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Image generation capabilities</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Sora is also capable of generating images. We do this by arranging patches of Gaussian noise in a spatial grid with a temporal extent of one frame. The model can generate images of variable sizes—up to 2048x2048 resolution.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-47" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/image_0.png"><span class="f-caption-1 mt-8">Close-up portrait shot of a woman in autumn, extreme detail, shallow depth of field</span></div></div><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/image_1.png"><span class="f-caption-1 mt-8">Vibrant coral reef teeming with colorful fish and sea creatures</span></div></div><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/image_2.png"><span class="f-caption-1 mt-8">Digital art of a young tiger under an apple tree in a matte painting style with gorgeous details</span></div></div><div class="col-span-6 md:col-span-3"><div class="flex flex-col"><img loading="lazy" src="./Video generation models as world simulators_files/image_3.png"><span class="f-caption-1 mt-8">A snowy mountain village with cozy cabins and a northern lights display, high detail and photorealistic dslr, 50mm f/1.2</span></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="emerging-simulation-capabilities" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Emerging simulation capabilities</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-4"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>We find that video models exhibit a number of interesting emergent capabilities when trained at scale. These capabilities enable Sora to simulate some aspects of people, animals and environments from the physical world. These properties emerge without any explicit inductive biases for 3D, objects, etc.—they are purely phenomena of scale.</p><p><strong>3D consistency.</strong> Sora can generate videos with dynamic camera motion. As the camera shifts and rotates, people and scene elements move consistently through three-dimensional space.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-50" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_0.mp4"></video><!----></div></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_1.mp4"></video><!----></div></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p><strong>Long-range coherence and object permanence. </strong>A significant challenge for video generation systems has been maintaining temporal consistency when sampling long videos. We find that Sora is often, though not always, able to effectively model both short- and long-range dependencies. For example, our model can persist people, animals and objects even when they are occluded or leave the frame. Likewise, it can generate multiple shots of the same character in a single sample, maintaining their appearance throughout the video.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-52" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_2.mp4"></video><!----></div></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_3.mp4"></video><!----></div></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p><strong>Interacting with the world.</strong> Sora can sometimes simulate actions that affect the state of the world in simple ways. For example, a painter can leave new strokes along a canvas that persist over time, or a man can eat a burger and leave bite marks.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-54" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_4.mp4"></video><!----></div></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_5.mp4"></video><!----></div></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p><strong>Simulating digital worlds.</strong> Sora is also able to simulate artificial processes–one example is video games. Sora can simultaneously control the player in Minecraft with a basic policy while also rendering the world and its dynamics in high fidelity. These capabilities can be elicited zero-shot by prompting Sora with captions mentioning “Minecraft.”<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="SoraVideoGrid-56" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div layout="auto"><div class="grid-layout"><!--[--><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_6.mp4"></video><!----></div></div></div><div class="col-span-6 md:col-span-3"><div><div><video autoplay="" controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/simulation_7.mp4"></video><!----></div></div></div><!--]--><!----></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>These capabilities suggest that continued scaling of video models is a promising path towards the development of highly-capable simulators of the physical and digital world, and the objects, animals and people that live within them.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--heading" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7" id="discussion" data-heading=""><div class="container"><div class="cols-container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols"><h2 class="f-heading-3">Discussion</h2></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="InlineVideo-59" style=""><!----><!----><!----><!----><div class="mt-spacing-6"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div><video controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/discussion_0.mp4"></video><!----></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>Sora currently exhibits numerous limitations as a simulator. For example, it does not accurately model the physics of many basic interactions, like glass shattering. Other interactions, like eating food, do not always yield correct changes in object state. We enumerate other common failure modes of the model—such as incoherencies that develop in long duration samples or spontaneous appearances of objects—in our <a href="https://openai.com/sora" rel="noopener noreferrer">landing page</a>.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--code-snippet" id="InlineVideo-61" style=""><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="md:w-6-cols lg:ml-2-cols lg:w-6-cols relative"><div><video controls="" loop="" muted="" playsinline="true" src="https://cdn.openai.com/tmp/s/discussion_1.mp4"></video><!----></div></div></div></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--[--><div class="ui-block ui-block--text" style=""><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div class="mt-spacing-7"><div class="container"><div class="cols-container"><div class="xs:w-12-cols md:w-6-cols lg:ml-2-cols lg:w-6-cols relative f-body-2"><div class="ui-richtext"><div><p>We believe the capabilities Sora has today demonstrate that continued scaling of video models is a promising path towards the development of capable simulators of the physical and digital world, and the objects, animals and people that live within them.<br class="softbreak"></p></div></div></div></div></div></div><!----><!----><!----><!----><!----><!----><!----></div><!--]--><!--]--></div></div><!----><div class="container"><div class="mt-spacing-7 border-t border-primary pt-8 lg:pt-12"><div class="cols-container"><div class="xs:w-6-cols md:w-2-cols lg:w-2-cols"><h3 id="referencesTitle" class="f-subhead-2">References</h3></div><div class="mt-40 xs:w-6-cols md:w-6-cols md:mt-0 lg:w-10-cols"><div class="f-body-1"><ol aria-labelledby="referencesTitle" class="-mt-spacing-3 list-none lg:columns-2 lg:gap-[var(--inner-gutter)]"><li id="fn-1" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Srivastava, Nitish, Elman Mansimov, and Ruslan Salakhudinov. "Unsupervised learning of video representations using lstms." International conference on machine learning. PMLR, 2015.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-1-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-2" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Chiappa, Silvia, et al. "Recurrent environment simulators." arXiv preprint arXiv:1704.02254 (2017).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-2-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-3" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Ha, David, and Jürgen Schmidhuber. "World models." arXiv preprint arXiv:1803.10122 (2018).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-3-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-4" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Vondrick, Carl, Hamed Pirsiavash, and Antonio Torralba. "Generating videos with scene dynamics." Advances in neural information processing systems 29 (2016).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-4-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-5" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Tulyakov, Sergey, et al. "Mocogan: Decomposing motion and content for video generation." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-5-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-6" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Clark, Aidan, Jeff Donahue, and Karen Simonyan. "Adversarial video generation on complex datasets." arXiv preprint arXiv:1907.06571 (2019).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-6-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-7" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Brooks, Tim, et al. "Generating long videos of dynamic scenes." Advances in Neural Information Processing Systems 35 (2022): 31769-31781.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-7-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-8" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Yan, Wilson, et al. "Videogpt: Video generation using vq-vae and transformers." arXiv preprint arXiv:2104.10157 (2021).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-8-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-9" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Wu, Chenfei, et al. "Nüwa: Visual synthesis pre-training for neural visual world creation." European conference on computer vision. Cham: Springer Nature Switzerland, 2022.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-9-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-10" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Ho, Jonathan, et al. "Imagen video: High definition video generation with diffusion models." <em>arXiv preprint arXiv:2210.02303</em> (2022).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-10-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-11" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Blattmann, Andreas, et al. "Align your latents: High-resolution video synthesis with latent diffusion models." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-11-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-12" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Gupta, Agrim, et al. "Photorealistic video generation with diffusion models." arXiv preprint arXiv:2312.06662 (2023).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-12-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-13" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Vaswani, Ashish, et al. "Attention is all you need." <em>Advances in neural information processing systems</em> 30 (2017).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-13-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a><a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-13-1" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-14" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Brown, Tom, et al. "Language models are few-shot learners." <em>Advances in neural information processing systems</em> 33 (2020): 1877-1901.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-14-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a><a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-14-1" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-15" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Dosovitskiy, Alexey, et al. "An image is worth 16x16 words: Transformers for image recognition at scale." <em>arXiv preprint arXiv:2010.11929</em> (2020).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-15-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a><a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-15-1" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-16" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Arnab, Anurag, et al. "Vivit: A video vision transformer." <em>Proceedings of the IEEE/CVF international conference on computer vision</em>. 2021.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-16-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a><a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-16-1" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-17" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>He, Kaiming, et al. "Masked autoencoders are scalable vision learners." <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 2022.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-17-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a><a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-17-1" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-18" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Dehghani, Mostafa, et al. "Patch n'Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution." <em>arXiv preprint arXiv:2307.06304</em> (2023).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-18-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a><a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-18-1" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-19" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Rombach, Robin, et al. "High-resolution image synthesis with latent diffusion models." <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 2022.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-19-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-20" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Kingma, Diederik P., and Max Welling. "Auto-encoding variational bayes." <em>arXiv preprint arXiv:1312.6114</em> (2013).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-20-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-21" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Sohl-Dickstein, Jascha, et al. "Deep unsupervised learning using nonequilibrium thermodynamics." <em>International conference on machine learning</em>. PMLR, 2015.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-21-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-22" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Ho, Jonathan, Ajay Jain, and Pieter Abbeel. "Denoising diffusion probabilistic models." <em>Advances in neural information processing systems</em> 33 (2020): 6840-6851.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-22-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-23" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Nichol, Alexander Quinn, and Prafulla Dhariwal. "Improved denoising diffusion probabilistic models." <em>International Conference on Machine Learning</em>. PMLR, 2021.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-23-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-24" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Dhariwal, Prafulla, and Alexander Quinn Nichol. "Diffusion Models Beat GANs on Image Synthesis." <em>Advances in Neural Information Processing Systems</em>. 2021.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-24-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-25" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Karras, Tero, et al. "Elucidating the design space of diffusion-based generative models." <em>Advances in Neural Information Processing Systems</em> 35 (2022): 26565-26577.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-25-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-26" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Peebles, William, and Saining Xie. "Scalable diffusion models with transformers." <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 2023.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-26-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-27" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Chen, Mark, et al. "Generative pretraining from pixels." <em>International conference on machine learning</em>. PMLR, 2020.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-27-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-28" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Ramesh, Aditya, et al. "Zero-shot text-to-image generation." <em>International Conference on Machine Learning</em>. PMLR, 2021.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-28-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-29" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Yu, Jiahui, et al. "Scaling autoregressive models for content-rich text-to-image generation." <em>arXiv preprint arXiv:2206.10789</em> 2.3 (2022): 5.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-29-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-30" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Betker, James, et al. "Improving image generation with better captions." <em>Computer Science. https://cdn.openai.com/papers/dall-e-3. pdf</em> 2.3 (2023): 8<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-30-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a><a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-30-1" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-31" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Ramesh, Aditya, et al. "Hierarchical text-conditional image generation with clip latents." <em>arXiv preprint arXiv:2204.06125</em> 1.2 (2022): 3.<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-31-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li><li id="fn-32" class="w-full target:bg-[color:var(--background-interactive-primary-hover)] mt-spacing-3 relative inline-block pl-48 before:absolute before:top-0 before:left-0 lg:pr-32 md:scroll-mt-96 scroll-mt-80 [counter-increment:step-counter] before:content-[counter(step-counter)]"><div class="[&amp;_a]:break-all ui-richtext"><p>Meng, Chenlin, et al. "Sdedit: Guided image synthesis and editing with stochastic differential equations." <em>arXiv preprint arXiv:2108.01073</em> (2021).<a href="https://openai.com/research/video-generation-models-as-world-simulators?fbclid=IwAR1KwrioOqZkWLLsj02BZu8F52LX789aAk-YerssUphUe6xOb4dUO33V40M#ref-32-0" class="ml-2 no-underline" style="text-decoration: none; top: 2px;">↩︎</a></p></div></li></ol></div><!----></div></div></div></div><div class="container"><div class="mt-spacing-7 border-t border-primary pt-8 lg:pt-12"><div class="cols-container"><div class="xs:w-6-cols md:w-2-cols lg:w-2-cols"><h3 class="f-subhead-2">Authors</h3></div><div class="mt-40 xs:w-6-cols md:w-6-cols md:mt-0 lg:w-10-cols"><div class="cols-container"><!--[--><div class="xs:w-6-cols md:w-6-cols lg:w-4-cols"><div class="cols-container"><!--[--><div class="xs:w-3-cols md:w-2-cols lg:w-2-cols"><!----><ul><!--[--><li class=""><a href="https://openai.com/research?authors=tim-brooks" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Tim Brooks"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Tim Brooks</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=bill-peebles" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Bill Peebles"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Bill Peebles</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=connor-holmes" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Connor Holmes"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Connor Holmes</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=will-depue" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Will DePue"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Will DePue</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=yufei-guo" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Yufei Guo"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Yufei Guo</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=li-jing" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Li Jing"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Li Jing</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=david-schnurr" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="David Schnurr"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">David Schnurr</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=joe-taylor" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Joe Taylor"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Joe Taylor</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=troy-luhman" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Troy Luhman"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Troy Luhman</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=eric-luhman" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Eric Luhman"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Eric Luhman</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=clarence-wing-yin-ng" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Clarence Wing Yin Ng"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Clarence Wing Yin Ng</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=ricky-wang" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Ricky Wang"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Ricky Wang</span><!----><!--]--></span></a></li><li class="mt-4"><a href="https://openai.com/research?authors=aditya-ramesh" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="Aditya Ramesh"><span class="flex items-center"><!--[--><!----><span class="underline-thickness-1 underline-offset-4 underline">Aditya Ramesh</span><!----><!--]--></span></a></li><!--]--></ul><!----></div><!--]--></div></div><div class="xs:w-6-cols md:w-6-cols lg:w-4-cols xs:mt-40 md:mt-48 lg:ml-1-cols lg:mt-0"><div class="cols-container"><!--[--><!--]--></div></div><!--]--></div></div></div></div></div><div class="container"><div class="mt-spacing-7 border-t border-primary pt-8 lg:pt-12"><div class="cols-container"><div class="xs:w-6-cols md:w-2-cols lg:w-2-cols"><h3 id="citationBody1Title" class="f-subhead-2">Acknowledgments</h3></div><div class="mt-40 xs:w-6-cols md:w-6-cols md:mt-0 lg:w-10-cols"><div class="cols-container"><!----><!--[--><div class="xs:w-6-cols md:w-6-cols lg:w-5-cols"><h4 class="f-subhead-2 mb-8">Citation</h4><div class="f-body-1 ui-richtext"><p>Please cite as Brooks, Peebles, et al., and use the following BibTeX for citation:&nbsp;<a href="https://openai.com/bibtex/videoworldsimulators2024.bib" rel="noopener noreferrer" target="_blank">https://openai.com/bibtex/videoworldsimulators2024.bib</a><br class="softbreak"></p></div></div><!----><!--]--></div></div></div></div></div><div class="container"><div class="mt-spacing-7"><div class="pt-spacing-3 w-full border-t border-inherit"><div class="cols-container"><div class="xs:w-6-cols md:w-4-cols lg:w-6-cols"><h2 class="f-heading-1" id="listing1title">Related research</h2></div><div class="xs:w-6-cols md:w-4-cols md:flex md:flex-col lg:w-6-cols"><div class="block xs:mt-12 md:mt-0 md:ml-auto lg:mt-4"><a href="https://openai.com/research" class="ui-link group f-ui-1 inline-block ui-link--underline relative text-[currentColor]" aria-label="View all research"><span class="flex items-center"><!----><span class="underline-thickness-1 underline-offset-4 underline">View all research</span><!----></span></a></div></div></div></div><div class="ui-list"><div class=""><ul aria-labelledby="listing1title" class="cols-container"><li class="lg:w-3-cols xs:w-6-cols mt-spacing-6 md:w-4-cols"><a href="https://openai.com/research/building-an-early-warning-system-for-llm-aided-biological-threat-creation" class="ui-link group relative cursor-pointer" aria-label="Building an early warning system for LLM-aided biological threat creation" id="245" type="research-publications"><div class=""><div class=""><div class=""><img src="./Video generation models as world simulators_files/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg" width="1024" height="1024" alt="" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 50vw, 500px" srcset="https://images.openai.com/blob/ec66425e-99ca-4314-9999-70e6010c8162/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/ec66425e-99ca-4314-9999-70e6010c8162/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/ec66425e-99ca-4314-9999-70e6010c8162/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/ec66425e-99ca-4314-9999-70e6010c8162/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/ec66425e-99ca-4314-9999-70e6010c8162/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/ec66425e-99ca-4314-9999-70e6010c8162/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/ec66425e-99ca-4314-9999-70e6010c8162/building-an-early-warning-system-for-llm-aided-biological-threat-creation.jpg?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false" class="w-full"></div><!----></div></div><div class=""><h3 id="post1title" class="f-subhead-2 mt-8 decoration-1 underline-offset-1 underline-transparent group-hover:underline-text-primary">Building an early warning system for LLM-aided biological threat creation</h3><!----><!----><div class="f-body-1 mt-4"><span aria-hidden="true">Jan 31, 2024</span><span class="sr-only">January 31, 2024</span></div><!----><!----><!----></div></a><!----></li><li class="lg:w-3-cols xs:w-6-cols mt-spacing-6 md:w-4-cols"><a href="https://openai.com/research/weak-to-strong-generalization" class="ui-link group relative cursor-pointer" aria-label="Weak-to-strong generalization" id="238" type="research-publications"><div class=""><div class=""><div class=""><img src="./Video generation models as world simulators_files/weak-to-strong-generalization.jpg" width="1025" height="1024" alt="Weak To Strong Generalization" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 50vw, 500px" srcset="https://images.openai.com/blob/3ae4eaf0-e103-445d-8974-12da0a9934c0/weak-to-strong-generalization.jpg?trim=0,345,0,310&amp;width=400 400w, https://images.openai.com/blob/3ae4eaf0-e103-445d-8974-12da0a9934c0/weak-to-strong-generalization.jpg?trim=0,345,0,310&amp;width=800 800w, https://images.openai.com/blob/3ae4eaf0-e103-445d-8974-12da0a9934c0/weak-to-strong-generalization.jpg?trim=0,345,0,310&amp;width=1000 1000w, https://images.openai.com/blob/3ae4eaf0-e103-445d-8974-12da0a9934c0/weak-to-strong-generalization.jpg?trim=0,345,0,310&amp;width=1400 1400w, https://images.openai.com/blob/3ae4eaf0-e103-445d-8974-12da0a9934c0/weak-to-strong-generalization.jpg?trim=0,345,0,310&amp;width=2000 2000w, https://images.openai.com/blob/3ae4eaf0-e103-445d-8974-12da0a9934c0/weak-to-strong-generalization.jpg?trim=0,345,0,310&amp;width=2600 2600w, https://images.openai.com/blob/3ae4eaf0-e103-445d-8974-12da0a9934c0/weak-to-strong-generalization.jpg?trim=0,345,0,310&amp;width=3200 3200w" aria-hidden="false" class="w-full"></div><!----></div></div><div class=""><h3 id="post2title" class="f-subhead-2 mt-8 decoration-1 underline-offset-1 underline-transparent group-hover:underline-text-primary">Weak-to-strong generalization</h3><!----><!----><div class="f-body-1 mt-4"><span aria-hidden="true">Dec 14, 2023</span><span class="sr-only">December 14, 2023</span></div><!----><!----><!----></div></a><!----></li><li class="lg:w-3-cols xs:w-6-cols mt-spacing-6 md:w-4-cols"><a href="https://openai.com/research/practices-for-governing-agentic-ai-systems" class="ui-link group relative cursor-pointer" aria-label="Practices for Governing Agentic AI Systems" id="236" type="research-publications"><div class=""><div class=""><div class=""><img src="./Video generation models as world simulators_files/practices-for-governing-agentic-ai-systems.jpg" width="1024" height="1024" alt="Practices For Governing Agentic AI Systems" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 50vw, 500px" srcset="https://images.openai.com/blob/dfdeca52-d054-4ce9-aabc-3386f24873d8/practices-for-governing-agentic-ai-systems.jpg?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/dfdeca52-d054-4ce9-aabc-3386f24873d8/practices-for-governing-agentic-ai-systems.jpg?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/dfdeca52-d054-4ce9-aabc-3386f24873d8/practices-for-governing-agentic-ai-systems.jpg?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/dfdeca52-d054-4ce9-aabc-3386f24873d8/practices-for-governing-agentic-ai-systems.jpg?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/dfdeca52-d054-4ce9-aabc-3386f24873d8/practices-for-governing-agentic-ai-systems.jpg?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/dfdeca52-d054-4ce9-aabc-3386f24873d8/practices-for-governing-agentic-ai-systems.jpg?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/dfdeca52-d054-4ce9-aabc-3386f24873d8/practices-for-governing-agentic-ai-systems.jpg?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false" class="w-full"></div><!----></div></div><div class=""><h3 id="post3title" class="f-subhead-2 mt-8 decoration-1 underline-offset-1 underline-transparent group-hover:underline-text-primary">Practices for Governing Agentic AI Systems</h3><!----><!----><div class="f-body-1 mt-4"><span aria-hidden="true">Dec 14, 2023</span><span class="sr-only">December 14, 2023</span></div><!----><!----><!----></div></a><!----></li><li class="lg:w-3-cols xs:w-6-cols mt-spacing-6 md:w-4-cols"><a href="https://openai.com/research/dall-e-3-system-card" class="ui-link group relative cursor-pointer" aria-label="DALL·E 3 system card" id="234" type="research-publications"><div class=""><div class=""><div class=""><img src="./Video generation models as world simulators_files/dall-e-3-system-card.png" width="2064" height="2064" alt="Dall E 3 System Card" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 50vw, 500px" srcset="https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false" class="w-full"></div><!----></div></div><div class=""><h3 id="post4title" class="f-subhead-2 mt-8 decoration-1 underline-offset-1 underline-transparent group-hover:underline-text-primary">DALL·E 3 system card</h3><!----><!----><div class="f-body-1 mt-4"><span aria-hidden="true">Oct 3, 2023</span><span class="sr-only">October 3, 2023</span></div><!----><!----><!----></div></a><!----></li></ul></div></div></div></div><!----><!--]--><!--]--><!----></div><footer class="theme-dark-gray"><div class="mt-spacing-7 pt-spacing-7 w-full bg-primary text-primary"><div class="container"><div class="cols-container"><div class="xs:w-6-cols md:w-8-cols md:mb-48 lg:w-4-cols lg:mb-0"><a href="https://openai.com/" class="relative z-10 inline-block focus:outline-0 before:absolute before:-top-8 before:-bottom-8 before:-left-12 before:-right-12 before:-z-10 before:hidden before:border-4 before:border-primary before:content-[&#39;&#39;] focus:before:block" aria-label="OpenAI"><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1180 320" class="a-icon--logo-text flex h-32 max-w-[126px]" style="width:118;height:32;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><g fill="currentColor" data-v-e1bdab2c=""><path d="m367.44 153.84c0 52.32 33.6 88.8 80.16 88.8s80.16-36.48 80.16-88.8-33.6-88.8-80.16-88.8-80.16 36.48-80.16 88.8zm129.6 0c0 37.44-20.4 61.68-49.44 61.68s-49.44-24.24-49.44-61.68 20.4-61.68 49.44-61.68 49.44 24.24 49.44 61.68z"></path><path d="m614.27 242.64c35.28 0 55.44-29.76 55.44-65.52s-20.16-65.52-55.44-65.52c-16.32 0-28.32 6.48-36.24 15.84v-13.44h-28.8v169.2h28.8v-56.4c7.92 9.36 19.92 15.84 36.24 15.84zm-36.96-69.12c0-23.76 13.44-36.72 31.2-36.72 20.88 0 32.16 16.32 32.16 40.32s-11.28 40.32-32.16 40.32c-17.76 0-31.2-13.2-31.2-36.48z"></path><path d="m747.65 242.64c25.2 0 45.12-13.2 54-35.28l-24.72-9.36c-3.84 12.96-15.12 20.16-29.28 20.16-18.48 0-31.44-13.2-33.6-34.8h88.32v-9.6c0-34.56-19.44-62.16-55.92-62.16s-60 28.56-60 65.52c0 38.88 25.2 65.52 61.2 65.52zm-1.44-106.8c18.24 0 26.88 12 27.12 25.92h-57.84c4.32-17.04 15.84-25.92 30.72-25.92z"></path><path d="m823.98 240h28.8v-73.92c0-18 13.2-27.6 26.16-27.6 15.84 0 22.08 11.28 22.08 26.88v74.64h28.8v-83.04c0-27.12-15.84-45.36-42.24-45.36-16.32 0-27.6 7.44-34.8 15.84v-13.44h-28.8z"></path><path d="m1014.17 67.68-65.28 172.32h30.48l14.64-39.36h74.4l14.88 39.36h30.96l-65.28-172.32zm16.8 34.08 27.36 72h-54.24z"></path><path d="m1163.69 68.18h-30.72v172.32h30.72z"></path><path d="m297.06 130.97c7.26-21.79 4.76-45.66-6.85-65.48-17.46-30.4-52.56-46.04-86.84-38.68-15.25-17.18-37.16-26.95-60.13-26.81-35.04-.08-66.13 22.48-76.91 55.82-22.51 4.61-41.94 18.7-53.31 38.67-17.59 30.32-13.58 68.54 9.92 94.54-7.26 21.79-4.76 45.66 6.85 65.48 17.46 30.4 52.56 46.04 86.84 38.68 15.24 17.18 37.16 26.95 60.13 26.8 35.06.09 66.16-22.49 76.94-55.86 22.51-4.61 41.94-18.7 53.31-38.67 17.57-30.32 13.55-68.51-9.94-94.51zm-120.28 168.11c-14.03.02-27.62-4.89-38.39-13.88.49-.26 1.34-.73 1.89-1.07l63.72-36.8c3.26-1.85 5.26-5.32 5.24-9.07v-89.83l26.93 15.55c.29.14.48.42.52.74v74.39c-.04 33.08-26.83 59.9-59.91 59.97zm-128.84-55.03c-7.03-12.14-9.56-26.37-7.15-40.18.47.28 1.3.79 1.89 1.13l63.72 36.8c3.23 1.89 7.23 1.89 10.47 0l77.79-44.92v31.1c.02.32-.13.63-.38.83l-64.41 37.19c-28.69 16.52-65.33 6.7-81.92-21.95zm-16.77-139.09c7-12.16 18.05-21.46 31.21-26.29 0 .55-.03 1.52-.03 2.2v73.61c-.02 3.74 1.98 7.21 5.23 9.06l77.79 44.91-26.93 15.55c-.27.18-.61.21-.91.08l-64.42-37.22c-28.63-16.58-38.45-53.21-21.95-81.89zm221.26 51.49-77.79-44.92 26.93-15.54c.27-.18.61-.21.91-.08l64.42 37.19c28.68 16.57 38.51 53.26 21.94 81.94-7.01 12.14-18.05 21.44-31.2 26.28v-75.81c.03-3.74-1.96-7.2-5.2-9.06zm26.8-40.34c-.47-.29-1.3-.79-1.89-1.13l-63.72-36.8c-3.23-1.89-7.23-1.89-10.47 0l-77.79 44.92v-31.1c-.02-.32.13-.63.38-.83l64.41-37.16c28.69-16.55 65.37-6.7 81.91 22 6.99 12.12 9.52 26.31 7.15 40.1zm-168.51 55.43-26.94-15.55c-.29-.14-.48-.42-.52-.74v-74.39c.02-33.12 26.89-59.96 60.01-59.94 14.01 0 27.57 4.92 38.34 13.88-.49.26-1.33.73-1.89 1.07l-63.72 36.8c-3.26 1.85-5.26 5.31-5.24 9.06l-.04 89.79zm14.63-31.54 34.65-20.01 34.65 20v40.01l-34.65 20-34.65-20z"></path></g></svg></a></div><!--[--><div class="xs:w-3-cols xs:mt-40 md:w-2-cols md:mt-0"><h4 id="footerList0" class="f-ui-2">Research</h4><ul aria-labelledby="footerList0"><!--[--><li class="mt-1"><a href="https://openai.com/research/overview" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Overview"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Overview</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/research" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Index"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Index</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/gpt-4" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="GPT-4"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">GPT-4</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/dall-e-3" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="DALL·E 3"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">DALL·E 3</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/sora" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Sora"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Sora</span><!----><!--]--></span></a></li><!--]--></ul></div><div class="xs:w-3-cols xs:mt-40 md:w-2-cols md:mt-0"><h4 id="footerList1" class="f-ui-2">API</h4><ul aria-labelledby="footerList1"><!--[--><li class="mt-1"><a href="https://openai.com/product" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Overview"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Overview</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/pricing" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Pricing"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Pricing</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://platform.openai.com/docs/introduction" rel="noopener" target="_blank" aria-label="Docs" class="ui-link group f-ui-1 inline-block relative ui-link--inherit"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Docs</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></div><div class="xs:w-3-cols xs:mt-40 md:w-2-cols md:mt-0"><h4 id="footerList2" class="f-ui-2">ChatGPT</h4><ul aria-labelledby="footerList2"><!--[--><li class="mt-1"><a href="https://openai.com/chatgpt" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Overview"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Overview</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/chatgpt/team" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Team"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Team</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/chatgpt/enterprise" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Enterprise"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Enterprise</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/chatgpt/pricing" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Pricing"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Pricing</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://chat.openai.com/auth/login" rel="noopener" target="_blank" aria-label="Try ChatGPT" class="ui-link group f-ui-1 inline-block relative ui-link--inherit"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Try ChatGPT</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-north-east400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="5 4.31 5 5.69 9.33 5.69 2.51 12.51 3.49 13.49 10.31 6.67 10.31 11 11.69 11 11.69 4.31 5 4.31" data-v-e1bdab2c=""></polygon></svg><!--]--></span></a></li><!--]--></ul></div><div class="xs:w-3-cols xs:mt-40 md:w-2-cols md:mt-0"><h4 id="footerList3" class="f-ui-2">Company</h4><ul aria-labelledby="footerList3"><!--[--><li class="mt-1"><a href="https://openai.com/about" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="About"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">About</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/blog" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Blog"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Blog</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/careers" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Careers"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Careers</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/charter" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Charter"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Charter</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/security" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Security"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Security</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/customer-stories" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Customer stories"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Customer stories</span><!----><!--]--></span></a></li><li class="mt-1"><a href="https://openai.com/safety" class="ui-link group f-ui-1 inline-block relative ui-link--inherit" aria-label="Safety"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Safety</span><!----><!--]--></span></a></li><!--]--></ul></div><!--]--></div><div class="mt-spacing-9 border-t border-primary pt-8"><div class="cols-container"><div class="xs:w-3-cols md:w-2-cols lg:w-4-cols flex flex-col items-start md:min-h-92 lg:min-h-100"><span class="f-subhead-2">OpenAI © 2015 – 2024</span><!--[--><a href="https://openai.com/policies" class="ui-link group f-ui-1 inline-block relative ui-link--inherit xs:mt-3 md:mt-1 block" aria-label="Terms &amp; policies"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Terms &amp; policies</span><!----><!--]--></span></a><a href="https://openai.com/policies/privacy-policy" class="ui-link group f-ui-1 inline-block relative ui-link--inherit xs:mt-3 md:mt-1 block" aria-label="Privacy policy"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Privacy policy</span><!----><!--]--></span></a><a href="https://openai.com/brand" class="ui-link group f-ui-1 inline-block relative ui-link--inherit xs:mt-3 md:mt-1 block" aria-label="Brand guidelines"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Brand guidelines</span><!----><!--]--></span></a><!--]--></div><div class="xs:w-3-cols md:w-6-cols lg:w-8-cols"><h4 id="footerSocialHeading" class="f-subhead-2 md:hidden">Social</h4><ul aria-labelledby="footerSocialHeading" class="md:flex md:flex-row md:flex-wrap"><!--[--><li class="xs:mt-1 md:mt-0 md:mr-16 lg:mr-24 lg:mb-24"><a class="ui-link group relative inline-block ui-link--inherit" href="https://twitter.com/OpenAI" target="_blank"><span class="flex items-center"><span class="f-ui-1 underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Twitter</span></span></a></li><li class="xs:mt-1 md:mt-0 md:mr-16 lg:mr-24 lg:mb-24"><a class="ui-link group relative inline-block ui-link--inherit" href="https://youtube.com/OpenAI" target="_blank"><span class="flex items-center"><span class="f-ui-1 underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">YouTube</span></span></a></li><li class="xs:mt-1 md:mt-0 md:mr-16 lg:mr-24 lg:mb-24"><a class="ui-link group relative inline-block ui-link--inherit" href="https://github.com/openai" target="_blank"><span class="flex items-center"><span class="f-ui-1 underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">GitHub</span></span></a></li><li class="xs:mt-1 md:mt-0 md:mr-16 lg:mr-24 lg:mb-24"><a class="ui-link group relative inline-block ui-link--inherit" href="https://soundcloud.com/openai_audio" target="_blank"><span class="flex items-center"><span class="f-ui-1 underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">SoundCloud</span></span></a></li><li class="xs:mt-1 md:mt-0 md:mr-16 lg:mr-24 lg:mb-24"><a class="ui-link group relative inline-block ui-link--inherit" href="https://www.linkedin.com/company/openai" target="_blank"><span class="flex items-center"><span class="f-ui-1 underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">LinkedIn</span></span></a></li><!--]--></ul></div></div><div class="cols-container mt-24 md:mt-0 md:-translate-y-full md:transform"><div class="xs:w-3-cols md:ml-2-cols md:w-6-cols lg:ml-4-cols lg:w-8-cols"><button aria-label="Back to top" class="ui-link group f-ui-1 inline-block relative ui-link--inherit"><span class="flex items-center"><!--[--><!----><span class="underline-transparent underline-thickness-1 underline-offset-4 group-hover:underline group-hover:underline-inherit">Back to top</span><svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="a-icon--arrow-up400 a-icon--text a-icon--no-align top-[0.05em] relative f-ui-1 ml-2 -mr-4" style="width:1em;height:1em;" data-new="" aria-hidden="true" data-v-e1bdab2c=""><polygon fill="currentColor" points="12.73 7.25 8 2.52 3.27 7.25 4.25 8.23 7.31 5.17 7.31 14 8.69 14 8.69 5.17 11.75 8.23 12.73 7.25" data-v-e1bdab2c=""></polygon></svg><!--]--></span></button></div></div></div></div><div class="mt-spacing-7 pb-spacing-7 bg-inverse" aria-hidden="true"><div style="margin-top:-23px"><!--[--><div class="bg-primary" style="margin-top:0px;height:23px"></div><div class="bg-primary" style="margin-top:1px;height:22px"></div><div class="bg-primary" style="margin-top:2px;height:21px"></div><div class="bg-primary" style="margin-top:3px;height:20px"></div><div class="bg-primary" style="margin-top:4px;height:19px"></div><div class="bg-primary" style="margin-top:5px;height:18px"></div><div class="bg-primary" style="margin-top:6px;height:17px"></div><div class="bg-primary" style="margin-top:7px;height:16px"></div><div class="bg-primary" style="margin-top:8px;height:15px"></div><div class="bg-primary" style="margin-top:9px;height:14px"></div><div class="bg-primary" style="margin-top:10px;height:13px"></div><div class="bg-primary" style="margin-top:11px;height:12px"></div><div class="bg-primary" style="margin-top:12px;height:11px"></div><div class="bg-primary" style="margin-top:13px;height:10px"></div><div class="bg-primary" style="margin-top:14px;height:9px"></div><div class="bg-primary" style="margin-top:15px;height:8px"></div><div class="bg-primary" style="margin-top:16px;height:7px"></div><div class="bg-primary" style="margin-top:17px;height:6px"></div><div class="bg-primary" style="margin-top:18px;height:5px"></div><div class="bg-primary" style="margin-top:19px;height:4px"></div><div class="bg-primary" style="margin-top:20px;height:3px"></div><div class="bg-primary" style="margin-top:21px;height:2px"></div><div class="bg-primary" style="margin-top:22px;height:1px"></div><div class="bg-primary" style="margin-top:23px;height:0px"></div><!--]--></div></div></div></footer></div><!--]--><div class="theme-light-gray fixed inset-0 z-[999] shutter-transition"><div class="flex items-center h-full"><div class="w-full mt-spacing-7 pb-spacing-7" aria-hidden="true"><!--[--><div class="shutter-row overflow-hidden" style="--shutter-delay: 292.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 285ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 277.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 270ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 262.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 255ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 247.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 240ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 232.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 225ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 217.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 210ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 202.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 195ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 187.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 180ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 172.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 165ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 157.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 150ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 142.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 135ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 127.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 120ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 112.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 105ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 97.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 90ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 82.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 75ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 67.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 60ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 52.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 45ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 37.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 30ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 22.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 15ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 7.5ms;"></div><div class="shutter-row overflow-hidden" style="--shutter-delay: 0ms;"></div><!--]--></div></div></div></div><!--]--></div><!--]--></div><script type="module">import p from "/research/video-generation-models-as-world-simulators/_payload.js";window.__NUXT__={...p,...((function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af){return {state:{"$spage-transition":"simple",$snavigation:{header:[{title:m,items:[{text:i,url:n},{text:o,url:p},{text:q,url:r},{text:s,url:t},{text:u,url:v}]},{title:w,items:[{text:i,url:x},{text:j,url:y},{text:z,url:A}]},{title:B,items:[{text:i,url:C},{text:D,url:E},{text:F,url:G},{text:j,url:H},{text:k,url:I}]},{title:J,url:K,items:[]},{title:L,items:[{text:M,url:N},{text:O,url:P},{text:Q,url:R},{text:"Residency",url:"\u002Fresidency"},{text:S,url:T},{text:U,url:V},{text:W,url:X}]}],footer:[{title:m,items:[{text:i,url:n},{text:o,url:p},{text:q,url:r},{text:s,url:t},{text:u,url:v}]},{title:w,items:[{text:i,url:x},{text:j,url:y},{text:z,url:A}]},{title:B,items:[{text:i,url:C},{text:D,url:E},{text:F,url:G},{text:j,url:H},{text:k,url:I}]},{title:L,items:[{text:M,url:N},{text:O,url:P},{text:Q,url:R},{text:S,url:T},{text:U,url:V},{text:W,url:X},{text:J,url:K}]}],quicklinks:[{text:"Log in",url:"https:\u002F\u002Fplatform.openai.com\u002Flogin?launch"},{text:k,url:"https:\u002F\u002Fchat.openai.com"}],tertiary:[{text:"Terms & policies",url:"\u002Fpolicies"},{text:"Privacy policy",url:"\u002Fpolicies\u002Fprivacy-policy"},{text:"Brand guidelines",url:"\u002Fbrand"}],social:[{text:"Twitter",url:"https:\u002F\u002Ftwitter.com\u002FOpenAI"},{text:"YouTube",url:"https:\u002F\u002Fyoutube.com\u002FOpenAI"},{text:"GitHub",url:"https:\u002F\u002Fgithub.com\u002Fopenai"},{text:"SoundCloud",url:"https:\u002F\u002Fsoundcloud.com\u002Fopenai_audio"},{text:"LinkedIn",url:"https:\u002F\u002Fwww.linkedin.com\u002Fcompany\u002Fopenai"}]},"$spage-loading":Y,"$spreview-token":Z,"$spage-theme":Z,"$sglobal-cta":Y,$scitations:{resources:[{type:a,meta:b,id:"3056",selector:"1",description:"\u003Cp\u003ESrivastava, Nitish, Elman Mansimov, and Ruslan Salakhudinov. \"Unsupervised learning of video representations using lstms.\" International conference on machine learning. PMLR, 2015.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Srivastava, Nitish, Elman Mansimov, and Ruslan Salakhudinov. \"Unsupervised learning of video representations using lstms.\" International conference on machine learning. PMLR, 2015.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3057",selector:"2",description:"\u003Cp\u003EChiappa, Silvia, et al. \"Recurrent environment simulators.\" arXiv preprint arXiv:1704.02254 (2017).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Chiappa, Silvia, et al. \"Recurrent environment simulators.\" arXiv preprint arXiv:1704.02254 (2017).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3058",selector:"3",description:"\u003Cp\u003EHa, David, and Jürgen Schmidhuber. \"World models.\" arXiv preprint arXiv:1803.10122 (2018).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Ha, David, and Jürgen Schmidhuber. \"World models.\" arXiv preprint arXiv:1803.10122 (2018).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3059",selector:"4",description:"\u003Cp\u003EVondrick, Carl, Hamed Pirsiavash, and Antonio Torralba. \"Generating videos with scene dynamics.\" Advances in neural information processing systems 29 (2016).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Vondrick, Carl, Hamed Pirsiavash, and Antonio Torralba. \"Generating videos with scene dynamics.\" Advances in neural information processing systems 29 (2016).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3060",selector:"5",description:"\u003Cp\u003ETulyakov, Sergey, et al. \"Mocogan: Decomposing motion and content for video generation.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Tulyakov, Sergey, et al. \"Mocogan: Decomposing motion and content for video generation.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3061",selector:"6",description:"\u003Cp\u003EClark, Aidan, Jeff Donahue, and Karen Simonyan. \"Adversarial video generation on complex datasets.\" arXiv preprint arXiv:1907.06571 (2019).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Clark, Aidan, Jeff Donahue, and Karen Simonyan. \"Adversarial video generation on complex datasets.\" arXiv preprint arXiv:1907.06571 (2019).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3062",selector:"7",description:"\u003Cp\u003EBrooks, Tim, et al. \"Generating long videos of dynamic scenes.\" Advances in Neural Information Processing Systems 35 (2022): 31769-31781.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Brooks, Tim, et al. \"Generating long videos of dynamic scenes.\" Advances in Neural Information Processing Systems 35 (2022): 31769-31781.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3063",selector:"8",description:"\u003Cp\u003EYan, Wilson, et al. \"Videogpt: Video generation using vq-vae and transformers.\" arXiv preprint arXiv:2104.10157 (2021).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Yan, Wilson, et al. \"Videogpt: Video generation using vq-vae and transformers.\" arXiv preprint arXiv:2104.10157 (2021).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3064",selector:"9",description:"\u003Cp\u003EWu, Chenfei, et al. \"Nüwa: Visual synthesis pre-training for neural visual world creation.\" European conference on computer vision. Cham: Springer Nature Switzerland, 2022.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Wu, Chenfei, et al. \"Nüwa: Visual synthesis pre-training for neural visual world creation.\" European conference on computer vision. Cham: Springer Nature Switzerland, 2022.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3065",selector:"10",description:"\u003Cp\u003EHo, Jonathan, et al. \"Imagen video: High definition video generation with diffusion models.\" \u003Cem\u003EarXiv preprint arXiv:2210.02303\u003C\u002Fem\u003E (2022).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Ho, Jonathan, et al. \"Imagen video: High definition video generation with diffusion models.\" ",{type:h,props:[],children:["arXiv preprint arXiv:2210.02303"]}," (2022).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3066",selector:"11",description:"\u003Cp\u003EBlattmann, Andreas, et al. \"Align your latents: High-resolution video synthesis with latent diffusion models.\" Proceedings of the IEEE\u002FCVF Conference on Computer Vision and Pattern Recognition. 2023.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Blattmann, Andreas, et al. \"Align your latents: High-resolution video synthesis with latent diffusion models.\" Proceedings of the IEEE\u002FCVF Conference on Computer Vision and Pattern Recognition. 2023.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3067",selector:"12",description:"\u003Cp\u003EGupta, Agrim, et al. \"Photorealistic video generation with diffusion models.\" arXiv preprint arXiv:2312.06662 (2023).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Gupta, Agrim, et al. \"Photorealistic video generation with diffusion models.\" arXiv preprint arXiv:2312.06662 (2023).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3068",selector:"13",description:"\u003Cp\u003EVaswani, Ashish, et al. \"Attention is all you need.\" \u003Cem\u003EAdvances in neural information processing systems\u003C\u002Fem\u003E 30 (2017).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Vaswani, Ashish, et al. \"Attention is all you need.\" ",{type:h,props:[],children:[l]}," 30 (2017).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3069",selector:"14",description:"\u003Cp\u003EBrown, Tom, et al. \"Language models are few-shot learners.\" \u003Cem\u003EAdvances in neural information processing systems\u003C\u002Fem\u003E 33 (2020): 1877-1901.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Brown, Tom, et al. \"Language models are few-shot learners.\" ",{type:h,props:[],children:[l]}," 33 (2020): 1877-1901.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3070",selector:"15",description:"\u003Cp\u003EDosovitskiy, Alexey, et al. \"An image is worth 16x16 words: Transformers for image recognition at scale.\" \u003Cem\u003EarXiv preprint arXiv:2010.11929\u003C\u002Fem\u003E (2020).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Dosovitskiy, Alexey, et al. \"An image is worth 16x16 words: Transformers for image recognition at scale.\" ",{type:h,props:[],children:["arXiv preprint arXiv:2010.11929"]}," (2020).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3071",selector:"16",description:"\u003Cp\u003EArnab, Anurag, et al. \"Vivit: A video vision transformer.\" \u003Cem\u003EProceedings of the IEEE\u002FCVF international conference on computer vision\u003C\u002Fem\u003E. 2021.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Arnab, Anurag, et al. \"Vivit: A video vision transformer.\" ",{type:h,props:[],children:["Proceedings of the IEEE\u002FCVF international conference on computer vision"]},_,{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3072",selector:"17",description:"\u003Cp\u003EHe, Kaiming, et al. \"Masked autoencoders are scalable vision learners.\" \u003Cem\u003EProceedings of the IEEE\u002FCVF conference on computer vision and pattern recognition\u003C\u002Fem\u003E. 2022.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["He, Kaiming, et al. \"Masked autoencoders are scalable vision learners.\" ",{type:h,props:[],children:[$]},aa,{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3073",selector:"18",description:"\u003Cp\u003EDehghani, Mostafa, et al. \"Patch n'Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution.\" \u003Cem\u003EarXiv preprint arXiv:2307.06304\u003C\u002Fem\u003E (2023).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Dehghani, Mostafa, et al. \"Patch n'Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution.\" ",{type:h,props:[],children:["arXiv preprint arXiv:2307.06304"]}," (2023).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3074",selector:"19",description:"\u003Cp\u003ERombach, Robin, et al. \"High-resolution image synthesis with latent diffusion models.\" \u003Cem\u003EProceedings of the IEEE\u002FCVF conference on computer vision and pattern recognition\u003C\u002Fem\u003E. 2022.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Rombach, Robin, et al. \"High-resolution image synthesis with latent diffusion models.\" ",{type:h,props:[],children:[$]},aa,{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3075",selector:"20",description:"\u003Cp\u003EKingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" \u003Cem\u003EarXiv preprint arXiv:1312.6114\u003C\u002Fem\u003E (2013).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\" ",{type:h,props:[],children:["arXiv preprint arXiv:1312.6114"]}," (2013).",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3076",selector:"21",description:"\u003Cp\u003ESohl-Dickstein, Jascha, et al. \"Deep unsupervised learning using nonequilibrium thermodynamics.\" \u003Cem\u003EInternational conference on machine learning\u003C\u002Fem\u003E. PMLR, 2015.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Sohl-Dickstein, Jascha, et al. \"Deep unsupervised learning using nonequilibrium thermodynamics.\" ",{type:h,props:[],children:[ab]},". PMLR, 2015.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3077",selector:"22",description:"\u003Cp\u003EHo, Jonathan, Ajay Jain, and Pieter Abbeel. \"Denoising diffusion probabilistic models.\" \u003Cem\u003EAdvances in neural information processing systems\u003C\u002Fem\u003E 33 (2020): 6840-6851.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Ho, Jonathan, Ajay Jain, and Pieter Abbeel. \"Denoising diffusion probabilistic models.\" ",{type:h,props:[],children:[l]}," 33 (2020): 6840-6851.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3078",selector:"23",description:"\u003Cp\u003ENichol, Alexander Quinn, and Prafulla Dhariwal. \"Improved denoising diffusion probabilistic models.\" \u003Cem\u003EInternational Conference on Machine Learning\u003C\u002Fem\u003E. PMLR, 2021.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Nichol, Alexander Quinn, and Prafulla Dhariwal. \"Improved denoising diffusion probabilistic models.\" ",{type:h,props:[],children:[ac]},ad,{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3079",selector:"24",description:"\u003Cp\u003EDhariwal, Prafulla, and Alexander Quinn Nichol. \"Diffusion Models Beat GANs on Image Synthesis.\" \u003Cem\u003EAdvances in Neural Information Processing Systems\u003C\u002Fem\u003E. 2021.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Dhariwal, Prafulla, and Alexander Quinn Nichol. \"Diffusion Models Beat GANs on Image Synthesis.\" ",{type:h,props:[],children:[ae]},_,{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3080",selector:"25",description:"\u003Cp\u003EKarras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\" \u003Cem\u003EAdvances in Neural Information Processing Systems\u003C\u002Fem\u003E 35 (2022): 26565-26577.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\" ",{type:h,props:[],children:[ae]}," 35 (2022): 26565-26577.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3081",selector:"26",description:"\u003Cp\u003EPeebles, William, and Saining Xie. \"Scalable diffusion models with transformers.\" \u003Cem\u003EProceedings of the IEEE\u002FCVF International Conference on Computer Vision\u003C\u002Fem\u003E. 2023.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Peebles, William, and Saining Xie. \"Scalable diffusion models with transformers.\" ",{type:h,props:[],children:["Proceedings of the IEEE\u002FCVF International Conference on Computer Vision"]},". 2023.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3082",selector:"27",description:"\u003Cp\u003EChen, Mark, et al. \"Generative pretraining from pixels.\" \u003Cem\u003EInternational conference on machine learning\u003C\u002Fem\u003E. PMLR, 2020.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Chen, Mark, et al. \"Generative pretraining from pixels.\" ",{type:h,props:[],children:[ab]},". PMLR, 2020.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3083",selector:"28",description:"\u003Cp\u003ERamesh, Aditya, et al. \"Zero-shot text-to-image generation.\" \u003Cem\u003EInternational Conference on Machine Learning\u003C\u002Fem\u003E. PMLR, 2021.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Ramesh, Aditya, et al. \"Zero-shot text-to-image generation.\" ",{type:h,props:[],children:[ac]},ad,{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3084",selector:"29",description:"\u003Cp\u003EYu, Jiahui, et al. \"Scaling autoregressive models for content-rich text-to-image generation.\" \u003Cem\u003EarXiv preprint arXiv:2206.10789\u003C\u002Fem\u003E 2.3 (2022): 5.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Yu, Jiahui, et al. \"Scaling autoregressive models for content-rich text-to-image generation.\" ",{type:h,props:[],children:["arXiv preprint arXiv:2206.10789"]}," 2.3 (2022): 5.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3085",selector:"30",description:"\u003Cp\u003EBetker, James, et al. \"Improving image generation with better captions.\" \u003Cem\u003EComputer Science. https:\u002F\u002Fcdn.openai.com\u002Fpapers\u002Fdall-e-3. pdf\u003C\u002Fem\u003E 2.3 (2023): 8\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Betker, James, et al. \"Improving image generation with better captions.\" ",{type:h,props:[],children:["Computer Science. https:\u002F\u002Fcdn.openai.com\u002Fpapers\u002Fdall-e-3. pdf"]}," 2.3 (2023): 8",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3086",selector:"31",description:"\u003Cp\u003ERamesh, Aditya, et al. \"Hierarchical text-conditional image generation with clip latents.\" \u003Cem\u003EarXiv preprint arXiv:2204.06125\u003C\u002Fem\u003E 1.2 (2022): 3.\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Ramesh, Aditya, et al. \"Hierarchical text-conditional image generation with clip latents.\" ",{type:h,props:[],children:["arXiv preprint arXiv:2204.06125"]}," 1.2 (2022): 3.",{type:e,props:{class:f},children:[]}]}]},scope:g},{type:a,meta:b,id:"3087",selector:"32",description:"\u003Cp\u003EMeng, Chenlin, et al. \"Sdedit: Guided image synthesis and editing with stochastic differential equations.\" \u003Cem\u003EarXiv preprint arXiv:2108.01073\u003C\u002Fem\u003E (2021).\u003Cbr class=\"softbreak\"\u003E\u003C\u002Fp\u003E",richTextDescription:{type:c,props:[],children:[{type:d,props:[],children:["Meng, Chenlin, et al. \"Sdedit: Guided image synthesis and editing with stochastic differential equations.\" ",{type:h,props:[],children:["arXiv preprint arXiv:2108.01073"]}," (2021).",{type:e,props:{class:f},children:[]}]}]},scope:g}],footnotes:{},references:{}}},_errors:{},serverRendered:true,config:{public:{TWILL_API_BASE:"https:\u002F\u002Fopenaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net",TWILL_API_AUTH_TOKEN:af,APP_ENV:"production",SENTRY_DSN:"https:\u002F\u002Fe474bbe145f946ec8544b66d517227fa@o33249.ingest.sentry.io\u002F4504879481421824",GOOGLE_ANALYTICS_ID:"G-9YTZJE58M9",CLOUDFLARE_WORKER_BASE_URL:"https:\u002F\u002Fimages.openai.com\u002Fblob"},app:{baseURL:"\u002F",buildAssetsDir:"\u002F_nuxt\u002F",cdnURL:af}},prerenderedAt:1708130033832}}("footnotes",void 0,"div","p","br","softbreak","reference","em","Overview","Pricing","Try ChatGPT","Advances in neural information processing systems","Research","\u002Fresearch\u002Foverview","Index","\u002Fresearch","GPT-4","\u002Fgpt-4","DALL·E 3","\u002Fdall-e-3","Sora","\u002Fsora","API","\u002Fproduct","\u002Fpricing","Docs","https:\u002F\u002Fplatform.openai.com\u002Fdocs\u002Fintroduction","ChatGPT","\u002Fchatgpt","Team","\u002Fchatgpt\u002Fteam","Enterprise","\u002Fchatgpt\u002Fenterprise","\u002Fchatgpt\u002Fpricing","https:\u002F\u002Fchat.openai.com\u002Fauth\u002Flogin","Safety","\u002Fsafety","Company","About","\u002Fabout","Blog","\u002Fblog","Careers","\u002Fcareers","Charter","\u002Fcharter","Security","\u002Fsecurity","Customer stories","\u002Fcustomer-stories",false,null,". 2021.","Proceedings of the IEEE\u002FCVF conference on computer vision and pattern recognition",". 2022.","International conference on machine learning","International Conference on Machine Learning",". PMLR, 2021.","Advances in Neural Information Processing Systems","")))}</script><script type="module" src="./Video generation models as world simulators_files/entry.3fed4871.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/app.241b6099.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/_slug_.78f59fd3.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/Sync.149551cd.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/VideoTwoUpSync.2e5acc7b.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/InlineVideo.ceb7cabc.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/VideoGrid.038c23ff.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/Turtles.0af69134.js.tải xuống" crossorigin=""></script><script type="module" src="./Video generation models as world simulators_files/Madlib.770b9bbb.js.tải xuống" crossorigin=""></script>
</body><div style="position: absolute; top: 0px; z-index: 2147483647; display: block !important;"><template shadowrootmode="open"><style>@import "chrome-extension://jdfkmiabjpfjacifcmihfdjhpnjpiick/css/content-script.css";
</style><div class="body"><div class="turn-lights-overlay"></div><toasts id="toasts-container"></toasts><div class="savior-widget" hidden="true" style="position: absolute; top: 13544.6px; left: 1210px;"><div class="widget-attach hidden">
    <div class="btn-control relative" id="hide-widget">
        <svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M4.80001 13.9905L4.00964 13.2001L8.20964 9.00013L4.00964 4.80013L4.80001 4.00977L9.00001 8.20977L13.2 4.00977L13.9904 4.80013L9.79038 9.00013L13.9904 13.2001L13.2 13.9905L9.00001 9.7905L4.80001 13.9905Z" fill="currentColor"></path>
        </svg>
        <div class="tooltip" position="down">Tạm ẩn thanh này</div>
    </div>

    <div id="download-btn" class="btn-control relative">
        <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
            <circle cx="9.99992" cy="9.99992" r="9.16667" fill="#4FBA69"></circle>
            <path d="M10 15.8372L5.27246 11.1097L6.14263 10.2187L9.37502 13.4511V4.1626H10.625V13.4511L13.8574 10.2315L14.7275 11.1097L10 15.8372Z" fill="currentColor"></path>
        </svg>
        <div class="tooltip" position="down">Tải video, audio hoặc phụ đề</div>

        <dropdown-box class="download-box" hidden="true">
            <dropdown-box-header class="mobile-content-box-header">
                <img src="chrome-extension://jdfkmiabjpfjacifcmihfdjhpnjpiick/images/logo_cc.svg" savior-rendered="">
                <h2>Chọn tệp để tải</h2>
                <button class="dropdown-box-closer" id="mobile-transfer-closer">
                    <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                        <path d="M5.33327 15.5448L4.45508 14.6667L9.12174 9.99999L4.45508 5.33333L5.33327 4.45514L9.99993 9.12181L14.6666 4.45514L15.5448 5.33333L10.8781 9.99999L15.5448 14.6667L14.6666 15.5448L9.99993 10.8782L5.33327 15.5448Z" fill="currentColor"></path>
                    </svg>
                </button>
            </dropdown-box-header>
            <dropdown-box-body id="downloads" data-panel="no-media">
                <panel value="loading">
                    <savior-row class="download-box-content-box">
                        <svg width="20" height="20" class="loading-3-dots" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg"></svg>
                        <span>Đang tải dữ liệu</span>
                    </savior-row>
                </panel>

                <panel value="media" id="downloads-media"></panel>

                <panel value="no-media">
                    <savior-row class="download-box-content-box">
                        <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                            <path d="M10.0001 5.83332C9.77907 5.83332 9.56711 5.92112 9.41083 6.0774C9.25455 6.23368 9.16675 6.44564 9.16675 6.66666V9.99999C9.16675 10.221 9.25455 10.433 9.41083 10.5892C9.56711 10.7455 9.77907 10.8333 10.0001 10.8333C10.2211 10.8333 10.4331 10.7455 10.5893 10.5892C10.7456 10.433 10.8334 10.221 10.8334 9.99999V6.66666C10.8334 6.44564 10.7456 6.23368 10.5893 6.0774C10.4331 5.92112 10.2211 5.83332 10.0001 5.83332ZM10.7668 13.0167C10.7485 12.9636 10.7233 12.9131 10.6918 12.8667L10.5918 12.7417C10.4746 12.626 10.3258 12.5477 10.1641 12.5166C10.0024 12.4854 9.83518 12.5028 9.68342 12.5667C9.58243 12.6089 9.48942 12.668 9.40842 12.7417C9.33118 12.8195 9.27008 12.9119 9.22861 13.0134C9.18714 13.1149 9.16612 13.2237 9.16675 13.3333C9.16807 13.4422 9.19072 13.5498 9.23342 13.65C9.27084 13.7534 9.33056 13.8473 9.40832 13.9251C9.48609 14.0029 9.58001 14.0626 9.68342 14.1C9.78317 14.1441 9.89103 14.1669 10.0001 14.1669C10.1091 14.1669 10.217 14.1441 10.3168 14.1C10.4202 14.0626 10.5141 14.0029 10.5918 13.9251C10.6696 13.8473 10.7293 13.7534 10.7668 13.65C10.8095 13.5498 10.8321 13.4422 10.8334 13.3333C10.8375 13.2778 10.8375 13.2221 10.8334 13.1667C10.8191 13.1135 10.7966 13.0629 10.7668 13.0167ZM10.0001 1.66666C8.35191 1.66666 6.74074 2.1554 5.37033 3.07108C3.99992 3.98675 2.93182 5.28824 2.30109 6.81096C1.67036 8.33368 1.50533 10.0092 1.82687 11.6257C2.14842 13.2423 2.94209 14.7271 4.10753 15.8925C5.27297 17.058 6.75782 17.8517 8.37433 18.1732C9.99084 18.4947 11.6664 18.3297 13.1891 17.699C14.7118 17.0683 16.0133 16.0002 16.929 14.6297C17.8447 13.2593 18.3334 11.6482 18.3334 9.99999C18.3334 8.90564 18.1179 7.82201 17.6991 6.81096C17.2803 5.79991 16.6665 4.88125 15.8926 4.10743C15.1188 3.33361 14.2002 2.71978 13.1891 2.30099C12.1781 1.8822 11.0944 1.66666 10.0001 1.66666ZM10.0001 16.6667C8.68154 16.6667 7.39261 16.2757 6.29628 15.5431C5.19996 14.8106 4.34547 13.7694 3.84089 12.5512C3.3363 11.333 3.20428 9.99259 3.46152 8.69939C3.71875 7.40618 4.35369 6.2183 5.28604 5.28594C6.21839 4.35359 7.40628 3.71866 8.69948 3.46142C9.99269 3.20419 11.3331 3.33621 12.5513 3.84079C13.7695 4.34538 14.8107 5.19986 15.5432 6.29619C16.2758 7.39252 16.6668 8.68145 16.6668 9.99999C16.6668 11.7681 15.9644 13.4638 14.7141 14.714C13.4639 15.9643 11.7682 16.6667 10.0001 16.6667Z" fill="currentColor"></path>
                        </svg>
                        <span>Không tìm thấy tệp để tải</span>
                    </savior-row>
                </panel>
            </dropdown-box-body>
        </dropdown-box>
    </div>

        <div id="open-pip" class="btn-control" data-svg-control="off">
            <svg data-value="off" width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path fill-rule="evenodd" clip-rule="evenodd" d="M15.8335 2.91667H2.50016C2.27004 2.91667 2.0835 3.10322 2.0835 3.33334V13.3333C2.0835 13.5635 2.27004 13.75 2.50016 13.75H4.16683V15H2.50016C1.57969 15 0.833496 14.2538 0.833496 13.3333V3.33334C0.833496 2.41286 1.57969 1.66667 2.50016 1.66667H15.8335C16.754 1.66667 17.5002 2.41286 17.5002 3.33334V5.83334H16.2502V3.33334C16.2502 3.10322 16.0636 2.91667 15.8335 2.91667ZM5.8335 8.70371C5.8335 8.03892 6.37618 7.50001 7.04562 7.50001H17.9547C18.6241 7.50001 19.1668 8.03892 19.1668 8.70371V17.1296C19.1668 17.7944 18.6241 18.3333 17.9547 18.3333H7.04562C6.37618 18.3333 5.8335 17.7944 5.8335 17.1296V8.70371ZM9.55736 15.3027C9.45237 15.4077 9.52673 15.5872 9.67521 15.5872L14.9469 15.5872L14.9469 10.3156C14.9469 10.1671 14.7673 10.0928 14.6623 10.1978L12.8191 12.041L10.8806 10.1025C10.8155 10.0374 10.71 10.0374 10.6449 10.1025L9.46207 11.2853C9.39698 11.3503 9.39698 11.4559 9.46207 11.521L11.4006 13.4595L9.55736 15.3027Z" fill="currentColor"></path>
            </svg>
            <svg data-value="on" width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path fill-rule="evenodd" clip-rule="evenodd" d="M15.8335 2.91666H2.50016C2.27004 2.91666 2.0835 3.1032 2.0835 3.33332V13.3333C2.0835 13.5634 2.27004 13.75 2.50016 13.75H8.3335V15H2.50016C1.57969 15 0.833496 14.2538 0.833496 13.3333V3.33332C0.833496 2.41285 1.57969 1.66666 2.50016 1.66666H15.8335C16.754 1.66666 17.5002 2.41285 17.5002 3.33332V9.99999H16.2502V3.33332C16.2502 3.1032 16.0636 2.91666 15.8335 2.91666ZM10.0002 15.8334V14.1667V12.5C10.0002 12.0398 10.3733 11.6667 10.8335 11.6667H15.8335H17.5002H18.3335C18.7937 11.6667 19.1668 12.0398 19.1668 12.5V18.3334C19.1668 18.7936 18.7937 19.1667 18.3335 19.1667H10.8335C10.3733 19.1667 10.0002 18.7936 10.0002 18.3334V15.8334ZM9.20216 5.39112C9.30715 5.28612 9.23279 5.1066 9.08431 5.1066H4.27354V9.91737C4.27354 10.0659 4.45306 10.1402 4.55806 10.0352L6.22847 8.36481L7.99997 10.1363C8.06505 10.2014 8.17058 10.2014 8.23567 10.1363L9.30325 9.06873C9.36834 9.00364 9.36834 8.89811 9.30325 8.83303L7.53175 7.06152L9.20216 5.39112Z" fill="currentColor"></path>
            </svg>
            <div class="tooltip" position="down">Ghim video</div>
        </div>

    <div id="switch-light" class="btn-control" data-svg-control="off">
        <svg data-value="off" width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M10.0002 19.1667C9.60383 19.1667 9.2534 19.0669 8.94887 18.8675C8.64436 18.668 8.43132 18.4063 8.30976 18.0823H8.02485C7.62093 18.0823 7.27304 17.9429 6.98119 17.6643C6.68932 17.3856 6.54338 17.0535 6.54338 16.6679V13.4646C5.54687 12.8879 4.76276 11.2815 4.19105 10.3119C3.61935 9.34236 3.3335 8.3045 3.3335 7.19834C3.3335 5.42365 3.9799 3.91914 5.27271 2.68481C6.56554 1.4505 8.14136 0.833344 10.0002 0.833344C11.859 0.833344 13.4348 1.4505 14.7276 2.68481C16.0204 3.91914 16.6668 5.42365 16.6668 7.19834C16.6668 8.32385 16.381 9.36655 15.8093 10.3264C15.2376 11.2863 14.4535 12.8879 13.4569 13.4646V16.6679C13.4569 17.0535 13.311 17.3856 13.0191 17.6643C12.7273 17.9429 12.3794 18.0823 11.9755 18.0823H11.6906C11.569 18.4063 11.356 18.668 11.0515 18.8675C10.7469 19.0669 10.3965 19.1667 10.0002 19.1667ZM8.02485 16.6679H11.9755V16.6667H8.02485V16.6679ZM8.02485 16.6667H11.9755V13.9252H8.02485V16.6667ZM7.82731 12.5108H9.41137V8.93194L7.29551 6.91182L8.12361 6.12119L10.0002 7.91283L11.8767 6.12119L12.7048 6.91182L10.589 8.93194V12.5108H12.173C13.0619 12.1021 13.7862 10.6677 14.3459 9.87401C14.9055 9.08034 15.1854 8.18845 15.1854 7.19834C15.1854 5.81532 14.6833 4.64447 13.6792 3.68579C12.6751 2.72711 11.4487 2.24777 10.0002 2.24777C8.5516 2.24777 7.32526 2.72711 6.32114 3.68579C5.31702 4.64447 4.81496 5.81532 4.81496 7.19834C4.81496 8.18845 5.09479 9.08034 5.65447 9.87401C6.21414 10.6677 6.93842 12.1021 7.82731 12.5108Z" fill="currentColor"></path>
        </svg>
        <svg data-value="on" width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M10.0002 19.1667C9.60383 19.1667 9.2534 19.0669 8.94887 18.8675C8.64436 18.668 8.43132 18.4063 8.30976 18.0823H8.02485C7.62093 18.0823 7.27304 17.9429 6.98119 17.6643C6.68932 17.3856 6.54338 17.0535 6.54338 16.6679V13.4646C5.54687 12.8879 4.76276 11.2815 4.19105 10.3119C3.61935 9.34236 3.3335 8.3045 3.3335 7.19834C3.3335 5.42365 3.9799 3.91914 5.27271 2.68481C6.56554 1.4505 8.14136 0.833344 10.0002 0.833344C11.859 0.833344 13.4348 1.4505 14.7276 2.68481C16.0204 3.91914 16.6668 5.42365 16.6668 7.19834C16.6668 8.32385 16.381 9.36655 15.8093 10.3264C15.2376 11.2863 14.4535 12.8879 13.4569 13.4646V16.6679C13.4569 17.0535 13.311 17.3856 13.0191 17.6643C12.7273 17.9429 12.3794 18.0823 11.9755 18.0823H11.6906C11.569 18.4063 11.356 18.668 11.0515 18.8675C10.7469 19.0669 10.3965 19.1667 10.0002 19.1667ZM8.02485 16.6679H11.9755V16.6667H8.02485V16.6679ZM8.02485 16.6667H11.9755V13.9252H8.02485V16.6667ZM10.589 12.5108V8.93194L12.7048 6.91182L11.8767 6.12119L10.0002 7.91283L8.12361 6.12119L7.29551 6.91182L9.41137 8.93194V12.5108H10.589Z" fill="currentColor"></path>
        </svg>
        <div class="tooltip" position="down">Tắt đèn</div>
    </div>

    <div id="other-feature" class="btn-control relative last-of-type">
        <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M9.99998 16.0576C9.65624 16.0576 9.36198 15.9353 9.11719 15.6905C8.8724 15.4457 8.75 15.1514 8.75 14.8077C8.75 14.4639 8.8724 14.1697 9.11719 13.9249C9.36198 13.6801 9.65624 13.5577 9.99998 13.5577C10.3437 13.5577 10.638 13.6801 10.8828 13.9249C11.1276 14.1697 11.25 14.4639 11.25 14.8077C11.25 15.1514 11.1276 15.4457 10.8828 15.6905C10.638 15.9353 10.3437 16.0576 9.99998 16.0576ZM9.99998 11.25C9.65624 11.25 9.36198 11.1276 9.11719 10.8828C8.8724 10.638 8.75 10.3437 8.75 10C8.75 9.65626 8.8724 9.362 9.11719 9.11721C9.36198 8.87241 9.65624 8.75002 9.99998 8.75002C10.3437 8.75002 10.638 8.87241 10.8828 9.11721C11.1276 9.362 11.25 9.65626 11.25 10C11.25 10.3437 11.1276 10.638 10.8828 10.8828C10.638 11.1276 10.3437 11.25 9.99998 11.25ZM9.99998 6.44229C9.65624 6.44229 9.36198 6.31989 9.11719 6.0751C8.8724 5.83032 8.75 5.53606 8.75 5.19231C8.75 4.84857 8.8724 4.55431 9.11719 4.30952C9.36198 4.06474 9.65624 3.94235 9.99998 3.94235C10.3437 3.94235 10.638 4.06474 10.8828 4.30952C11.1276 4.55431 11.25 4.84857 11.25 5.19231C11.25 5.53606 11.1276 5.83032 10.8828 6.0751C10.638 6.31989 10.3437 6.44229 9.99998 6.44229Z" fill="currentColor"></path>
        </svg>
        <div class="tooltip" position="down">Tính năng khác</div>
        <dropdown-box id="expansion" class="expansion-box" hidden="true">
            <dropdown-item id="open-mobile" hidden="true">
                <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M14.331 18.75C14.7519 18.75 15.1082 18.6041 15.3999 18.3125C15.6916 18.0208 15.8374 17.6645 15.8374 17.2435V2.75642C15.8374 2.33547 15.6916 1.97917 15.3999 1.6875C15.1082 1.39583 14.7519 1.25 14.331 1.25H8.72203V2.49998H14.331C14.3951 2.49998 14.4539 2.52669 14.5073 2.5801C14.5607 2.63353 14.5874 2.69231 14.5874 2.75642V3.54167H8.72203V4.79162H14.5874V15.2083H6.25409V13.5417H5.00411V17.2435C5.00411 17.6645 5.14994 18.0208 5.44161 18.3125C5.73328 18.6041 6.08958 18.75 6.51053 18.75H14.331ZM14.5874 16.4583V17.2435C14.5874 17.3077 14.5607 17.3664 14.5073 17.4199C14.4539 17.4733 14.3951 17.5 14.331 17.5H6.51053C6.44642 17.5 6.38764 17.4733 6.33421 17.4199C6.2808 17.3664 6.25409 17.3077 6.25409 17.2435V16.4583H14.5874ZM5.42076 11.3701L9.29894 7.49196L8.42076 6.61379L6.04574 8.98879V2.70833H4.79578V8.98879L2.42076 6.61379L1.54257 7.49196L5.42076 11.3701Z" fill="#45474A"></path>
                </svg>

                <span>Tải tệp về điện thoại</span>
            </dropdown-item>
            <dropdown-item id="hide-on-site">
                <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M13.1444 10.8109L12.2085 9.875C12.3335 9.18481 12.1366 8.56436 11.6179 8.01362C11.0992 7.46287 10.4627 7.24999 9.70848 7.37499L8.7726 6.43912C8.96063 6.35472 9.15347 6.29142 9.35112 6.24922C9.54876 6.20702 9.7651 6.18591 10.0001 6.18591C10.9456 6.18591 11.7483 6.51577 12.408 7.1755C13.0677 7.83522 13.3976 8.63783 13.3976 9.58333C13.3976 9.81837 13.3765 10.0374 13.3342 10.2404C13.2921 10.4434 13.2288 10.6335 13.1444 10.8109ZM15.795 13.4038L14.8751 12.5417C15.4029 12.1389 15.8717 11.6979 16.2814 11.2187C16.6911 10.7396 17.0418 10.1944 17.3335 9.58333C16.639 8.18055 15.6425 7.06597 14.3439 6.23958C13.0453 5.41319 11.5974 4.99999 10.0001 4.99999C9.59737 4.99999 9.20153 5.02777 8.81264 5.08333C8.42375 5.13888 8.04181 5.22222 7.66681 5.33333L6.69568 4.3622C7.22239 4.1528 7.76032 3.99842 8.30946 3.89906C8.85859 3.7997 9.42216 3.75002 10.0001 3.75002C11.9531 3.75002 13.7143 4.28847 15.2838 5.36539C16.8532 6.44232 17.998 7.8483 18.7181 9.58333C18.4093 10.328 18.0105 11.023 17.5217 11.6682C17.033 12.3135 16.4574 12.8921 15.795 13.4038ZM16.4681 18.2243L13.0963 14.8782C12.669 15.0363 12.1954 15.1656 11.6756 15.266C11.1559 15.3664 10.5974 15.4166 10.0001 15.4166C8.04182 15.4166 6.28062 14.8782 4.71652 13.8013C3.15242 12.7243 2.00766 11.3184 1.28223 9.58333C1.58992 8.84722 1.98736 8.16052 2.47454 7.52322C2.96172 6.88595 3.49805 6.33333 4.08352 5.86539L1.77581 3.53206L2.65402 2.65387L17.3463 17.3461L16.4681 18.2243ZM4.96171 6.74356C4.52154 7.09399 4.09339 7.5152 3.67725 8.0072C3.26111 8.49919 2.9243 9.02456 2.66681 9.58333C3.36125 10.9861 4.35778 12.1007 5.65639 12.9271C6.955 13.7535 8.40292 14.1667 10.0001 14.1667C10.3794 14.1667 10.7571 14.1346 11.1332 14.0705C11.5093 14.0064 11.8282 13.9402 12.0899 13.8718L11.0354 12.7916C10.8933 12.8493 10.7288 12.8953 10.5418 12.9295C10.3549 12.9636 10.1743 12.9807 10.0001 12.9807C9.05464 12.9807 8.25203 12.6509 7.59231 11.9912C6.93259 11.3314 6.60273 10.5288 6.60273 9.58333C6.60273 9.41452 6.61982 9.23797 6.65402 9.05368C6.68821 8.86938 6.73415 8.70084 6.79183 8.54806L4.96171 6.74356Z" fill="#45474A"></path>
                </svg>

                <span>Không hiển thị lại trên openai.com</span>
            </dropdown-item>
            <dropdown-item id="open-settings">
                <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M8.07696 17.9167L7.75965 15.3782C7.53636 15.3034 7.30746 15.1987 7.07294 15.0641C6.83843 14.9295 6.62876 14.7852 6.44392 14.6314L4.09296 15.625L2.16992 12.2917L4.20357 10.7548C4.18433 10.6309 4.17071 10.5064 4.16269 10.3814C4.15468 10.2564 4.15067 10.132 4.15067 10.008C4.15067 9.88944 4.15468 9.76898 4.16269 9.64665C4.17071 9.52431 4.18433 9.3905 4.20357 9.24521L2.16992 7.70835L4.09296 4.39108L6.4359 5.37667C6.63676 5.21747 6.85124 5.0719 7.07934 4.93996C7.30745 4.808 7.53155 4.70196 7.75163 4.62183L8.07696 2.08337H11.923L12.2404 4.62985C12.4904 4.72066 12.7166 4.82669 12.9191 4.94796C13.1215 5.06922 13.3259 5.21212 13.532 5.37667L15.907 4.39108L17.8301 7.70835L15.7644 9.26923C15.7943 9.40385 15.8106 9.52966 15.8133 9.64665C15.8159 9.76363 15.8173 9.88142 15.8173 10C15.8173 10.1133 15.8146 10.2284 15.8093 10.3454C15.8039 10.4624 15.7847 10.5962 15.7516 10.7468L17.8013 12.2917L15.8782 15.625L13.532 14.6234C13.3259 14.7879 13.1154 14.9335 12.9006 15.0601C12.6859 15.1867 12.4658 15.2901 12.2404 15.3702L11.923 17.9167H8.07696ZM10.0096 12.5C10.703 12.5 11.293 12.2567 11.7796 11.77C12.2663 11.2834 12.5096 10.6934 12.5096 10C12.5096 9.30666 12.2663 8.71665 11.7796 8.23C11.293 7.74336 10.703 7.50004 10.0096 7.50004C9.30771 7.50004 8.71557 7.74336 8.23319 8.23C7.75083 8.71665 7.50965 9.30666 7.50965 10C7.50965 10.6934 7.75083 11.2834 8.23319 11.77C8.71557 12.2567 9.30771 12.5 10.0096 12.5ZM10.0096 11.25C9.66239 11.25 9.36725 11.1285 9.12419 10.8854C8.88114 10.6424 8.75961 10.3472 8.75961 10C8.75961 9.6528 8.88114 9.35766 9.12419 9.1146C9.36725 8.87155 9.66239 8.75002 10.0096 8.75002C10.3568 8.75002 10.652 8.87155 10.895 9.1146C11.1381 9.35766 11.2596 9.6528 11.2596 10C11.2596 10.3472 11.1381 10.6424 10.895 10.8854C10.652 11.1285 10.3568 11.25 10.0096 11.25ZM9.16667 16.6667H10.8045L11.1042 14.4343C11.5294 14.3232 11.918 14.1653 12.27 13.9608C12.6221 13.7562 12.9615 13.4931 13.2885 13.1715L15.359 14.0417L16.1795 12.625L14.3718 11.2628C14.4412 11.047 14.4885 10.8355 14.5136 10.6282C14.5387 10.421 14.5513 10.2116 14.5513 10C14.5513 9.78315 14.5387 9.57374 14.5136 9.37181C14.4885 9.1699 14.4412 8.9637 14.3718 8.75323L16.1955 7.37502L15.375 5.95835L13.2804 6.84137C13.0016 6.54329 12.6675 6.27994 12.278 6.05131C11.8886 5.82267 11.4947 5.66081 11.0962 5.56573L10.8333 3.33335H9.17948L8.90386 5.55771C8.47864 5.65814 8.08601 5.81199 7.72596 6.01925C7.36592 6.22651 7.02244 6.49361 6.69553 6.82054L4.62501 5.95835L3.80448 7.37502L5.60417 8.71637C5.53473 8.91401 5.48612 9.11967 5.45834 9.33335C5.43056 9.54703 5.41667 9.77193 5.41667 10.008C5.41667 10.2249 5.43056 10.4375 5.45834 10.6459C5.48612 10.8542 5.53205 11.0598 5.59615 11.2628L3.80448 12.625L4.62501 14.0417L6.68751 13.1667C7.00374 13.4915 7.34188 13.7575 7.70192 13.9648C8.06196 14.172 8.45994 14.3312 8.89584 14.4423L9.16667 16.6667Z" fill="#45474A"></path>
                </svg>

                <span>Cài đặt</span>

                <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M4.42316 17.0836C4.00222 17.0836 3.64591 16.9378 3.35425 16.6461C3.06258 16.3545 2.91675 15.9981 2.91675 15.5772V4.42341C2.91675 4.00246 3.06258 3.64616 3.35425 3.35449C3.64591 3.06283 4.00222 2.91699 4.42316 2.91699H9.67952V4.16697H4.42316C4.35905 4.16697 4.30028 4.19368 4.24685 4.2471C4.19344 4.30053 4.16673 4.3593 4.16673 4.42341V15.5772C4.16673 15.6413 4.19344 15.7001 4.24685 15.7535C4.30028 15.8069 4.35905 15.8336 4.42316 15.8336H15.577C15.6411 15.8336 15.6998 15.8069 15.7533 15.7535C15.8067 15.7001 15.8334 15.6413 15.8334 15.5772V10.3208H17.0834V15.5772C17.0834 15.9981 16.9375 16.3545 16.6459 16.6461C16.3542 16.9378 15.9979 17.0836 15.577 17.0836H4.42316ZM8.09942 12.7791L7.22123 11.901L14.9552 4.16697H11.6667V2.91699H17.0834V8.33364H15.8334V5.04516L8.09942 12.7791Z" fill="#1A1C1E"></path>
                </svg>
            </dropdown-item>
        </dropdown-box>
    </div>

    <div id="mobile-wrapper" class="btn-control relative is-active last-of-type" hidden="true">
        <svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M12.8976 16.875C13.2765 16.875 13.5972 16.7437 13.8597 16.4812C14.1222 16.2187 14.2534 15.898 14.2534 15.5192V2.48078C14.2534 2.10193 14.1222 1.78125 13.8597 1.51875C13.5972 1.25625 13.2765 1.125 12.8976 1.125H7.84958V2.24998H12.8976C12.9553 2.24998 13.0082 2.27402 13.0563 2.32209C13.1044 2.37018 13.1284 2.42308 13.1284 2.48078V3.1875H7.84958V4.31246H13.1284V13.6875H5.62844V12.1875H4.50345V15.5192C4.50345 15.898 4.6347 16.2187 4.89721 16.4812C5.15971 16.7437 5.48038 16.875 5.85923 16.875H12.8976ZM13.1284 14.8125V15.5192C13.1284 15.5769 13.1044 15.6298 13.0563 15.6779C13.0082 15.7259 12.9553 15.75 12.8976 15.75H5.85923C5.80153 15.75 5.74864 15.7259 5.70055 15.6779C5.65247 15.6298 5.62844 15.5769 5.62844 15.5192V14.8125H13.1284ZM4.87844 10.2331L8.36881 6.74276L7.57844 5.95241L5.44092 8.08991V2.4375H4.31595V8.08991L2.17844 5.95241L1.38807 6.74276L4.87844 10.2331Z" fill="currentColor"></path>
        </svg>
    </div>

    <div id="onboard-nmp" hidden="true"></div>

</div></div></div></template></div></html>