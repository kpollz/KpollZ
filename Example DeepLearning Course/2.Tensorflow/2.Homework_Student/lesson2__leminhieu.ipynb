{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lesson2__leminhieu.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. Lý thuyết\n","\n","**1) Để khởi tạo model trong tensorflow chúng ta sử dụng class nào?**\n","\n","A. Sequential hoặc Model\n","\n","B. Dense\n","\n","C. Adam\n","\n","D. Variable\n","\n","***Đáp án: A.***\n","\n","**2) Điểm khác biệt giữa fit và fit_generator trong tensorflow là gì ?**\n","\n","A. fit sẽ yêu cầu load toàn bộ dữ liệu lên RAM trong khi fit_generator sẽ sử dụng một hàm generator để sinh dữ liệu tại mỗi mini-batch. Từ đó giúp tiết kiệm bộ nhớ.\n","\n","B. fit sẽ sử dụng hàm generator để sinh dữ liệu tại thời điểm huấn luyện còn fit_generator sẽ load toàn bộ dữ liệu.\n","\n","C. fit sẽ huấn luyện model theo mini-batch còn fit_generator thì huấn luyện trên toàn bộ dataset.\n","\n","D. trong hàm fit chúng ta có thể khai báo tập validation dataset còn trong fit_generator thì không.\n","\n","***Đáp án: A.***\n","\n","**3) Các modules chính trong tensorflow dùng để xây dựng và huấn luyện model.**\n","\n","A. `tf.keras.layers`: khởi tạo activation function; `tf.keras.Sequential`: khởi tạo model; `tf.keras.activations`: để khởi tạo các layers; `tf.keras.optimizers`: Khởi tạo optimizer cho bài toán tối ưu loss function; `tf.keras.losses`: khởi tạo loss function; `tf.keras.preprocessing`: Preprocessing data.\n","\n","B. `tf.keras.layers`: để khởi tạo các layers; `tf.keras.Sequential`: khởi tạo model; `tf.keras.activations`: khởi tạo activation function; `tf.keras.optimizers`: Khởi tạo optimizer cho bài toán tối ưu loss function; `tf.keras.losses`: khởi tạo loss function; `tf.keras.preprocessing`: Preprocessing data.\n","\n","C. `tf.keras.layers`: để khởi tạo các layers; `tf.keras.Sequential`: Preprocessing data; `tf.keras.activations`: khởi tạo activation function; `tf.keras.optimizers`: Khởi tạo optimizer cho bài toán tối ưu loss function; `tf.keras.losses`: khởi tạo loss function; `tf.keras.preprocessing`: khởi tạo model\n","\n","D. `tf.keras.layers`: để khởi tạo các layers; `tf.keras.Sequential`: khởi tạo model; `tf.keras.activations`: khởi tạo activation function; `tf.keras.optimizers`: khởi tạo loss function; `tf.keras.losses`: Khởi tạo optimizer cho bài toán tối ưu loss function; `tf.keras.preprocessing`: Preprocessing data.\n","\n","***Đáp án: B.***\n","\n","**4) Các bước trong huấn luyện model bao gồm:**\n","\n","A. 1. Train/test data split --> 2. Initialize the optimizer algorithm --> 3. Build up model architecture --> 4. Train model on train --> 5. Evaluation on test --> 6. Save and use trained model\n","\n","B. 1. Train/test data split --> 2. Build up model architecture --> 3. Train model on train --> 4. Initialize the optimizer algorithm --> 5. Evaluation on test --> 6. Save and use trained model\n","\n","C. 1. Train/test data split --> 2. Build up model architecture --> 3. Initialize the optimizer algorithm --> 4. Evaluation on test --> 5. Train model on train --> 6. Save and use trained model\n","\n","D. 1. Train/test data split --> 2. Build up model architecture --> 3. Initialize the optimizer algorithm --> 4. Train model on train --> 5. Evaluation on test --> 6. Save and use trained model\n","\n","***Đáp án: D.***\n","\n","**5) Ý nghĩa của tham số epochs và batch_size trong huấn luyện mô hình là gì?**\n","\n","A. epochs là kích thước của một mini-batch, batch_size là số lượt lặp lại toàn bộ dữ liệu khi huấn luyện.\n","\n","B. epochs là số lượt lặp lại toàn bộ dữ liệu validation khi huấn luyện, batch_size là kích thước của một mini-batch.\n","\n","C. epochs là số lượt lặp lại toàn bộ dữ liệu train khi huấn luyện, batch_size là kích thước của một mini-batch.\n","\n","D. epochs là số lượng vòng lặp, mỗi vòng lặp là một lượt fit mini-batch, trên bộ dữ liệu khi huấn luyện; batch_size là kích thước của một mini-batch.\n","\n","***Đáp án: D.***"],"metadata":{"id":"DUXbtwUsAGPq"}},{"cell_type":"markdown","source":["# Đáp án câu 5 là C"],"metadata":{"id":"EtyE1MrygTB2"}},{"cell_type":"markdown","source":["# 2. Thực hành\n","\n","6) Khởi tạo một tensor 3 chiều với định dạng là float và kích thước là 32x32x3\n","\n","7) Nếu coi tensor trên là một bức ảnh RGB với số channel là 3 ở cuối. Hãy truy suất các ma trận ảnh tương ứng với mỗi kênh R, G, B.\n","\n","8) Thực hiện tích hadamard và tích thông thường giữa ma trận R và G.\n","\n","9) Từ bộ dữ liệu [Income-Classification](https://www.kaggle.com/t/090688c8d33a40b68be9e271d6ba6bae) hãy chuẩn hóa dữ liệu và phân chia tập train/test theo tỷ lệ 80/20. \n","\n","10) Xây dựng một mạng deep-neural-network để huấn luyện mô hình trên dữ liệu train và đánh giá mô hình trên dữ liệu test.\n"],"metadata":{"id":"LzLjMsckAJAT"}},{"cell_type":"code","source":["\"\"\" \n","6) Khởi tạo một tensor 3 chiều với định dạng là float và kích thước là 32x32x3\n","\"\"\"\n","import tensorflow as tf\n","\n","A = tf.random.normal([3, 32, 32], dtype=tf.float32)\n","A"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmyCERvgCaAO","outputId":"9e4e4372-7ec1-4926-a5e2-c37330270159"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 32, 32), dtype=float32, numpy=\n","array([[[-0.10053179,  1.0720441 , -0.21220092, ...,  0.04653974,\n","          1.3145849 , -1.5496628 ],\n","        [-0.02180839, -0.7558969 , -0.87025386, ..., -0.30926684,\n","          0.30075425, -0.4103318 ],\n","        [ 0.22985315, -1.9093149 , -0.54006237, ..., -1.0158746 ,\n","          0.89288753, -0.61859053],\n","        ...,\n","        [-1.6203943 ,  0.760472  ,  0.66730994, ..., -1.0951998 ,\n","          0.86497426,  0.8267141 ],\n","        [ 0.07999255,  1.2790133 , -0.09035151, ...,  2.015207  ,\n","          0.73786527,  1.8319598 ],\n","        [ 0.36370155,  1.5820992 , -0.09972443, ..., -0.2901798 ,\n","         -0.15992454, -0.29433522]],\n","\n","       [[ 0.11246386,  0.8659415 ,  0.6644706 , ...,  0.16932437,\n","          0.41107932, -0.99738437],\n","        [-0.6936267 ,  1.2754345 ,  0.20183522, ...,  1.0035905 ,\n","          0.7040914 ,  1.7550101 ],\n","        [ 1.207518  , -0.27660635, -0.8622163 , ...,  0.02586595,\n","         -1.2308481 , -0.9757581 ],\n","        ...,\n","        [ 0.8240296 ,  0.25791034, -2.345487  , ..., -0.41423535,\n","         -0.22661445,  0.4822032 ],\n","        [ 1.0366478 , -0.12781419,  0.1715555 , ..., -0.06099313,\n","          1.9318476 , -0.9293198 ],\n","        [ 0.8518265 , -0.5754731 , -1.6122677 , ..., -1.0376246 ,\n","          0.85654205, -0.3040477 ]],\n","\n","       [[-1.001682  , -0.51628447, -0.52264154, ..., -0.8867197 ,\n","          0.51816237,  0.08405879],\n","        [ 0.8766672 , -0.9190279 ,  0.08159795, ...,  0.25012752,\n","         -2.210301  ,  1.2047396 ],\n","        [-1.5045058 , -0.7141395 , -0.59662443, ...,  0.3691377 ,\n","          2.1802194 ,  1.1789078 ],\n","        ...,\n","        [ 0.6536907 ,  1.3415111 , -0.45744833, ...,  0.5865774 ,\n","          0.02457571,  1.0809281 ],\n","        [ 0.9294893 , -0.8080595 , -0.20406632, ..., -1.1816254 ,\n","         -0.8682141 , -1.4461982 ],\n","        [-0.04475067, -0.80794054, -0.2263502 , ...,  0.57465655,\n","         -0.98238575, -0.6805934 ]]], dtype=float32)>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["\"\"\"\n","7) Nếu coi tensor trên là một bức ảnh RGB với số channel là 3 ở cuối. \n","Hãy truy suất các ma trận ảnh tương ứng với mỗi kênh R, G, B.\n","\"\"\"\n","R, G, B = A[0], A[1], A[2]\n","R"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"np8XhQxBCaXK","outputId":"9594abdb-df8b-48e2-fe3c-dbc071850241"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(32, 32), dtype=float32, numpy=\n","array([[-0.10053179,  1.0720441 , -0.21220092, ...,  0.04653974,\n","         1.3145849 , -1.5496628 ],\n","       [-0.02180839, -0.7558969 , -0.87025386, ..., -0.30926684,\n","         0.30075425, -0.4103318 ],\n","       [ 0.22985315, -1.9093149 , -0.54006237, ..., -1.0158746 ,\n","         0.89288753, -0.61859053],\n","       ...,\n","       [-1.6203943 ,  0.760472  ,  0.66730994, ..., -1.0951998 ,\n","         0.86497426,  0.8267141 ],\n","       [ 0.07999255,  1.2790133 , -0.09035151, ...,  2.015207  ,\n","         0.73786527,  1.8319598 ],\n","       [ 0.36370155,  1.5820992 , -0.09972443, ..., -0.2901798 ,\n","        -0.15992454, -0.29433522]], dtype=float32)>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["\"\"\"\n","8) Thực hiện tích hadamard giữa ma trận R và G.\n","\"\"\"\n","R * G"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Fg_KE7RCahh","outputId":"15f1d39e-adc0-472e-e77b-27b76755ab37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(32, 32), dtype=float32, numpy=\n","array([[-0.01130619,  0.92832756, -0.14100128, ...,  0.00788031,\n","         0.54039866,  1.5456095 ],\n","       [ 0.01512688, -0.964097  , -0.17564787, ..., -0.31037724,\n","         0.2117585 , -0.72013646],\n","       [ 0.27755183,  0.5281286 ,  0.46565056, ..., -0.02627656,\n","        -1.0990089 ,  0.6035947 ],\n","       ...,\n","       [-1.335253  ,  0.1961336 , -1.5651668 , ...,  0.45367047,\n","        -0.19601566,  0.39864418],\n","       [ 0.0829241 , -0.16347605, -0.0155003 , ..., -0.12291379,\n","         1.4254432 , -1.7024765 ],\n","       [ 0.3098106 , -0.9104556 ,  0.16078249, ...,  0.3010977 ,\n","        -0.1369821 ,  0.08949195]], dtype=float32)>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["\"\"\"\n","8) Thực hiện tích thông thường giữa ma trận R và G.\n","\"\"\"\n","R @ G"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXvFxEAGGbX7","outputId":"73548d11-20d3-454c-d2e0-854f019dd918"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(32, 32), dtype=float32, numpy=\n","array([[ -6.2129016 ,   2.5287852 ,  -0.76174295, ...,   5.558402  ,\n","         -7.3541117 ,   5.5078244 ],\n","       [ -1.2892944 ,  -0.48517695,  -8.519064  , ...,   0.23508678,\n","         -1.7641267 ,  -4.9081254 ],\n","       [ -2.3941505 ,  -2.1653955 ,   9.664059  , ...,  -2.164116  ,\n","         -2.133213  ,  -0.2624151 ],\n","       ...,\n","       [  0.7358825 ,   1.7894965 ,   9.152539  , ...,   4.2300587 ,\n","         -5.165422  ,  -4.8546505 ],\n","       [ 10.007445  ,   4.9345303 , -10.267459  , ...,  -6.130768  ,\n","          7.0766535 ,   1.3808624 ],\n","       [ -2.181734  ,   6.3415313 ,   2.0702338 , ...,   3.2810082 ,\n","         -3.9315672 ,   3.825285  ]], dtype=float32)>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["\"\"\"\n","9) Từ bộ dữ liệu Income-Classification hãy chuẩn hóa dữ liệu \n","và phân chia tập train/test theo tỷ lệ 80/20.\n","\"\"\""],"metadata":{"id":"iac2VOEICasB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwNtNBJAVjdZ","outputId":"6ae7f8a7-886f-4084-c536-02e441434906"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"drive/MyDrive/Colab Notebooks/TowardDataScience/lesson2\")"],"metadata":{"id":"N6Fmpz5pWzM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8HgdT709WnZ3","outputId":"bbe6ab97-9d39-49e1-921b-a2e343468db8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks/TowardDataScience/lesson2'"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import pandas as pd\n","\n","data = pd.read_csv('train.csv').dropna()\n","\n","sample = data.sample(10)\n","sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":600},"id":"weLB88MPWZIQ","outputId":"028b6ed7-e67e-4c70-d2e8-46f7091e64eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-4976215e-2b96-4fd2-80e0-2006c9761100\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>age</th>\n","      <th>work_type</th>\n","      <th>final_weight</th>\n","      <th>education</th>\n","      <th>total_education_yrs</th>\n","      <th>marital_state</th>\n","      <th>job</th>\n","      <th>status</th>\n","      <th>ethnicity</th>\n","      <th>sex</th>\n","      <th>capital_gain</th>\n","      <th>capital_loss</th>\n","      <th>hrs_per_week</th>\n","      <th>nationality</th>\n","      <th>target_income</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17947</th>\n","      <td>17947</td>\n","      <td>29</td>\n","      <td>Private</td>\n","      <td>134152</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Separated</td>\n","      <td>Machine-op-inspct</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>M</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7957</th>\n","      <td>7957</td>\n","      <td>20</td>\n","      <td>?</td>\n","      <td>124242</td>\n","      <td>Some-college</td>\n","      <td>10</td>\n","      <td>Never-married</td>\n","      <td>?</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>F</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21938</th>\n","      <td>21938</td>\n","      <td>42</td>\n","      <td>Private</td>\n","      <td>185602</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Wife</td>\n","      <td>White</td>\n","      <td>F</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>US</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10817</th>\n","      <td>10817</td>\n","      <td>30</td>\n","      <td>?</td>\n","      <td>96851</td>\n","      <td>Some-college</td>\n","      <td>10</td>\n","      <td>Never-married</td>\n","      <td>?</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>F</td>\n","      <td>0</td>\n","      <td>1719</td>\n","      <td>25</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>786</th>\n","      <td>786</td>\n","      <td>20</td>\n","      <td>Private</td>\n","      <td>182661</td>\n","      <td>Some-college</td>\n","      <td>10</td>\n","      <td>Never-married</td>\n","      <td>Sales</td>\n","      <td>Own-child</td>\n","      <td>Black</td>\n","      <td>M</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9935</th>\n","      <td>9935</td>\n","      <td>47</td>\n","      <td>Private</td>\n","      <td>176239</td>\n","      <td>Some-college</td>\n","      <td>10</td>\n","      <td>Widowed</td>\n","      <td>Prof-specialty</td>\n","      <td>Unmarried</td>\n","      <td>White</td>\n","      <td>F</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1330</th>\n","      <td>1330</td>\n","      <td>28</td>\n","      <td>Local-gov</td>\n","      <td>296537</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Craft-repair</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>M</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>45</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11924</th>\n","      <td>11924</td>\n","      <td>25</td>\n","      <td>Self-emp-inc</td>\n","      <td>161007</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>M</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20801</th>\n","      <td>20801</td>\n","      <td>45</td>\n","      <td>Private</td>\n","      <td>168038</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>M</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15835</th>\n","      <td>15835</td>\n","      <td>19</td>\n","      <td>Private</td>\n","      <td>175820</td>\n","      <td>11th</td>\n","      <td>7</td>\n","      <td>Never-married</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Own-child</td>\n","      <td>White</td>\n","      <td>M</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>US</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4976215e-2b96-4fd2-80e0-2006c9761100')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4976215e-2b96-4fd2-80e0-2006c9761100 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4976215e-2b96-4fd2-80e0-2006c9761100');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          ID  age     work_type  ...  hrs_per_week nationality  target_income\n","17947  17947   29       Private  ...            40          US              0\n","7957    7957   20             ?  ...            40          US              0\n","21938  21938   42       Private  ...            40          US              1\n","10817  10817   30             ?  ...            25          US              0\n","786      786   20       Private  ...            20          US              0\n","9935    9935   47       Private  ...            40          US              0\n","1330    1330   28     Local-gov  ...            45          US              0\n","11924  11924   25  Self-emp-inc  ...            40          US              0\n","20801  20801   45       Private  ...            32          US              0\n","15835  15835   19       Private  ...            25          US              0\n","\n","[10 rows x 16 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","features = ['age', 'final_weight', 'total_education_yrs', 'capital_gain', \n","            'capital_loss', 'hrs_per_week']\n","label = 'target_income'\n","   \n","# Split data 80%-20% into training set and test set\n","x_train, x_test, y_train, y_test = train_test_split(data[features].values, # input variable\n","                                                    data[label].values, # output variable\n","                                                    test_size=0.20, # test dataset proportion\n","                                                    stratify=data['target_income'], # assign equal proportion of target label in train/test \n","                                                    random_state=0) # keep train/test split the same if run again. \n","\n","print('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n","print(\"Sample of features and labels:\")\n","\n","# Take a look at the first 25 training features and corresponding labels\n","for n in range(0,24):\n","    print(x_train[n], y_train[n])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vEXm59ZavKL6","outputId":"746c0524-f434-47a7-bb64-a5065b9db863"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Set: 20000, Test Set: 5000 \n","\n","Sample of features and labels:\n","[    25 188488      9      0      0     40] 0\n","[    43 315971     14      0      0     40] 0\n","[   41 27305     9  7688     0    40] 1\n","[    46 216414     10      0      0     40] 1\n","[    24 207940      9      0      0     30] 0\n","[    50 256861      9      0      0     80] 0\n","[    71 210673      9      0      0     28] 0\n","[    54 185936      5      0      0     15] 0\n","[    41 171615     12      0      0     45] 1\n","[    25 239120     13      0      0     13] 0\n","[   44 99651    14  5178     0    40] 1\n","[    25 557082      9      0      0     38] 0\n","[   43 64112    10     0     0    50] 0\n","[    57 127728     15  15024      0     60] 1\n","[    40 175304     10      0      0     40] 0\n","[    47 106252     13      0      0     50] 0\n","[   32 98656    14     0     0    40] 0\n","[    51 205884     10      0      0     40] 1\n","[    36 269318     13      0      0     50] 1\n","[    59 283005      7      0      0     40] 0\n","[    30 312667     10      0      0     40] 0\n","[    29 240738      9      0      0     40] 1\n","[    35 210150      9      0      0     40] 0\n","[   39 74163     8     0     0    40] 0\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"aPQFeTu5vKXT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","10) Xây dựng một mạng deep-neural-network để huấn luyện mô hình \n","trên dữ liệu train và đánh giá mô hình trên dữ liệu test.\n","\"\"\""],"metadata":{"id":"JzRF0FDYCa0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip freeze | grep tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6TKIdK0xIzz","outputId":"05c1939f-3263-4382-876d-8cee510c06e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow @ file:///tensorflow-2.7.0-cp37-cp37m-linux_x86_64.whl\n","tensorflow-datasets==4.0.1\n","tensorflow-estimator==2.7.0\n","tensorflow-gcs-config==2.7.0\n","tensorflow-hub==0.12.0\n","tensorflow-io-gcs-filesystem==0.23.1\n","tensorflow-metadata==1.6.0\n","tensorflow-probability==0.15.0\n"]}]},{"cell_type":"code","source":["import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras import models\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import utils\n","from tensorflow.keras import optimizers\n","\n","# Set random seed for reproducability\n","tensorflow.random.set_seed(0)\n","\n","print(\"Libraries imported.\")\n","print('Keras version:',keras.__version__)\n","print('TensorFlow version:',tensorflow.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2rUEZfFxI3K","outputId":"08d71a58-22d9-4c99-e973-da9d72377c93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Libraries imported.\n","Keras version: 2.7.0\n","TensorFlow version: 2.7.0\n"]}]},{"cell_type":"code","source":["# Set data types for float features\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# Set data types for categorical labels\n","y_train = utils.to_categorical(y_train)\n","y_test = utils.to_categorical(y_test)\n","print('Ready...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O22RpK04xI7D","outputId":"1c2812a7-b385-491a-fe92-580159c0091f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ready...\n"]}]},{"cell_type":"code","source":["hl = 10 # Number of hidden layer nodes\n","\n","model = Sequential()\n","model.add(Dense(hl, input_dim=len(features), activation='relu'))\n","model.add(Dense(hl, input_dim=hl, activation='relu'))\n","model.add(Dense(2, input_dim=hl, activation='softmax'))\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8hYAi-ixI_f","outputId":"a147de62-7c3b-469d-f905-1ef94a63f04b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 10)                70        \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                110       \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 22        \n","                                                                 \n","=================================================================\n","Total params: 202\n","Trainable params: 202\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["#hyper-parameters for optimizer\n","learning_rate = 0.001\n","opt = optimizers.Adam(lr=learning_rate)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\n","num_epochs = 80\n","history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjQpW3WexrFs","outputId":"b550701a-c5a3-4ad8-a3a3-97abd179c7d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","2000/2000 [==============================] - 4s 2ms/step - loss: 1204.8092 - accuracy: 0.6234 - val_loss: 6.0885 - val_accuracy: 0.2394\n","Epoch 2/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 7.5680 - accuracy: 0.6393 - val_loss: 4.0394 - val_accuracy: 0.7680\n","Epoch 3/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 5.1818 - accuracy: 0.6410 - val_loss: 1.8638 - val_accuracy: 0.7682\n","Epoch 4/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 1.5035 - accuracy: 0.6735 - val_loss: 0.6009 - val_accuracy: 0.7640\n","Epoch 5/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5605 - accuracy: 0.7587 - val_loss: 0.5340 - val_accuracy: 0.7640\n","Epoch 6/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5512 - accuracy: 0.7621 - val_loss: 0.5519 - val_accuracy: 0.7712\n","Epoch 7/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5561 - accuracy: 0.7616 - val_loss: 0.5482 - val_accuracy: 0.7622\n","Epoch 8/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7616 - val_loss: 0.5481 - val_accuracy: 0.7622\n","Epoch 9/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5490 - accuracy: 0.7616 - val_loss: 0.5481 - val_accuracy: 0.7622\n","Epoch 10/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7616 - val_loss: 0.5481 - val_accuracy: 0.7622\n","Epoch 11/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7616 - val_loss: 0.5481 - val_accuracy: 0.7622\n","Epoch 12/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5587 - accuracy: 0.7617 - val_loss: 0.5453 - val_accuracy: 0.7642\n","Epoch 13/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5502 - accuracy: 0.7617 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 14/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 15/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 16/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 17/80\n","2000/2000 [==============================] - 5s 3ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 18/80\n","2000/2000 [==============================] - 4s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 19/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5490 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 20/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 21/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 22/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 23/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 24/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 25/80\n","2000/2000 [==============================] - 6s 3ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 26/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 27/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 28/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 29/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 30/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 31/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 32/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 33/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 34/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 35/80\n","2000/2000 [==============================] - 5s 3ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 36/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 37/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 38/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 39/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 40/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 41/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 42/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 43/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 44/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 45/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 46/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 47/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 48/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 49/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 50/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 51/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 52/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 53/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 54/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 55/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 56/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 57/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 58/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 59/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 60/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 61/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 62/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 63/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 64/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 65/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 66/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 67/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 68/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5491 - val_accuracy: 0.7616\n","Epoch 69/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 70/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 71/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 72/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 73/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 74/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 75/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 76/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 77/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 78/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 79/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n","Epoch 80/80\n","2000/2000 [==============================] - 3s 2ms/step - loss: 0.5492 - accuracy: 0.7615 - val_loss: 0.5490 - val_accuracy: 0.7616\n"]}]},{"cell_type":"code","source":["%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","epoch_nums = range(1,num_epochs+1)\n","training_loss = history.history[\"loss\"]\n","validation_loss = history.history[\"val_loss\"]\n","plt.plot(epoch_nums, training_loss)\n","plt.plot(epoch_nums, validation_loss)\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['training', 'validation'], loc='upper right')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"I0o9IGtJxrJa","outputId":"040ecc41-c8e0-4933-ef2a-d3735d687b24"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfa0lEQVR4nO3de5SU1Z3u8e9TF0UuCgKiAhEmYSmCKNgSPIwZFWPQJGqMFzy5qGPCOi7nGCdZEzGZExInWcuscanxHDVDoolxjIbBGD05Jt6CSZylRFBCUHQkitJ4oUHBC96A3/nj3V0URVV303R1FfB8lr36rf2+VfWjqu2n9373u0sRgZmZWUdyjS7AzMyan8PCzMw65bAwM7NOOSzMzKxTDgszM+tUodEF1MOQIUNi1KhRjS7DzGynsmjRojURMbTavl0yLEaNGsXChQsbXYaZ2U5F0gu19nkYyszMOuWwMDOzTjkszMysU7vkOQsz27V88MEHtLa28u677za6lF1Cnz59GDFiBMViscv3cViYWdNrbW1lwIABjBo1CkmNLmenFhGsXbuW1tZWRo8e3eX7eRjKzJreu+++y+DBgx0UPUASgwcP3u5eWt3CQtJNklZLWlrW9q+Snpa0RNKdkgaW7btM0nJJz0j6RFn79NS2XNKsetVrZs3NQdFzuvNa1rNn8VNgekXb/cD4iJgA/BdwGYCkQ4EZwLh0n+sl5SXlgeuAk4BDgXPSsXXx9nsbueq+Z1i8cl29nsLMbKdUt7CIiD8Ar1W03RcRG9PNR4ERaftU4PaIeC8ingeWA5PT1/KIeC4i3gduT8fWxbsfbOLa3y3nzw4LMyuzbt06rr/++u2+38knn8y6dR3/PvnWt77FAw880N3Sek0jz1n8PfCbtD0cWFm2rzW11WrfhqSZkhZKWtjW1tatggr57OX4YNPmbt3fzHZNtcJi48aNVY7e4p577mHgwIEdHnP55Zdzwgkn7FB9vaEhYSHpm8BG4NaeesyImBMRLRHRMnRo1aVNOlXMZ+N4Gzf70wPNbItZs2bx17/+lSOOOIKjjjqKY445hlNOOYVDD81GxU877TSOPPJIxo0bx5w5c0r3GzVqFGvWrGHFihWMHTuWL3/5y4wbN44TTzyRd955B4DzzjuPefPmlY6fPXs2kyZN4rDDDuPpp58GoK2tjY9//OOMGzeOL33pSxx00EGsWbOmV1+DXp86K+k84FPAtNjyma6rgJFlh41IbXTQ3uMKuSw7N7pnYda0vvN/n+Spl97o0cc89MC9mf3pcTX3X3HFFSxdupTFixfz0EMP8clPfpKlS5eWpp7edNNN7LvvvrzzzjscddRRfPazn2Xw4MFbPcazzz7Lbbfdxo9+9CPOOuss7rjjDj7/+c9v81xDhgzh8ccf5/rrr+fKK6/kxz/+Md/5znc4/vjjueyyy/jtb3/LjTfe2KP//q7o1Z6FpOnA14FTImJD2a67gRmS9pQ0GhgD/Al4DBgjabSkPchOgt9dr/raexYfbHLPwsxqmzx58lbXKFx77bUcfvjhTJkyhZUrV/Lss89uc5/Ro0dzxBFHAHDkkUeyYsWKqo99+umnb3PMww8/zIwZMwCYPn06gwYN6sF/TdfUrWch6TbgWGCIpFZgNtnspz2B+9PUrUcj4n9ExJOS5gJPkQ1PXRQRm9Lj/ANwL5AHboqIJ+tYM/mc2LjZPQuzZtVRD6C39OvXr7T90EMP8cADD/DII4/Qt29fjj322KrXMOy5556l7Xw+XxqGqnVcPp/v9JxIb6pbWETEOVWaa/adIuJ7wPeqtN8D3NODpXWokBMb3bMwszIDBgzgzTffrLpv/fr1DBo0iL59+/L000/z6KOP9vjzT506lblz53LppZdy33338frrr/f4c3TGy31UKOZzHoYys60MHjyYqVOnMn78ePbaay+GDRtW2jd9+nR++MMfMnbsWA4++GCmTJnS488/e/ZszjnnHG655RaOPvpo9t9/fwYMGNDjz9MRbTnHvOtoaWmJ7n740RGX38cphx/I5aeO7+GqzKy7li1bxtixYxtdRsO899575PN5CoUCjzzyCBdeeCGLFy/eoces9ppKWhQRLdWOd8+iQiHnnoWZNZcXX3yRs846i82bN7PHHnvwox/9qNdrcFhUKOblqbNm1lTGjBnDE0880dAavOpshUJevijPzKyCw6JCMZfzch9mZhUcFhUKeU+dNTOr5LCoUMjlfFGemVkFh0WFYl6eDWVmO6R///4AvPTSS5xxxhlVjzn22GPpbIr/Nddcw4YNW1ZG6sqS5/XisKhQyLtnYWY948ADDyytKNsdlWHRlSXP68VhUaGQc8/CzLY2a9YsrrvuutLtb3/723z3u99l2rRppeXE77rrrm3ut2LFCsaPzy7wfeedd5gxYwZjx47lM5/5zFZrQ1144YW0tLQwbtw4Zs+eDWSLE7700kscd9xxHHfcccCWJc8BrrrqKsaPH8/48eO55pprSs9Xayn0HeXrLCoU8zk2vN88i3eZWYXfzIJX/tKzj7n/YXDSFTV3n3322VxyySVcdNFFAMydO5d7772Xiy++mL333ps1a9YwZcoUTjnllJqfb33DDTfQt29fli1bxpIlS5g0aVJp3/e+9z323XdfNm3axLRp01iyZAkXX3wxV111FfPnz2fIkCFbPdaiRYv4yU9+woIFC4gIPvrRj/J3f/d3DBo0qMtLoW8v9ywq+DoLM6s0ceJEVq9ezUsvvcSf//xnBg0axP777883vvENJkyYwAknnMCqVat49dVXaz7GH/7wh9Iv7QkTJjBhwoTSvrlz5zJp0iQmTpzIk08+yVNPPdVhPQ8//DCf+cxn6NevH/379+f000/nj3/8I9D1pdC3l3sWFQq5HO9v9DkLs6bVQQ+gns4880zmzZvHK6+8wtlnn82tt95KW1sbixYtolgsMmrUqKpLk3fm+eef58orr+Sxxx5j0KBBnHfeed16nHZdXQp9e7lnUaHonoWZVXH22Wdz++23M2/ePM4880zWr1/PfvvtR7FYZP78+bzwwgsd3v9jH/sYP//5zwFYunQpS5YsAeCNN96gX79+7LPPPrz66qv85je/Kd2n1tLoxxxzDL/61a/YsGEDb7/9NnfeeSfHHHNMD/5rt+WeRYVCPue1ocxsG+PGjePNN99k+PDhHHDAAXzuc5/j05/+NIcddhgtLS0ccsghHd7/wgsv5Pzzz2fs2LGMHTuWI488EoDDDz+ciRMncsghhzBy5EimTp1aus/MmTOZPn06Bx54IPPnzy+1T5o0ifPOO4/JkycD8KUvfYmJEyf22JBTNV6ivMJXf7GYBc+/xn/OOr6HqzKz7trdlyivh+1dotzDUBWyE9zuWZiZlXNYVMiGoXa93paZ2Y5wWFQo5uRVZ82a0K44ZN4o3XktHRYVsuU+/ENp1kz69OnD2rVrHRg9ICJYu3Ytffr02a77eTZUhaKHocyazogRI2htbaWtra3RpewS+vTpw4gRI7brPg6LCsW8+MAnuM2aSrFYZPTo0Y0uY7fmYagKhVyOCNjkoSgzs5K6hYWkmyStlrS0rG1fSfdLejZ9H5TaJelaScslLZE0qew+56bjn5V0br3qbVfIZ4uA+SS3mdkW9exZ/BSYXtE2C3gwIsYAD6bbACcBY9LXTOAGyMIFmA18FJgMzG4PmHopprDwSW4zsy3qFhYR8QfgtYrmU4Gb0/bNwGll7T+LzKPAQEkHAJ8A7o+I1yLideB+tg2gHlXIZS+Jl/wwM9uit89ZDIuIl9P2K8CwtD0cWFl2XGtqq9W+DUkzJS2UtHBHZkwUS8NQ7lmYmbVr2AnuyCZM99hv5IiYExEtEdEydOjQbj9OIZ96Fp4RZWZW0tth8WoaXiJ9X53aVwEjy44bkdpqtddNIZfOWbhnYWZW0tthcTfQPqPpXOCusvYvpllRU4D1abjqXuBESYPSie0TU1vdFFPPwrOhzMy2qNtFeZJuA44FhkhqJZvVdAUwV9IFwAvAWenwe4CTgeXABuB8gIh4TdK/AI+l4y6PiMqT5j2q4NlQZmbbqFtYRMQ5NXZNq3JsABfVeJybgJt6sLQOtc+Gcs/CzGwLX8FdoXSdhc9ZmJmVOCwqeDaUmdm2HBYVijlfZ2FmVslhUaHUs3BYmJmVOCwqlBYS9DCUmVmJw6JCMeeehZlZJYdFhdJ1Fp46a2ZW4rCoUFpI0BflmZmVOCwqeIlyM7NtOSwqFHxRnpnZNhwWFUoLCXo2lJlZicOigpcoNzPblsOiQsFLlJuZbcNhUaHoJcrNzLbhsKjg2VBmZttyWFQoXWfhcxZmZiUOiwqSyOfkJcrNzMo4LKoo5OTZUGZmZRwWVRTzOQ9DmZmVcVhUUch7GMrMrJzDoopCzj0LM7NyDosqinl56qyZWRmHRRXZMJR7FmZm7RwWVRRzOS/3YWZWpiFhIekfJT0paamk2yT1kTRa0gJJyyX9QtIe6dg90+3laf+oetdXyHvqrJlZuV4PC0nDgYuBlogYD+SBGcD3gasj4iPA68AF6S4XAK+n9qvTcXVVyOU8G8rMrEyjhqEKwF6SCkBf4GXgeGBe2n8zcFraPjXdJu2fJkn1LK6Yl2dDmZmV6fWwiIhVwJXAi2QhsR5YBKyLiI3psFZgeNoeDqxM992Yjh9c+biSZkpaKGlhW1vbDtVYyLtnYWZWrhHDUIPIegujgQOBfsD0HX3ciJgTES0R0TJ06NAdeqxCzj0LM7NyjRiGOgF4PiLaIuID4JfAVGBgGpYCGAGsSturgJEAaf8+wNp6Fpgt9+GehZlZu0aExYvAFEl907mHacBTwHzgjHTMucBdafvudJu0/3cRUdc/+z0bysxsa404Z7GA7ET148BfUg1zgEuBr0paTnZO4sZ0lxuBwan9q8CsetdY8HUWZmZbKXR+SM+LiNnA7Irm54DJVY59FzizN+pqV/QV3GZmW/EV3FUU8jmvDWVmVsZhUUXRs6HMzLbisKjCn2dhZrY1h0UV2TCUexZmZu0cFlVkw1DuWZiZtXNYVJEt9+GehZlZO4dFFb4oz8xsaw6LKoq5HB/4BLeZWYnDoopCXkTAJg9FmZkBDouqivnsZfFJbjOzjMOiimI++2wln+Q2M8s4LKoo5LKXxUt+mJllHBZVtPcsvOSHmVnGYVFFIZ2z8JIfZmYZh0UVhVw6Z+GehZkZ4LCoyrOhzMy25rCoouDZUGZmW3FYVNE+G8o9CzOzjMOiitJ1Fj5nYWYGOCyq8mwoM7OtdSksJH1F0t7K3CjpcUkn1ru4RinmfJ2FmVm5rvYs/j4i3gBOBAYBXwCuqFtVDVbqWTgszMyAroeF0veTgVsi4smytl1O+2woL1NuZpbpalgsknQfWVjcK2kA0O3fpJIGSpon6WlJyyQdLWlfSfdLejZ9H5SOlaRrJS2XtETSpO4+b1cVc+5ZmJmV62pYXADMAo6KiA1AETh/B573B8BvI+IQ4HBgWXr8ByNiDPBgug1wEjAmfc0EbtiB5+2S0nUWnjprZgZ0PSyOBp6JiHWSPg/8M7C+O08oaR/gY8CNABHxfkSsA04Fbk6H3QyclrZPBX4WmUeBgZIO6M5zd1VpIUFflGdmBnQ9LG4ANkg6HPga8FfgZ918ztFAG/ATSU9I+rGkfsCwiHg5HfMKMCxtDwdWlt2/NbXVjZcoNzPbWlfDYmNEBNlf+f8nIq4DBnTzOQvAJOCGiJgIvM2WIScA0nNt15/1kmZKWihpYVtbWzdLSwX6ojwzs610NSzelHQZ2ZTZ/ycpR3beojtagdaIWJBuzyMLj1fbh5fS99Vp/ypgZNn9R6S2rUTEnIhoiYiWoUOHdrO0TGkhQc+GMjMDuh4WZwPvkV1v8QrZL+x/7c4TpvuvlHRwapoGPAXcDZyb2s4F7krbdwNfTLOipgDry4ar6sJLlJuZba3QlYMi4hVJtwJHSfoU8KeI6O45C4D/CdwqaQ/gObKZVTlgrqQLgBeAs9Kx95BN2V0ObGDHZmF1ScFLlJuZbaVLYSHpLLKexENkF+P9b0n/FBHzuvOkEbEYaKmya1qVYwO4qDvP011FL1FuZraVLoUF8E2yayxWA0gaCjxAdr5hl+PZUGZmW+vqOYtce1Aka7fjvjud0nUWPmdhZgZ0vWfxW0n3Arel22eTnUvYJUkin5OXKDczS7p6gvufJH0WmJqa5kTEnfUrq/EKOXk2lJlZ0tWeBRFxB3BHHWtpKsV8zsNQZmZJh2Eh6U2qX0ktsolKe9elqiZQyHsYysysXYdhERHdXdJjp1fIuWdhZtZul53RtKOKeXnqrJlZ4rCoIRuGcs/CzAwcFjUVczkv92FmljgsaijkPXXWzKydw6KGQi7n2VBmZonDooZiXp4NZWaWOCxqKOR9zsLMrJ3DogYv92FmtoXDooZiPuePVTUzSxwWNXg2lJnZFg6LGgq+zsLMrMRhUUPRV3CbmZU4LGoo5HNeG8rMLHFY1FDM+ToLM7N2Dosa/HkWZmZbOCxqyIah3LMwMwOHRU3ZMJR7FmZm0MCwkJSX9ISkX6fboyUtkLRc0i8k7ZHa90y3l6f9o3qjvkI+59lQZmZJI3sWXwGWld3+PnB1RHwEeB24ILVfALye2q9Ox9WdL8ozM9uiIWEhaQTwSeDH6baA44F56ZCbgdPS9qnpNmn/tHR8XRVzXu7DzKxdo3oW1wBfB9p/Gw8G1kXExnS7FRietocDKwHS/vXp+K1ImilpoaSFbW1tO1xgIS8iYJOHoszMej8sJH0KWB0Ri3rycSNiTkS0RETL0KFDd/jxivnspfFJbjMzKDTgOacCp0g6GegD7A38ABgoqZB6DyOAVen4VcBIoFVSAdgHWFvvIgu5bKTLJ7nNzBrQs4iIyyJiRESMAmYAv4uIzwHzgTPSYecCd6Xtu9Nt0v7fRUTdf4MXUs/CS36YmTXXdRaXAl+VtJzsnMSNqf1GYHBq/yowqzeK2SOf9Sy85IeZWWOGoUoi4iHgobT9HDC5yjHvAmf2amGU9Sw8I8rMrKl6Fk2ldM7CPQszM4dFLZ4NZWa2hcOihkLes6HMzNo5LGoo5NyzMDNr57CooZj3OQszs3YOixo8G8rMbAuHRQ3FnK+zMDNr57CoYcsV3A4LMzOHRQ3ts6G8TLmZmcOipmLOPQszs3YOixpK11l46qyZmcOilmJpGMo9CzMzh0UNhZyXKDcza+ewqKHgi/LMzEocFjWUFhL0bCgzM4dFLV6i3MxsC4dFDQUvUW5mVuKwqKHoJcrNzEocFjV4NpSZ2RYOixpK11n4nIWZmcOiFknkc/IS5WZmOCw6VMjJs6HMzHBYdKiYz3kYyswMh0WHCnkPQ5mZQQPCQtJISfMlPSXpSUlfSe37Srpf0rPp+6DULknXSlouaYmkSb1VayHnnoWZGTSmZ7ER+FpEHApMAS6SdCgwC3gwIsYAD6bbACcBY9LXTOCG3iq0mJenzpqZ0YCwiIiXI+LxtP0msAwYDpwK3JwOuxk4LW2fCvwsMo8CAyUd0Bu1ZsNQ7lmYmTX0nIWkUcBEYAEwLCJeTrteAYal7eHAyrK7taa2yseaKWmhpIVtbW09Ul8xl/NyH2ZmNDAsJPUH7gAuiYg3yvdFRADb9Sd9RMyJiJaIaBk6dGiP1FjIe+qsmRk0KCwkFcmC4taI+GVqfrV9eCl9X53aVwEjy+4+IrXVXSGX82woMzMaMxtKwI3Asoi4qmzX3cC5aftc4K6y9i+mWVFTgPVlw1V1VcyL992zMDOj0IDnnAp8AfiLpMWp7RvAFcBcSRcALwBnpX33ACcDy4ENwPm9VWghn/NsKDMzGhAWEfEwoBq7p1U5PoCL6lpUDV7uw8ws4yu4O1DM5/yxqmZmOCw65NlQZmYZh0UHCr7OwswMcFh0qOgruM3MAIdFhzwbysws47DoQDEnrzprZobDokP+PAszs4zDogPZMJR7FmZmDosOZMNQ7lmYmTksOlDI5zwbyswMh0WHfFGemVnGYdGBYs7LfZiZgcOiQ4W8iIBNHooys92cw6IDxXz28vgkt5nt7hwWHSjkspXUfZLbzHZ3DosOFFLPwkt+mNnuzmHRgWI+61l4yQ8z2905LDpQyKWehWdEmdluzmHRgULqWfhaCzPb3TksOrCHZ0OZmQEOiw6VehaeDWVmuzmHRQfaz1m4Z2FmuzuHRQeKPmdhZgY4LDpUus7Cs6HMbDe304SFpOmSnpG0XNKs3njOYs7XWZiZARQaXUBXSMoD1wEfB1qBxyTdHRFP9egTvf823HI69BsC/fdj1Mb+fCH/Bnf8++PcOWAY+QHD6Dtof4YPG8KH99ubD+/XnwP27kMuhYqZ2a5qpwgLYDKwPCKeA5B0O3Aq0LNh8cE7kC/C2uXw4iMcsOE1/qUYsBlYn75aYfMS8RZ9eIu9WBF7goTSF9l/ZRwkZtZ71vT7CEd+7Vc9/rg7S1gMB1aW3W4FPlp+gKSZwEyAD33oQ917ln5D4Lxfb3nMTRthw1p4ezW89Sq81Ua83cY7b77O2+tf45031vH+u2+xeXOwafNmNm8ONoeHrMyscd7f+6C6PO7OEhadiog5wByAlpaWnvmNnS/AgGHZF4cBWT+hX/oyM9td7CwnuFcBI8tuj0htZmbWC3aWsHgMGCNptKQ9gBnA3Q2uycxst7FTDENFxEZJ/wDcC+SBmyLiyQaXZWa229gpwgIgIu4B7ml0HWZmu6OdZRjKzMwayGFhZmadcliYmVmnHBZmZtYpxS54xbGkNuCF7bjLEGBNncrZEc1aFzRvbc1aFzRvbc1aF7i27tiRug6KiKHVduySYbG9JC2MiJZG11GpWeuC5q2tWeuC5q2tWesC19Yd9arLw1BmZtYph4WZmXXKYZGZ0+gCamjWuqB5a2vWuqB5a2vWusC1dUdd6vI5CzMz65R7FmZm1imHhZmZdWq3DgtJ0yU9I2m5pFkNruUmSaslLS1r21fS/ZKeTd8HNaCukZLmS3pK0pOSvtJEtfWR9CdJf061fSe1j5a0IL2vv0jL2vc6SXlJT0j6dZPVtULSXyQtlrQwtTXD+zlQ0jxJT0taJunoJqnr4PRatX+9IemSJqntH9PP/lJJt6X/J+ryc7bbhoWkPHAdcBJwKHCOpEMbWNJPgekVbbOAByNiDPBgut3bNgJfi4hDgSnARel1aoba3gOOj4jDgSOA6ZKmAN8Hro6IjwCvAxc0oDaArwDLym43S10Ax0XEEWXz8Zvh/fwB8NuIOAQ4nOy1a3hdEfFMeq2OAI4ENgB3Nro2ScOBi4GWiBhP9vENM6jXz1lE7JZfwNHAvWW3LwMua3BNo4ClZbefAQ5I2wcAzzTB63YX8PFmqw3oCzxO9tnsa4BCtfe5F+sZQfYL5Hjg12SfyNvwutJzrwCGVLQ19P0E9gGeJ026aZa6qtR5IvCfzVAbMBxYCexL9nETvwY+Ua+fs922Z8GWF7pda2prJsMi4uW0/QowrJHFSBoFTAQW0CS1paGexcBq4H7gr8C6iNiYDmnU+3oN8HVgc7o9uEnqAgjgPkmLJM1MbY1+P0cDbcBP0tDdjyX1a4K6Ks0AbkvbDa0tIlYBVwIvAi8D64FF1OnnbHcOi51KZH8mNGyes6T+wB3AJRHxRvm+RtYWEZsiGx4YAUwGDmlEHeUkfQpYHRGLGl1LDX8bEZPIhmAvkvSx8p0Nej8LwCTghoiYCLxNxbBOE/w/sAdwCvAflfsaUVs6R3IqWdAeCPRj26HsHrM7h8UqYGTZ7RGprZm8KukAgPR9dSOKkFQkC4pbI+KXzVRbu4hYB8wn63YPlNT+KZCNeF+nAqdIWgHcTjYU9YMmqAso/UVKRKwmG3ufTOPfz1agNSIWpNvzyMKj0XWVOwl4PCJeTbcbXdsJwPMR0RYRHwC/JPvZq8vP2e4cFo8BY9LMgT3Iupd3N7imSncD56btc8nOF/QqSQJuBJZFxFVNVttQSQPT9l5k51KWkYXGGY2qLSIui4gRETGK7OfqdxHxuUbXBSCpn6QB7dtkY/BLafD7GRGvACslHZyapgFPNbquCuewZQgKGl/bi8AUSX3T/6ftr1l9fs4aebKo0V/AycB/kY1zf7PBtdxGNu74AdlfWReQjXM/CDwLPADs24C6/pase70EWJy+Tm6S2iYAT6TalgLfSu1/A/wJWE42ZLBnA9/XY4FfN0tdqYY/p68n23/um+T9PAJYmN7PXwGDmqGuVFs/YC2wT1lbw2sDvgM8nX7+bwH2rNfPmZf7MDOzTu3Ow1BmZtZFDgszM+uUw8LMzDrlsDAzs045LMzMrFMOC7MmI+nY9pVqzZqFw8LMzDrlsDDrJkmfT5+nsVjSv6VFDd+SdHX6jIEHJQ1Nxx4h6VFJSyTd2f7ZB5I+IumB9Jkcj0v6cHr4/mWf7XBrukLXrGEcFmbdIGkscDYwNbKFDDcBnyO70ndhRIwDfg/MTnf5GXBpREwA/lLWfitwXWSfyfHfyK7ih2x130vIPmvlb8jW/DFrmELnh5hZFdPIPgjnsfRH/15kC8ltBn6Rjvl34JeS9gEGRsTvU/vNwH+kNZqGR8SdABHxLkB6vD9FRGu6vZjss04erv8/y6w6h4VZ9wi4OSIu26pR+l8Vx3V3PZ33yrY34f9XrcE8DGXWPQ8CZ0jaD0qfYX0Q2f9T7St+/nfg4YhYD7wu6ZjU/gXg9xHxJtAq6bT0GHtK6tur/wqzLvJfK2bdEBFPSfpnsk+cy5GtFnwR2Yf2TE77VpOd14BsqegfpjB4Djg/tX8B+DdJl6fHOLMX/xlmXeZVZ816kKS3IqJ/o+sw62kehjIzs065Z2FmZp1yz8LMzDrlsDAzs045LMzMrFMOCzMz65TDwszMOvX/AdzZL4VSl+AwAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Save the trained model\n","modelFileName = 'models/lesson2.h5'\n","model.save(modelFileName)\n","del model  # deletes the existing model variable\n","print('model saved as', modelFileName)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWoUKWF2xrMP","outputId":"7b9e387b-2a0a-40c1-a5d1-21273355c1a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model saved as models/=lesson2.h5\n"]}]},{"cell_type":"markdown","source":["# Nên hiển thị kết quả acc,f1,.. sau khi huấn luyện mô hình. Đưa ra các nhận xét về kết quả mô hình. Thử nghiệm thêm xử lý dữ liệu, thay đổi tham số mô hình.\n","# Cấp quyền muộn trừ 0.5"],"metadata":{"id":"Oi3flK4UgcT1"}},{"cell_type":"code","source":[""],"metadata":{"id":"YQb-9_LiguJ4"},"execution_count":null,"outputs":[]}]}