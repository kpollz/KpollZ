{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.Neural network and DL_Nguyễn Viết Long",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết\n",
        "\n",
        "1) Tại sao các mô hình deep learning lại chiếm ưu thế hơn so với các mô hình machine learning truyền thống đối với dữ liệu lớn ?\n",
        "\n",
        "A. Do mô hình deep learning có thể được thiết kế với kích thước tùy ý nên có khả năng xấp xỉ mọi hàm số. Do đó nó có khả năng biểu diễn tốt và hoạt động hiệu quả trên dữ liệu lớn.\n",
        "\n",
        "B. Các mô hình machine learning thường bị overfitting đối với dữ liệu lớn \n",
        "\n",
        "C. Các mô hình deep learning có chi phí huấn luyện tốn kém hơn so với machine learning.\n",
        "\n",
        "D. Do kiến trúc của mô hình Machine Learning bao gồm nhiều layers xếp chồng.\n",
        "\n",
        "=> Đáp án A\n",
        "\n",
        "2) Ý nghĩa của hàm loss function trong mạng neural network là gì ?\n",
        "\n",
        "A. Là hàm số đánh giá độ chính xác của mô hình.\n",
        "\n",
        "B. Mục tiêu của quá trình huấn luyện là tối thiểu hóa hàm loss function bằng thuật toán gradient descent. Giá trị của hàm số này giúp đo lường mức độ khớp của dự báo từ mô hình trên dữ liệu huấn luyện.\n",
        "\n",
        "C. Khi loss function giảm thì luôn đảm bảo độ chính xác của mô hình tăng.\n",
        "\n",
        "D. Là hàm số cần tối đa hóa trong quá trình huấn luyện.\n",
        "\n",
        "=> Đáp án B\n",
        "\n",
        "3) Khi huấn luyện trên các bộ dữ liệu bigdata thì chúng ta nên sử dụng phương pháp nào ?\n",
        "\n",
        "A) Sử dụng gradient descent trên toàn bộ dữ liệu.\n",
        "\n",
        "B) Sử dụng stochastic gradient descent trên từng điểm dữ liệu.\n",
        "\n",
        "C) Mini-batch gradient descent huấn luyện mô hình trên từng tập dữ liệu con có kích thước nhỏ hơn memory CPU/GPU.\n",
        "\n",
        "D) Có thể sử dụng stochastic gradient descent hoặc mini-batch gradient descent.\n",
        "\n",
        "=> Đáp án C\n",
        "\n",
        "4) Quá trình feed forward và backpropagation thực hiện những gì ?\n",
        "\n",
        "A) feed forward tính toán output và loss function, backpropagation tính đạo hàm trên từng layer và cập nhật trọng số.\n",
        "\n",
        "B) feed forward cập nhật trọng số cho mô hình, backpropagation tính toán output và loss function.\n",
        "\n",
        "C) feed forward tính ra output của mô hình, backpropagation tính toán loss function\n",
        "\n",
        "D) feed forward được thực hiện sau backpropagation.\n",
        "\n",
        "=> Đáp án A\n",
        "\n",
        "5) Tác dụng của batch normalization là gì ?\n",
        "\n",
        "A) Loại bỏ một tỷ lệ ngẫu nhiên số lượng units tại mỗi layer để tạo thành nhiều kiến trúc kết hợp ngẫu nhiên.\n",
        "\n",
        "B) Tìm ra các tham số phân phối là trung bình và phương sai trên từng mini-batch.\n",
        "\n",
        "C) Đồng nhất phân phối xác suất của $z^{[l]}$ trên mỗi layer $l$.\n",
        "\n",
        "D) Giảm thiểu ảnh hưởng của input distribution shift nhằm giúp huấn luyện loss function nhanh và ổn định hơn.\n",
        "\n",
        "=> Đáp án D\n"
      ],
      "metadata": {
        "id": "PDDUcokDmyX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành\n",
        "\n",
        "Xuất phát từ mô hình tốt nhất của bạn xây dựng được đối với bài toán phân loại income classification tại bài trước. Bạn hãy thực hiện một số thử nghiệm sau:\n",
        "\n",
        "6) Thay đổi hàm loss function, batch size và optimizer.\n",
        "\n",
        "7) Thử nghiệm thêm các layers mà bạn đã học được trong bài này vào kiến trúc của mình.\n",
        "\n",
        "8) Thay đổi các khởi tạo trọng số theo các phân phối khác nhau và đánh giá độ chính xác của kết quả huấn luyện.\n",
        "\n",
        "9) Thiết lập không gian search và tự động hóa tìm kiếm kiến trúc tốt nhất trên optuna.\n",
        "\n",
        "10) Deploy model sử dụng flask ap. Tham khảo [Flaskapp tutorial](https://drive.google.com/file/d/1AZNtzrmnhJ-OBgijWoaAqXbPhJ6xL0Po/view?usp=sharing)."
      ],
      "metadata": {
        "id": "zYoLCUgcm1Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jri0Hxt3koMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5302b913-5e8f-42a8-f495-6eb0af273c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/lesson 2/train.csv\").dropna()\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "tkNPjhffCU47",
        "outputId": "e7118dd9-8aee-443b-c4d8-1d858e17f0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8883fc5-3f8c-4d12-8a4a-215e52a7d75e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>age</th>\n",
              "      <th>work_type</th>\n",
              "      <th>final_weight</th>\n",
              "      <th>education</th>\n",
              "      <th>total_education_yrs</th>\n",
              "      <th>marital_state</th>\n",
              "      <th>job</th>\n",
              "      <th>status</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>nationality</th>\n",
              "      <th>target_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17864</th>\n",
              "      <td>17864</td>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>120781</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>South</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24946</th>\n",
              "      <td>24946</td>\n",
              "      <td>47</td>\n",
              "      <td>Private</td>\n",
              "      <td>139145</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13804</th>\n",
              "      <td>13804</td>\n",
              "      <td>36</td>\n",
              "      <td>Private</td>\n",
              "      <td>183081</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3126</th>\n",
              "      <td>3126</td>\n",
              "      <td>61</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>66614</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16927</th>\n",
              "      <td>16927</td>\n",
              "      <td>33</td>\n",
              "      <td>Private</td>\n",
              "      <td>403552</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3686</th>\n",
              "      <td>3686</td>\n",
              "      <td>32</td>\n",
              "      <td>?</td>\n",
              "      <td>285131</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18271</th>\n",
              "      <td>18271</td>\n",
              "      <td>60</td>\n",
              "      <td>Private</td>\n",
              "      <td>198170</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>US</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13550</th>\n",
              "      <td>13550</td>\n",
              "      <td>52</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>135716</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5069</th>\n",
              "      <td>5069</td>\n",
              "      <td>20</td>\n",
              "      <td>Private</td>\n",
              "      <td>56322</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10071</th>\n",
              "      <td>10071</td>\n",
              "      <td>67</td>\n",
              "      <td>?</td>\n",
              "      <td>183374</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>?</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>2329</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8883fc5-3f8c-4d12-8a4a-215e52a7d75e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8883fc5-3f8c-4d12-8a4a-215e52a7d75e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8883fc5-3f8c-4d12-8a4a-215e52a7d75e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          ID  age         work_type  ...  hrs_per_week nationality  target_income\n",
              "17864  17864   50      Self-emp-inc  ...            60       South              1\n",
              "24946  24946   47           Private  ...            60          US              0\n",
              "13804  13804   36           Private  ...            40          US              0\n",
              "3126    3126   61      Self-emp-inc  ...            40          US              0\n",
              "16927  16927   33           Private  ...            32          US              0\n",
              "3686    3686   32                 ?  ...            20          US              0\n",
              "18271  18271   60           Private  ...            45          US              1\n",
              "13550  13550   52  Self-emp-not-inc  ...            70          US              0\n",
              "5069    5069   20           Private  ...            20          US              0\n",
              "10071  10071   67                 ?  ...            15          US              0\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(\"ID\", axis = 1)\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "CePKFutnChMT",
        "outputId": "46465d9a-508a-40d1-95f7-af6ae795e6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bf888979-3e12-46ac-ab2f-09fe7416b462\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>final_weight</th>\n",
              "      <th>total_education_yrs</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>target_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25000.000000</td>\n",
              "      <td>2.500000e+04</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>38.568800</td>\n",
              "      <td>1.900156e+05</td>\n",
              "      <td>10.079160</td>\n",
              "      <td>1051.950240</td>\n",
              "      <td>86.053160</td>\n",
              "      <td>40.392200</td>\n",
              "      <td>0.23944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.642694</td>\n",
              "      <td>1.059694e+05</td>\n",
              "      <td>2.566125</td>\n",
              "      <td>7228.975017</td>\n",
              "      <td>400.535454</td>\n",
              "      <td>12.350547</td>\n",
              "      <td>0.42675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.228500e+04</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>1.178315e+05</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.786440e+05</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>2.368040e+05</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>1.484705e+06</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>4356.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf888979-3e12-46ac-ab2f-09fe7416b462')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf888979-3e12-46ac-ab2f-09fe7416b462 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf888979-3e12-46ac-ab2f-09fe7416b462');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                age  final_weight  ...  hrs_per_week  target_income\n",
              "count  25000.000000  2.500000e+04  ...  25000.000000    25000.00000\n",
              "mean      38.568800  1.900156e+05  ...     40.392200        0.23944\n",
              "std       13.642694  1.059694e+05  ...     12.350547        0.42675\n",
              "min       17.000000  1.228500e+04  ...      1.000000        0.00000\n",
              "25%       28.000000  1.178315e+05  ...     40.000000        0.00000\n",
              "50%       37.000000  1.786440e+05  ...     40.000000        0.00000\n",
              "75%       48.000000  2.368040e+05  ...     45.000000        0.00000\n",
              "max       90.000000  1.484705e+06  ...     99.000000        1.00000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe the outliers by histogram \n",
        "df['age'].hist(bins=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6PMIAxGICjW-",
        "outputId": "940647be-69bb-4329-de47-33ae92516c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f199110a810>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['hrs_per_week'].hist(bins=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8TGC4eX0ClOQ",
        "outputId": "4d55e6cb-5c80-4341-a43c-997238a20056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1997315a50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['final_weight'].hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "GvULrbcUClTh",
        "outputId": "41709c21-b226-4170-e907-1452c3942ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1990ac9c50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers from dataframe\n",
        "df = df[df['age']<65]\n",
        "df = df[df['hrs_per_week']>12]\n",
        "df = df[df['hrs_per_week']<65]\n",
        "df = df[df['final_weight']<420000]"
      ],
      "metadata": {
        "id": "ngBa3KUdClWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMJUNXCAClZM",
        "outputId": "4e646027-3b2b-4655-8a94-54dd7ccf5afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21998, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "def seed_all(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "seed = 42 \n",
        "seed_all(seed)"
      ],
      "metadata": {
        "id": "dsjB6JpFClcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metric\n",
        "def get_metrics(y_test, y_pred):\n",
        "    print('ACCURACY_SCORE: ', round(accuracy_score(y_test, y_pred), 4))\n",
        "    print('F1_SCORE: ', round(f1_score(y_test, y_pred, average='macro'), 4))\n",
        "    print('CONFUSION_MATRIX:\\n', confusion_matrix(y_test, y_pred),'\\n')\n",
        "    print(classification_report(y_test, y_pred, digits=4), '\\n')"
      ],
      "metadata": {
        "id": "jP0H_kDpClfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoder the dataset\n",
        "label = df.pop('target_income').values\n",
        "df = pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "zZEQBqt8DibH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features = df.columns.tolist()\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[features].values, label, test_size = 0.2, \n",
        "                                                    stratify = label, # assign equal proportion of target label in train/test \n",
        "                                                    random_state = 0) # keep train/test split the same if run again. \n",
        "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBw1eS9MEYuW",
        "outputId": "3e9d9614-ef1e-464d-81a4-8a74a649d76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 17598, Test Set: 4400 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescaling the data \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() \n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zqywCv8F7RY",
        "outputId": "e5b83974-e941-4c51-f26f-16902216c66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 17598, Test Set: 4400 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optuna Neural Architecture Search\n",
        "\n",
        "[Auto-Tuning Hyperparameters with Optuna and PyTorch\n",
        "](https://www.youtube.com/watch?v=P6NwZVl8ttc) is a good tutorial about search architecture.\n",
        "\n",
        "In the below, we are going to use optuna to search architecture of model that include:\n",
        "\n",
        "* Number of layers\n",
        "* Number of hidden units of each layers\n",
        "* the optimizer that applies to create the architecture.\n",
        "* learning rate"
      ],
      "metadata": {
        "id": "swkvCv_i8-CM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdjYQgT08z24",
        "outputId": "d79cb88a-2438-476a-f90e-053737db43a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=f9ccb7e6e3ad150bb95fe4c05795543e3df026e11174b10edeb46dea9efe7d33\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState # => tracking lại các lượt search từ model \n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "X3cGopep80Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td\n",
        "\n",
        "# Set random seed for reproducability => gieo hat de tai tao ket qua chay cho nhung luot tiep theo\n",
        "torch.manual_seed(0)\n",
        "\n",
        "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyIHIgFxGkhP",
        "outputId": "68d0939b-5aea-441a-fdee-8d13f7bd1a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported - ready to use PyTorch 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "# Reshape y target into [-1, 1] to fit with Binary Cross Entropy\n",
        "train_y = torch.Tensor(y_train).view(-1, 1).float()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=16,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).view(-1, 1).float()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=16,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uT-sKQuGtez",
        "outputId": "9d6d98d2-3d73-4229-d9c8-db2303359ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyDUr-Dp0S7R",
        "outputId": "c0ea193d-d65f-436a-81e6-d1b48982e941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define trial for model in which we define network architecture in random way. That architecture will be trained in the next step."
      ],
      "metadata": {
        "id": "vJoqvF0JC9xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
        "    layers = []\n",
        "\n",
        "    in_features = len(features)\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, 1))\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "TOv0xOkYBj2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective function to train and evaluate the model. Finally, we select the best model corresponding with highest accuracy on evaluation."
      ],
      "metadata": {
        "id": "i9RmhF1TDA1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCHSIZE = 16\n",
        "EPOCHS = 30\n",
        "LOG_INTERVAL = 10\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 300\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 100\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "    loss_criteria = nn.BCELoss()\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            # loss = F.nll_loss(output, target)\n",
        "            loss = loss_criteria(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(test_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = torch.tensor(output.data>=0.5).float()\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(test_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "JcyRZk2iSLqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\") # => tìm ra objective func có accuracy lớn nhất trên test data\n",
        "study.optimize(objective, n_trials=100, timeout=600) # => optimize dựa trên 100 trials trong 600s\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pGQVl4cSrrb",
        "outputId": "2d3f781c-173c-4448-fe0b-d5f4040b4b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-19 03:56:31,147]\u001b[0m A new study created in memory with name: no-name-64e44eff-a2d6-4c2f-8c92-ba4137f2f0ae\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 03:57:17,698]\u001b[0m Trial 0 finished with value: 0.838125 and parameters: {'n_layers': 2, 'n_units_l0': 21, 'dropout_l0': 0.49419798784219243, 'n_units_l1': 31, 'dropout_l1': 0.2602538732668534, 'optimizer': 'RMSprop', 'lr': 4.821171564918944e-05}. Best is trial 0 with value: 0.838125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 03:57:59,977]\u001b[0m Trial 1 finished with value: 0.843125 and parameters: {'n_layers': 2, 'n_units_l0': 99, 'dropout_l0': 0.2207875340345598, 'n_units_l1': 109, 'dropout_l1': 0.47116302498992424, 'optimizer': 'SGD', 'lr': 0.015599960857205167}. Best is trial 1 with value: 0.843125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 03:58:53,889]\u001b[0m Trial 2 finished with value: 0.83875 and parameters: {'n_layers': 6, 'n_units_l0': 50, 'dropout_l0': 0.46155172917250753, 'n_units_l1': 46, 'dropout_l1': 0.4976621905080231, 'n_units_l2': 103, 'dropout_l2': 0.3806661789642748, 'n_units_l3': 85, 'dropout_l3': 0.4404306758740971, 'n_units_l4': 97, 'dropout_l4': 0.46727172413092816, 'n_units_l5': 73, 'dropout_l5': 0.46813972724805436, 'optimizer': 'RMSprop', 'lr': 0.00015196056962479146}. Best is trial 1 with value: 0.843125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 03:59:42,559]\u001b[0m Trial 3 finished with value: 0.846875 and parameters: {'n_layers': 3, 'n_units_l0': 90, 'dropout_l0': 0.44405640851296346, 'n_units_l1': 73, 'dropout_l1': 0.235176954019638, 'n_units_l2': 105, 'dropout_l2': 0.44203479233998244, 'optimizer': 'Adam', 'lr': 0.0003571907680945229}. Best is trial 3 with value: 0.846875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:00:27,669]\u001b[0m Trial 4 finished with value: 0.75625 and parameters: {'n_layers': 4, 'n_units_l0': 15, 'dropout_l0': 0.20243864528200156, 'n_units_l1': 17, 'dropout_l1': 0.4271473116650133, 'n_units_l2': 42, 'dropout_l2': 0.3605465311939211, 'n_units_l3': 33, 'dropout_l3': 0.24701524408616374, 'optimizer': 'SGD', 'lr': 9.415933459746163e-05}. Best is trial 3 with value: 0.846875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:00:43,772]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:00:45,388]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:00:46,889]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:00:53,504]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:01:49,109]\u001b[0m Trial 9 finished with value: 0.83875 and parameters: {'n_layers': 5, 'n_units_l0': 89, 'dropout_l0': 0.20799990269161606, 'n_units_l1': 110, 'dropout_l1': 0.4704486768214552, 'n_units_l2': 5, 'dropout_l2': 0.3655771673244247, 'n_units_l3': 127, 'dropout_l3': 0.36125617521103326, 'n_units_l4': 91, 'dropout_l4': 0.4524521815785581, 'optimizer': 'Adam', 'lr': 0.002203545410179133}. Best is trial 3 with value: 0.846875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:01:52,314]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:01:53,820]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:01:56,817]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:02:40,829]\u001b[0m Trial 13 finished with value: 0.84375 and parameters: {'n_layers': 2, 'n_units_l0': 64, 'dropout_l0': 0.4099284751114415, 'n_units_l1': 91, 'dropout_l1': 0.30214835699719444, 'optimizer': 'Adam', 'lr': 0.0006305875148355409}. Best is trial 3 with value: 0.846875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:03:33,910]\u001b[0m Trial 14 finished with value: 0.84 and parameters: {'n_layers': 3, 'n_units_l0': 66, 'dropout_l0': 0.40668914397418515, 'n_units_l1': 89, 'dropout_l1': 0.29196596461354063, 'n_units_l2': 88, 'dropout_l2': 0.20240705802810846, 'optimizer': 'Adam', 'lr': 0.00048396664721039233}. Best is trial 3 with value: 0.846875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:04:28,786]\u001b[0m Trial 15 finished with value: 0.841875 and parameters: {'n_layers': 2, 'n_units_l0': 65, 'dropout_l0': 0.42569435205533895, 'n_units_l1': 51, 'dropout_l1': 0.2041737510389674, 'optimizer': 'Adam', 'lr': 0.0025261420699503895}. Best is trial 3 with value: 0.846875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:05:17,966]\u001b[0m Trial 16 finished with value: 0.8475 and parameters: {'n_layers': 3, 'n_units_l0': 75, 'dropout_l0': 0.3697812862189006, 'n_units_l1': 92, 'dropout_l1': 0.31250329747340094, 'n_units_l2': 125, 'dropout_l2': 0.4258317133105567, 'optimizer': 'Adam', 'lr': 0.00035952867884704907}. Best is trial 16 with value: 0.8475.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:05:19,741]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:05:21,315]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:05:24,755]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:05:26,363]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:10,193]\u001b[0m Trial 21 finished with value: 0.84625 and parameters: {'n_layers': 2, 'n_units_l0': 71, 'dropout_l0': 0.3907856917930709, 'n_units_l1': 92, 'dropout_l1': 0.2873821026116328, 'optimizer': 'Adam', 'lr': 0.0012336487362819121}. Best is trial 16 with value: 0.8475.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:13,355]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:14,844]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:16,405]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:17,894]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:19,541]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:22,911]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:25,765]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:27,287]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:06:28,804]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 04:07:12,642]\u001b[0m Trial 31 finished with value: 0.845 and parameters: {'n_layers': 2, 'n_units_l0': 71, 'dropout_l0': 0.4211856384232813, 'n_units_l1': 91, 'dropout_l1': 0.3086937201364214, 'optimizer': 'Adam', 'lr': 0.0005168883194966338}. Best is trial 16 with value: 0.8475.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  32\n",
            "  Number of pruned trials:  20\n",
            "  Number of complete trials:  12\n",
            "Best trial:\n",
            "  Value:  0.8475\n",
            "  Params: \n",
            "    n_layers: 3\n",
            "    n_units_l0: 75\n",
            "    dropout_l0: 0.3697812862189006\n",
            "    n_units_l1: 92\n",
            "    dropout_l1: 0.31250329747340094\n",
            "    n_units_l2: 125\n",
            "    dropout_l2: 0.4258317133105567\n",
            "    optimizer: Adam\n",
            "    lr: 0.00035952867884704907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model\n",
        "\n",
        "In that step, we retrain the model with the best architecture."
      ],
      "metadata": {
        "id": "ggQ4hddGH1I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model(trial)"
      ],
      "metadata": {
        "id": "mzq4vJ8EHxkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the loss function and optimizer that suits with hyperparameter search result. "
      ],
      "metadata": {
        "id": "Mamm-MOxH7ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_criteria = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=trial.params['lr'])\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 30 epochs\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "mS_DeQftH33k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model\n",
        "\n",
        "Finally, we train the best model in train dataset and evaluate in test dataset."
      ],
      "metadata": {
        "id": "XezWT8l0IOrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    '''\n",
        "    Train model through data loader and optimizer\n",
        "    Args:\n",
        "      model: model to train\n",
        "      data_loader: data loader to manage batch loading\n",
        "      optimizer: control update gradient descent\n",
        "    '''\n",
        "    # enable train mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        # reset optimizer into zero\n",
        "        optimizer.zero_grad()\n",
        "        # feed forward to compute output and loss\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        # accumulate loss\n",
        "        train_loss += loss.item()\n",
        "        # compute gradient descent\n",
        "        loss.backward()\n",
        "        # update into weight\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "\n",
        "def test(model, data_loader):\n",
        "    '''\n",
        "    evaluate model accuracy and loss on test\n",
        "    Args: \n",
        "      model: model trained\n",
        "      data_loader: load the dataset\n",
        "    '''\n",
        "    # Turn on evaluation mode\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    # Constrain operation inside torch.no_grad() to restrict the gradient compute and update weight \n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data)\n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out, target).item()\n",
        "            # Calculate the accuracy\n",
        "            predicted = torch.tensor(out.data[1]>=0.5).float()\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print(correct,' : ', len(data_loader.dataset))\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "DZpeyX1DE0tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training through epoch\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NSWjapwIXwI",
        "outputId": "bbe01b82-6161-4bb3-9c8a-75243794b4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 0.368973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2926  :  4400\n",
            "Validation set: Average loss: 0.329654, Accuracy: 2926/4400 (66%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.333589\n",
            "2908  :  4400\n",
            "Validation set: Average loss: 0.325401, Accuracy: 2908/4400 (66%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.321076\n",
            "2950  :  4400\n",
            "Validation set: Average loss: 0.322870, Accuracy: 2950/4400 (67%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.317430\n",
            "2940  :  4400\n",
            "Validation set: Average loss: 0.322471, Accuracy: 2940/4400 (67%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.313620\n",
            "2946  :  4400\n",
            "Validation set: Average loss: 0.324390, Accuracy: 2946/4400 (67%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.312862\n",
            "2940  :  4400\n",
            "Validation set: Average loss: 0.319950, Accuracy: 2940/4400 (67%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.310839\n",
            "2940  :  4400\n",
            "Validation set: Average loss: 0.321530, Accuracy: 2940/4400 (67%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.306397\n",
            "2946  :  4400\n",
            "Validation set: Average loss: 0.322132, Accuracy: 2946/4400 (67%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.305625\n",
            "2952  :  4400\n",
            "Validation set: Average loss: 0.320562, Accuracy: 2952/4400 (67%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.303244\n",
            "2942  :  4400\n",
            "Validation set: Average loss: 0.320017, Accuracy: 2942/4400 (67%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.304264\n",
            "2948  :  4400\n",
            "Validation set: Average loss: 0.322265, Accuracy: 2948/4400 (67%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.300696\n",
            "2982  :  4400\n",
            "Validation set: Average loss: 0.323571, Accuracy: 2982/4400 (68%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.301227\n",
            "2944  :  4400\n",
            "Validation set: Average loss: 0.323322, Accuracy: 2944/4400 (67%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.298832\n",
            "2948  :  4400\n",
            "Validation set: Average loss: 0.324447, Accuracy: 2948/4400 (67%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.299520\n",
            "2966  :  4400\n",
            "Validation set: Average loss: 0.324296, Accuracy: 2966/4400 (67%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.295291\n",
            "2968  :  4400\n",
            "Validation set: Average loss: 0.325297, Accuracy: 2968/4400 (67%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.297447\n",
            "2932  :  4400\n",
            "Validation set: Average loss: 0.341974, Accuracy: 2932/4400 (67%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.296464\n",
            "2960  :  4400\n",
            "Validation set: Average loss: 0.324700, Accuracy: 2960/4400 (67%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.297281\n",
            "2958  :  4400\n",
            "Validation set: Average loss: 0.344336, Accuracy: 2958/4400 (67%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.300457\n",
            "2954  :  4400\n",
            "Validation set: Average loss: 0.322749, Accuracy: 2954/4400 (67%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.299129\n",
            "2966  :  4400\n",
            "Validation set: Average loss: 0.342475, Accuracy: 2966/4400 (67%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.299142\n",
            "2980  :  4400\n",
            "Validation set: Average loss: 0.324411, Accuracy: 2980/4400 (68%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.297196\n",
            "2952  :  4400\n",
            "Validation set: Average loss: 0.343339, Accuracy: 2952/4400 (67%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.297507\n",
            "2954  :  4400\n",
            "Validation set: Average loss: 0.340823, Accuracy: 2954/4400 (67%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.297162\n",
            "2968  :  4400\n",
            "Validation set: Average loss: 0.342779, Accuracy: 2968/4400 (67%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.292333\n",
            "2946  :  4400\n",
            "Validation set: Average loss: 0.345981, Accuracy: 2946/4400 (67%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.290631\n",
            "2966  :  4400\n",
            "Validation set: Average loss: 0.349388, Accuracy: 2966/4400 (67%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.288650\n",
            "2946  :  4400\n",
            "Validation set: Average loss: 0.349884, Accuracy: 2946/4400 (67%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.294672\n",
            "2960  :  4400\n",
            "Validation set: Average loss: 0.344756, Accuracy: 2960/4400 (67%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.291390\n",
            "2954  :  4400\n",
            "Validation set: Average loss: 0.348068, Accuracy: 2954/4400 (67%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.293486\n",
            "2960  :  4400\n",
            "Validation set: Average loss: 0.348633, Accuracy: 2960/4400 (67%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.289890\n",
            "2954  :  4400\n",
            "Validation set: Average loss: 0.348706, Accuracy: 2954/4400 (67%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.292275\n",
            "2954  :  4400\n",
            "Validation set: Average loss: 0.347203, Accuracy: 2954/4400 (67%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.292376\n",
            "2954  :  4400\n",
            "Validation set: Average loss: 0.347845, Accuracy: 2954/4400 (67%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.292336\n",
            "2966  :  4400\n",
            "Validation set: Average loss: 0.347751, Accuracy: 2966/4400 (67%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.287495\n",
            "2960  :  4400\n",
            "Validation set: Average loss: 0.346573, Accuracy: 2960/4400 (67%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.289165\n",
            "2952  :  4400\n",
            "Validation set: Average loss: 0.346949, Accuracy: 2952/4400 (67%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.285946\n",
            "2960  :  4400\n",
            "Validation set: Average loss: 0.355130, Accuracy: 2960/4400 (67%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.291447\n",
            "2946  :  4400\n",
            "Validation set: Average loss: 0.347854, Accuracy: 2946/4400 (67%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.291031\n",
            "2954  :  4400\n",
            "Validation set: Average loss: 0.350189, Accuracy: 2954/4400 (67%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  predictions = [1 if i>0.5 else 0 for i in model(x).data]\n",
        "  predictions = torch.tensor(predictions)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "fkVdXC3KIb6q",
        "outputId": "64dc5ac0-5916-49a2-9a7c-c681ee2fd073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8518\n",
            "F1_SCORE:  0.7827\n",
            "CONFUSION_MATRIX:\n",
            " [[3115  225]\n",
            " [ 427  633]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8794    0.9326    0.9053      3340\n",
            "           1     0.7378    0.5972    0.6601      1060\n",
            "\n",
            "    accuracy                         0.8518      4400\n",
            "   macro avg     0.8086    0.7649    0.7827      4400\n",
            "weighted avg     0.8453    0.8518    0.8462      4400\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "fUbuHQePL4H2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85b4d6c-ed92-4b89-c964-3bb697c95bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def _save_pkl(path, obj):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "\n",
        "def _load_pkl(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    obj = pickle.load(f)\n",
        "  return obj"
      ],
      "metadata": {
        "id": "pcwManYROxIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_save_pkl('IncomeClassifier',model)"
      ],
      "metadata": {
        "id": "I0VXOL2rNFCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_save_pkl(\"IncomeScaler\",scaler)"
      ],
      "metadata": {
        "id": "UbaOxoFSO2I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Flask Deployment"
      ],
      "metadata": {
        "id": "5ZxFVZVcR1He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding numpy to json\n",
        "import json\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    '''\n",
        "    Encoding numpy into json\n",
        "    '''\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        if isinstance(obj, np.int32):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.int64):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.float32):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.float64):\n",
        "            return float(obj)\n",
        "        return json.JSONEncoder.default(self, obj)"
      ],
      "metadata": {
        "id": "TmkNTsQ_RomJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from flask import Flask, request\n",
        "import flask\n",
        "import json\n",
        "\n",
        "# Khởi tạo model.\n",
        "global model \n",
        "model = None\n",
        "# Khởi tạo flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Khai báo các route 1 cho API\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "# Khai báo hàm xử lý dữ liệu.\n",
        "def _hello_world():\n",
        "  return \"Hello world\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"App run!\")\n",
        "  app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXZMmCy9SB1Y",
        "outputId": "e25203e6-6b80-4fa5-aa72-71f8fd0ffab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "App run!\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D_4n3WyxSJmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chưa thấy câu 6,7,8 thay đổi loss,optim,khởi tạo trọng số, thêm bớt layer"
      ],
      "metadata": {
        "id": "SzEWVJ2b4Fwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5vVgi0nK4LSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}