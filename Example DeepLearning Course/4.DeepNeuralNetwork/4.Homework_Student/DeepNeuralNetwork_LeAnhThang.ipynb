{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepNeuralNetwork_LeAnhThang.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lý thuyết"
      ],
      "metadata": {
        "id": "uy1My1YTpD2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tại sao các mô hình deep learning lại chiếm ưu thế hơn so với các mô hình machine learning truyền thống đối với dữ liệu lớn ?\n",
        "\n",
        "    A. Do mô hình deep learning có thể được thiết kế với kích thước tùy ý nên có khả năng xấp xỉ mọi hàm số. Do đó nó có khả năng biểu diễn tốt và hoạt động hiệu quả trên dữ liệu lớn."
      ],
      "metadata": {
        "id": "T4EXQ6x3pGMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ý nghĩa của hàm loss function trong mạng neural network là gì ?\n",
        "\n",
        "    B. Mục tiêu của quá trình huấn luyện là tối thiểu hóa hàm loss function bằng thuật toán gradient descent. Giá trị của hàm số này giúp đo lường mức độ khớp của dự báo từ mô hình trên dữ liệu huấn luyện."
      ],
      "metadata": {
        "id": "YxWEPkYFpp--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Khi huấn luyện trên các bộ dữ liệu bigdata thì chúng ta nên sử dụng phương pháp nào ?\n",
        "\n",
        "    C) Mini-batch gradient descent huấn luyện mô hình trên từng tập dữ liệu con có kích thước nhỏ hơn memory CPU/GPU.\n",
        "    "
      ],
      "metadata": {
        "id": "ZbEPPqlUtEA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Quá trình feed forward và backpropagation thực hiện những gì ?\n",
        "\n",
        "    A) feed forward tính toán output và loss function, backpropagation tính đạo hàm trên từng layer và cập nhật trọng số."
      ],
      "metadata": {
        "id": "f72GiZc2tPAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Tác dụng của batch normalization là gì ?\n",
        "    \n",
        "    D) Giảm thiểu ảnh hưởng của input distribution shift nhằm giúp huấn luyện loss function nhanh và ổn định hơn.\n",
        "    "
      ],
      "metadata": {
        "id": "l8NImSXBt_uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thực hành"
      ],
      "metadata": {
        "id": "8VL68rAXyzMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6) Thay đổi hàm loss function, batch size và optimizer."
      ],
      "metadata": {
        "id": "cXcn2j1Ky4MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/machine_learning_hand_On_DS/kaggle/income\"\n",
        "# OS.chdir(path)\n",
        "%cd {path}"
      ],
      "metadata": {
        "id": "PD2XLeLBtOQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be54fb7-4254-45a7-f406-ae2c7809e8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/machine_learning_hand_On_DS/kaggle/income\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td\n",
        "\n",
        "# Set random seed for reproducability\n",
        "torch.manual_seed(0)\n",
        "\n",
        "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoOkWjM00zEX",
        "outputId": "c6f2b5b9-df82-444d-d62e-1fcf8c08c18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported - ready to use PyTorch 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "def seed_all(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "seed = 42 \n",
        "seed_all(seed)"
      ],
      "metadata": {
        "id": "eFYUSqGE0sD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metric\n",
        "def get_metrics(y_test, y_pred):\n",
        "    print('ACCURACY_SCORE: ', round(accuracy_score(y_test, y_pred), 4))\n",
        "    print('F1_SCORE: ', round(f1_score(y_test, y_pred, average='macro'), 4))\n",
        "    print('CONFUSION_MATRIX:\\n', confusion_matrix(y_test, y_pred),'\\n')\n",
        "    print(classification_report(y_test, y_pred, digits=4), '\\n')"
      ],
      "metadata": {
        "id": "1Xy6nFNXpFbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "5Wt12grP05oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize string\n",
        "def str_normalize(s):\n",
        "    # convert into lowercase and replace multiple spaces into single space\n",
        "    s = str(s).strip().lower()\n",
        "    s = re.sub(' +', \" \", s)\n",
        "    return s\n",
        "# Encode category and object columns \n",
        "def process(df):        \n",
        "  for col in df.columns:\n",
        "      if df[col].dtype.name == \"object\" or df[col].dtype.name == \"category\":\n",
        "          df[col] = df[col].apply(str_normalize).astype(\"category\")\n",
        "  return df\n",
        "df_all = process(df_all.copy())\n",
        "IDs=df_all.pop('ID')\n",
        "label = df_all.pop('target_income')\n",
        "df_all_one_hot = pd.get_dummies(df_all)"
      ],
      "metadata": {
        "id": "yZhZTKYb1SKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_all_one_hot.columns.tolist()\n",
        "label = label.values"
      ],
      "metadata": {
        "id": "N31Q2gn61Uja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_all_one_hot.columns.tolist()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_all_one_hot[features].values, # input variable\n",
        "                                                    label, # output variable\n",
        "                                                    test_size=0.2, # test dataset proportion\n",
        "                                                    # stratify=df_all['target_income'], # assign equal proportion of target label in train/test \n",
        "                                                    random_state=0) # keep train/test split the same if run again. \n",
        "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
        "#normalize\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t01wcemF1XYQ",
        "outputId": "0800ea55-44da-46a8-f57e-01122147e794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 20000, Test Set: 5000 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hl = 50\n",
        "# Define the neural network\n",
        "class IncomeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IncomeNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(len(features), hl)\n",
        "        self.fc2 = nn.Linear(hl, hl)\n",
        "        self.fc3 = nn.Linear(hl, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.nn.Softmax()(self.fc3(x))\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "GPfJ0XY11rcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        #feedforward: calculate y_pred and loss function\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backpropagate: compute gradient descent and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    #Return average loss\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "           \n",
        "            \n",
        "def test(model, data_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data)\n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out, target).item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            predicted = torch.tensor(out.data[:,1] >= 0.5).float()\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "            \n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "xcFFbMlE2tKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 64, adam"
      ],
      "metadata": {
        "id": "4t-Yl5EeAGFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=64\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=64,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=64,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVOmXdhl33y2",
        "outputId": "1c88dd2b-08c1-4149-f097-8c56f948a305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "id": "HqAXyxxN4at6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e62ad0-c1ee-409f-f7e7-c1cd6a67a12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.487801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set: Average loss: 0.458362, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.454245\n",
            "Validation set: Average loss: 0.452623, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.449317\n",
            "Validation set: Average loss: 0.453323, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.446011\n",
            "Validation set: Average loss: 0.453164, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.444069\n",
            "Validation set: Average loss: 0.450840, Accuracy: 4280/5000 (86%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.441352\n",
            "Validation set: Average loss: 0.451000, Accuracy: 4279/5000 (86%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.439621\n",
            "Validation set: Average loss: 0.451735, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.438430\n",
            "Validation set: Average loss: 0.449513, Accuracy: 4282/5000 (86%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.437326\n",
            "Validation set: Average loss: 0.451250, Accuracy: 4279/5000 (86%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.436111\n",
            "Validation set: Average loss: 0.452209, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.434973\n",
            "Validation set: Average loss: 0.450888, Accuracy: 4275/5000 (86%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.434064\n",
            "Validation set: Average loss: 0.452831, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.433347\n",
            "Validation set: Average loss: 0.451381, Accuracy: 4275/5000 (86%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.432564\n",
            "Validation set: Average loss: 0.453062, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.431677\n",
            "Validation set: Average loss: 0.453340, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.431216\n",
            "Validation set: Average loss: 0.452867, Accuracy: 4274/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.430503\n",
            "Validation set: Average loss: 0.454918, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.429090\n",
            "Validation set: Average loss: 0.454112, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.429110\n",
            "Validation set: Average loss: 0.455696, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.428903\n",
            "Validation set: Average loss: 0.455692, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.428235\n",
            "Validation set: Average loss: 0.455649, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.427902\n",
            "Validation set: Average loss: 0.455806, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.426917\n",
            "Validation set: Average loss: 0.456527, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.427036\n",
            "Validation set: Average loss: 0.454771, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.426773\n",
            "Validation set: Average loss: 0.455313, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.425756\n",
            "Validation set: Average loss: 0.457358, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.425419\n",
            "Validation set: Average loss: 0.456297, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.425007\n",
            "Validation set: Average loss: 0.457174, Accuracy: 4250/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.425198\n",
            "Validation set: Average loss: 0.457143, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.424905\n",
            "Validation set: Average loss: 0.458853, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.424566\n",
            "Validation set: Average loss: 0.456976, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.424531\n",
            "Validation set: Average loss: 0.456511, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.424369\n",
            "Validation set: Average loss: 0.456100, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.423645\n",
            "Validation set: Average loss: 0.458989, Accuracy: 4236/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.423837\n",
            "Validation set: Average loss: 0.458116, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.423448\n",
            "Validation set: Average loss: 0.455604, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.422194\n",
            "Validation set: Average loss: 0.456769, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.421574\n",
            "Validation set: Average loss: 0.456748, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.421657\n",
            "Validation set: Average loss: 0.458100, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.421147\n",
            "Validation set: Average loss: 0.457121, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.421062\n",
            "Validation set: Average loss: 0.458531, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.420705\n",
            "Validation set: Average loss: 0.459581, Accuracy: 4228/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.420177\n",
            "Validation set: Average loss: 0.457741, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.420021\n",
            "Validation set: Average loss: 0.457337, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.420017\n",
            "Validation set: Average loss: 0.458069, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.419329\n",
            "Validation set: Average loss: 0.457962, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.418791\n",
            "Validation set: Average loss: 0.459618, Accuracy: 4240/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.418480\n",
            "Validation set: Average loss: 0.458120, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.418721\n",
            "Validation set: Average loss: 0.458099, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.418636\n",
            "Validation set: Average loss: 0.458496, Accuracy: 4240/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# batch_size = 64\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "jJZkV75g7XlW",
        "outputId": "c2b6be4d-68e5-46d1-f30b-72e9117495b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.848\n",
            "F1_SCORE:  0.7758\n",
            "CONFUSION_MATRIX:\n",
            " [[3539  272]\n",
            " [ 488  701]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8788    0.9286    0.9030      3811\n",
            "           1     0.7205    0.5896    0.6485      1189\n",
            "\n",
            "    accuracy                         0.8480      5000\n",
            "   macro avg     0.7996    0.7591    0.7758      5000\n",
            "weighted avg     0.8412    0.8480    0.8425      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 256, adam"
      ],
      "metadata": {
        "id": "EbBpLG9-AVb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=256\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=256,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=256,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XD4x-NrAZ7x",
        "outputId": "9f52e21e-a9db-46b5-d235-e144baefd139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd2m7gh0AhgK",
        "outputId": "258ed331-210e-44e8-f142-43b66d976ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.538782\n",
            "Validation set: Average loss: 0.472816, Accuracy: 4174/5000 (83%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.464623\n",
            "Validation set: Average loss: 0.457728, Accuracy: 4228/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.454481\n",
            "Validation set: Average loss: 0.455806, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.451621\n",
            "Validation set: Average loss: 0.453642, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.448947\n",
            "Validation set: Average loss: 0.452540, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.446560\n",
            "Validation set: Average loss: 0.452169, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.444960\n",
            "Validation set: Average loss: 0.453201, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.444587\n",
            "Validation set: Average loss: 0.451738, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.443018\n",
            "Validation set: Average loss: 0.451996, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.440150\n",
            "Validation set: Average loss: 0.451562, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.438803\n",
            "Validation set: Average loss: 0.451259, Accuracy: 4265/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.437981\n",
            "Validation set: Average loss: 0.451390, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.436342\n",
            "Validation set: Average loss: 0.451641, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.436553\n",
            "Validation set: Average loss: 0.451865, Accuracy: 4273/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.435870\n",
            "Validation set: Average loss: 0.451612, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.435251\n",
            "Validation set: Average loss: 0.451890, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.435239\n",
            "Validation set: Average loss: 0.452605, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.432602\n",
            "Validation set: Average loss: 0.452846, Accuracy: 4271/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.432912\n",
            "Validation set: Average loss: 0.452214, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.431321\n",
            "Validation set: Average loss: 0.452991, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.431297\n",
            "Validation set: Average loss: 0.453292, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.430431\n",
            "Validation set: Average loss: 0.453709, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.428475\n",
            "Validation set: Average loss: 0.452985, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.428970\n",
            "Validation set: Average loss: 0.455222, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.431346\n",
            "Validation set: Average loss: 0.453993, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.427756\n",
            "Validation set: Average loss: 0.453907, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.427682\n",
            "Validation set: Average loss: 0.452859, Accuracy: 4265/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.428304\n",
            "Validation set: Average loss: 0.454116, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.426626\n",
            "Validation set: Average loss: 0.453814, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.425954\n",
            "Validation set: Average loss: 0.455723, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.425737\n",
            "Validation set: Average loss: 0.455099, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.424753\n",
            "Validation set: Average loss: 0.456008, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.425286\n",
            "Validation set: Average loss: 0.455050, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.423372\n",
            "Validation set: Average loss: 0.456137, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.423854\n",
            "Validation set: Average loss: 0.456259, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.423569\n",
            "Validation set: Average loss: 0.457084, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.424956\n",
            "Validation set: Average loss: 0.456978, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.422245\n",
            "Validation set: Average loss: 0.457022, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.422793\n",
            "Validation set: Average loss: 0.456297, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.423253\n",
            "Validation set: Average loss: 0.454830, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.423078\n",
            "Validation set: Average loss: 0.457464, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.423594\n",
            "Validation set: Average loss: 0.456502, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.421783\n",
            "Validation set: Average loss: 0.457462, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.421118\n",
            "Validation set: Average loss: 0.455430, Accuracy: 4265/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.421543\n",
            "Validation set: Average loss: 0.456050, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.421430\n",
            "Validation set: Average loss: 0.455997, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.420619\n",
            "Validation set: Average loss: 0.459380, Accuracy: 4226/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.421636\n",
            "Validation set: Average loss: 0.457515, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.423189\n",
            "Validation set: Average loss: 0.456698, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.420408\n",
            "Validation set: Average loss: 0.456052, Accuracy: 4258/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 256\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "NhS37UkmAmed",
        "outputId": "64a996b9-c209-46a3-eea8-754ea02509a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8516\n",
            "F1_SCORE:  0.7839\n",
            "CONFUSION_MATRIX:\n",
            " [[3528  283]\n",
            " [ 459  730]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8849    0.9257    0.9048      3811\n",
            "           1     0.7206    0.6140    0.6630      1189\n",
            "\n",
            "    accuracy                         0.8516      5000\n",
            "   macro avg     0.8028    0.7699    0.7839      5000\n",
            "weighted avg     0.8458    0.8516    0.8473      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 512, adam"
      ],
      "metadata": {
        "id": "61Trgk1-BDep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=512\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=512,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=512,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60803cf0-ab7a-4fdf-99c6-fd3cc84f6ed3",
        "id": "WDMwhePMBDep"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d468e753-5afc-4bb6-e295-b607fbad2a9d",
        "id": "lOJZxUYDBDeq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.419391\n",
            "Validation set: Average loss: 0.456438, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.416339\n",
            "Validation set: Average loss: 0.457602, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.421224\n",
            "Validation set: Average loss: 0.456650, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.415659\n",
            "Validation set: Average loss: 0.458089, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.415813\n",
            "Validation set: Average loss: 0.458009, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.416940\n",
            "Validation set: Average loss: 0.457347, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.418965\n",
            "Validation set: Average loss: 0.457033, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.416127\n",
            "Validation set: Average loss: 0.458889, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.418610\n",
            "Validation set: Average loss: 0.457002, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.416763\n",
            "Validation set: Average loss: 0.457493, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.416331\n",
            "Validation set: Average loss: 0.457603, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.415229\n",
            "Validation set: Average loss: 0.457418, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.415361\n",
            "Validation set: Average loss: 0.458134, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.416133\n",
            "Validation set: Average loss: 0.457568, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.415927\n",
            "Validation set: Average loss: 0.457856, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.415738\n",
            "Validation set: Average loss: 0.457066, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.416078\n",
            "Validation set: Average loss: 0.458592, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.416497\n",
            "Validation set: Average loss: 0.458114, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.420116\n",
            "Validation set: Average loss: 0.457845, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.416050\n",
            "Validation set: Average loss: 0.457477, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.417067\n",
            "Validation set: Average loss: 0.457130, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.418199\n",
            "Validation set: Average loss: 0.457945, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.414008\n",
            "Validation set: Average loss: 0.458425, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.416668\n",
            "Validation set: Average loss: 0.458109, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.417080\n",
            "Validation set: Average loss: 0.457542, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.414600\n",
            "Validation set: Average loss: 0.458216, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.414378\n",
            "Validation set: Average loss: 0.458677, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.416272\n",
            "Validation set: Average loss: 0.458866, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.416068\n",
            "Validation set: Average loss: 0.458949, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.413947\n",
            "Validation set: Average loss: 0.459352, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.416683\n",
            "Validation set: Average loss: 0.459627, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.417160\n",
            "Validation set: Average loss: 0.458744, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.414058\n",
            "Validation set: Average loss: 0.460151, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.415736\n",
            "Validation set: Average loss: 0.459160, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.414267\n",
            "Validation set: Average loss: 0.459595, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.414969\n",
            "Validation set: Average loss: 0.458005, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.413085\n",
            "Validation set: Average loss: 0.458469, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.414684\n",
            "Validation set: Average loss: 0.458941, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.413438\n",
            "Validation set: Average loss: 0.459409, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.414316\n",
            "Validation set: Average loss: 0.459503, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.411404\n",
            "Validation set: Average loss: 0.459304, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.412346\n",
            "Validation set: Average loss: 0.459021, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.413252\n",
            "Validation set: Average loss: 0.459595, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.414063\n",
            "Validation set: Average loss: 0.459904, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.412945\n",
            "Validation set: Average loss: 0.458993, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.412812\n",
            "Validation set: Average loss: 0.459734, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.413611\n",
            "Validation set: Average loss: 0.459184, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.413374\n",
            "Validation set: Average loss: 0.460209, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.412241\n",
            "Validation set: Average loss: 0.459918, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.412596\n",
            "Validation set: Average loss: 0.460110, Accuracy: 4241/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 512\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "XHz3bOjrBDer",
        "outputId": "edf960ea-4ce9-4c27-e550-6a5974682bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8482\n",
            "F1_SCORE:  0.7808\n",
            "CONFUSION_MATRIX:\n",
            " [[3507  304]\n",
            " [ 455  734]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8852    0.9202    0.9024      3811\n",
            "           1     0.7071    0.6173    0.6592      1189\n",
            "\n",
            "    accuracy                         0.8482      5000\n",
            "   macro avg     0.7961    0.7688    0.7808      5000\n",
            "weighted avg     0.8428    0.8482    0.8445      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEHCAYAAADYj0FrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWvklEQVR4nO3dfbBdVX3G8e9zL+8KJiGQxiQKoxGMjAYagZbWQaghYDsBRxE6oxmkBmzwbWhH8A8REMdOUSqI1CCR0FFeKiKRRkIMsYAjkAAhkiDlFkJJDC8xEEEgGvj1j70uHOK95+x17zk5L/v5MHvuOevsl3XM+Mxae629jiICM7Oq6Wt3BczM2sHhZ2aV5PAzs0py+JlZJTn8zKySHH5mVkkOPzNrC0m7Sbpb0v2S1kg6N5VfKelRSavSNj2VS9LFkgYkrZZ0SM255kh6OG1zylx/p9Z8LTOzhrYCR0XE85J2Bu6Q9NP02T9HxA+32/9YYGraDgMuAw6TNA44B5gBBHCPpEUR8Uy9i7vlZ2ZtEYXn09ud01bvqYvZwFXpuDuBMZImAscASyNicwq8pcCsRtfvqJafdto9tMue7a6GZTj4nW9pdxUsw2OPrWPTpk0azTn693prxLYXS+0bLz69JCKGDSJJ/cA9wNuBSyPiLkmfAi6Q9CVgGXBWRGwFJgGP1xy+PpUNV15XZ4XfLnuy6wEntrsaluEXd32r3VWwDEccNmPU54htL7HrgSeV2vel+y45UNLKmqL5ETH/1XNFvAxMlzQGuEHSQcDZwBPALsB84AvAeaOu+HY6KvzMrAsIUOnG46aIaJi4EfGspOXArIi4MBVvlfQ94J/S+w3AlJrDJqeyDcCR25X/vNE1fc/PzPKpr9xW7xTSPqnFh6TdgQ8Av0738ZAk4HjggXTIIuDjadT3cGBLRGwElgAzJY2VNBaYmcrqcsvPzPKVb/nVMxFYmO779QHXRcRNkm6VtA9FG3MVcHrafzFwHDAAvACcAhARmyWdD6xI+50XEZsbXdzhZ2aZ1LBVV0ZErAYOHqL8qGH2D2DeMJ8tABbkXN/hZ2b5mtPyayuHn5nlkaCvv921GDWHn5nla0K3t90cfmaWz91eM6ue5gx4tJvDz8zy5E1y7lgOPzPL55afmVWPoN+jvWZWNcItPzOrKN/zM7Pq8WivmVWVW35mVjl+vM3MKsvdXjOrJHd7zax6POBhZlXllp+ZVY4nOZtZNXm018yqyi0/M6sk3/Mzs8qRR3vNrKrc8jOzKpLDz8yqpuj1dn/4dX/H3cx2MCGV2+qeRdpN0t2S7pe0RtK5qXx/SXdJGpB0raRdUvmu6f1A+ny/mnOdncofknRMmW/h8DOzbM0IP2ArcFREvAeYDsySdDjwL8BFEfF24Bng1LT/qcAzqfyitB+SpgEnAe8CZgHfltRwIqLDz8yyNSP8ovB8ertz2gI4CvhhKl8IHJ9ez07vSZ8freIis4FrImJrRDwKDACHNvoODj8zy9aklh+S+iWtAp4ClgL/CzwbEdvSLuuBSen1JOBxgPT5FmDv2vIhjhmWBzzMLIuknAGP8ZJW1ryfHxHzB99ExMvAdEljgBuAA5tX0/ocfmaWLWOqy6aImNFop4h4VtJy4C+AMZJ2Sq27ycCGtNsGYAqwXtJOwJuA39aUD6o9Zlju9ppZtiaN9u6TWnxI2h34APAgsBz4cNptDnBjer0ovSd9fmtERCo/KY0G7w9MBe5u9B3c8jOzbE2a5DwRWJhGZvuA6yLiJklrgWskfQW4D7gi7X8F8B+SBoDNFCO8RMQaSdcBa4FtwLzUna7L4WdmeZS2UYqI1cDBQ5Q/whCjtRHxEvCRYc51AXBBzvUdfmaWzY+3mVnlCNHX1/3DBQ4/M8vX/Q0/h5+ZZZK7vWZWUQ4/M6skh5+ZVY4o99xup3P4mVmeHlnM1OFnZtnc8jOzSnL4mVk1dX/2tXZVF0mz0pr6A5LOauW1zGzHadZipu3UspZfWqnhUoplatYDKyQtioi1rbqmmbWe1BuPt7XyGxwKDETEIxHxB+AairX2zazL9ULLr5XhV2pdfUlzJa2UtDK2vdjC6phZ06jk1sHaPuCR1vOfD9C3x77R5uqYWQmd3qoro5XhN6J19c2sw/XIwgat7PauAKamX1/fhWLJ6UUtvJ6Z7QACpHJbJ2tZyy8itkk6A1gC9AMLImJNq65nZjuK6PPjbfVFxGJgcSuvYWY7Xi90e9s+4GFmXaYLurRlOPzMLIvA3V4zqya3/MyseuSWn5lVUDHVpfvDr/ufTjazHazcc72NAlLSFEnLJa2VtEbSZ1P5lyVtkLQqbcfVHHN2WiXqIUnH1JRnryDllp+ZZWtSw28bcGZE3CtpT+AeSUvTZxdFxIWvv6amUTws8S7gzcDPJL0jfZy9gpTDz8yyNaPbGxEbgY3p9XOSHmSIxU9qzAauiYitwKOSBihWj4K0glSq2+AKUnXDz91eM8tT8tG2lI/jB1dtStvcIU8p7QccDNyVis6QtFrSAkljU9lwK0WVWkFqe275mVmWzHl+myJiRt3zSW8Ergc+FxG/k3QZcD4Q6e/XgU+MvMZDc/iZWbZmjfZK2pki+L4fET8CiIgnaz6/HLgpva23UlT2ClLu9ppZtmas6qIiQa8AHoyIb9SUT6zZ7QTggfR6EXCSpF0l7Q9MBe5mhCtIueVnZnmat57fEcDHgF9JWpXKvgicLGk6Rbd3HXAaQESskXQdxUDGNmBeRLwMMJIVpBx+ZpZlcD2/0YqIOxh6sfthV4KKiAuAC4Yoz15ByuFnZpk6/8eJynD4mVk2P9trZtXj9fzMrIp6ZWEDh5+ZZXP4mVkl9UD2OfzMLJMXMzWzKpKnuphZVfVA9jn8zCxfXw+kn8PPzLL1QPY5/Mwsj5q3sEFbOfzMLFu/R3vNrIp6oOHn8DOzPKKY7tLtHH5mlq0Her0OPzPLVOIHybuBw8/MsvVA9jn8zCyP8GivmVWUu71mVjllfpayGzj8zCxbTz/bK+kSit/NHFJEfKYlNTKzjtf90Ve/5bdyh9XCzLpGzw94RMTCHVkRM+sSPTLPr6/RDpL2kXShpMWSbh3cdkTlzKwzDQ56NNrqn0NTJC2XtFbSGkmfTeXjJC2V9HD6OzaVS9LFkgYkrZZ0SM255qT9H5Y0p8x3aBh+wPeBB4H9gXOBdcCKMic3s96k1PprtDWwDTgzIqYBhwPzJE0DzgKWRcRUYFl6D3AsMDVtc4HLUl3GAecAhwGHAucMBmY9ZcJv74i4AvhjRPx3RHwCOKrEcWbWg0TxbG+ZrZ6I2BgR96bXz1E0siYBs4HB224LgePT69nAVVG4ExgjaSJwDLA0IjZHxDPAUmBWo+9RZqrLH9PfjZI+CPwGGFfiODPrURn3/MZLqh08nR8R84c4337AwcBdwISI2Jg+egKYkF5PAh6vOWx9KhuuvK4y4fcVSW8CzgQuAfYCPl/iODPrQRL0lw+/TRExo/759EbgeuBzEfG72mCNiJA07JS70WgYfhFxU3q5BXh/KyphZt2lWYO9knamCL7vR8SPUvGTkiZGxMbUrX0qlW8AptQcPjmVbQCO3K78542u3TD8JH2PISY7p3t/ZlZBzZjqouIkVwAPRsQ3aj5aBMwBvpb+3lhTfoakaygGN7akgFwCfLVmkGMmcHaj65fp9t5U83o34ASK+35mVlFNavkdAXwM+JWkVansixShd52kU4HHgBPTZ4uB44AB4AXgFICI2CzpfF6bhXJeRGxudPEy3d7ra99Luhq4o9FxZtabhJrybG9E3MHwT8odPcT+Acwb5lwLgAU51x/JwgZTgX1HcJyZ9YKqrOoi6Tlef8/vCeALrajMuw+cwq23/1srTm0tsmHzi+2ugmX4w8uvNOU8GaO9HatMt3fPHVERM+sOojcWMy3zbO+yMmVmVh3NeMKj3eqt57cbsAfFDO2xvHZjci9KzJ42s97V6cFWRr1u72nA54A3A/fwWvj9DvhWi+tlZh2qWLGl+9Ov3np+3wS+KenTEXHJDqyTmXW4/jJLonS4Ml/hFUljBt9IGivpH1tYJzPrYMWqLiq1dbIy4ffJiHh28E1aMuaTrauSmXW6vpJbJyszyblfktLsaiT1A7u0tlpm1sk6vFFXSpnwuxm4VtJ30vvTgJ+2rkpm1snUBV3aMsqE3xcolow+Pb1fDfxZy2pkZh2vB7Kv1BMer0i6C3gbxeoK4ynW3zKzChKwUw9M9Ks3yfkdwMlp2wRcCxARXtDUrOJ6veX3a+B24G8jYgBAkpevN6u6Lnh0rYx6o9EfAjYCyyVdLulohl97y8wqRCX/62TDhl9E/DgiTgIOBJZTPOq2r6TLJM3cURU0s87SrJ+ubLeG8xAj4vcR8YOI+DuKHwa5jxat52dm3aG/T6W2TpY1CTsinomI+RHxJ0tMm1k19ErLbyTL2JtZlVVlGXszs+1V5QkPM7NXDXZ7u53Dz8yy9UDDz+FnZnmEqvHrbWZmr9MFI7lldPp6g2bWgZq1krOkBZKekvRATdmXJW2QtCptx9V8drakAUkPSTqmpnxWKhuQdFap75D5nc2s4orf7S23lXAlMGuI8osiYnraFgNImgacBLwrHfNtSf1pgeVLgWOBacDJad+63O01s2zNmuoSEbdJ2q/k7rOBayJiK/CopAHg0PTZQEQ8AiDpmrTv2nonc8vPzLJltPzGS1pZs80teYkzJK1O3eKxqWwS8HjNPutT2XDldbnlZ2ZZJHJGezdFxIzMS1wGnA9E+vt14BOZ52jI4Wdm2Vo52BsRT756Hely4Kb0dgMwpWbXyamMOuXDcrfXzLK0+nd7JU2seXsCMDgSvAg4SdKukvYHpgJ3AyuAqZL2l7QLxaDIokbXccvPzLI1q+Un6WrgSIp7g+uBc4AjJU2n6Pauo/jFSCJijaTrKAYytgHzIuLldJ4zgCVAP7AgItY0urbDz8yyNesBj4g4eYjiK+rsfwFwwRDli4HFOdd2+JlZFj/eZmaVJYefmVVR90efw8/McsktPzOrINEbc+QcfmaWzS0/M6ukXljPz+FnZlmKbm/3p5/Dz8yy9UCv1+FnZrmE3PIzsypyy8/MKsf3/MysmgR9PTDRz+FnZtl8z8/MKqdYzLTdtRg9h5+ZZXPLz8wqyaO9ZlY5IuvX2zpWy8Zs0u9tPiXpgcZ7m1n3UOn/OlkrB6yvBGa18Pxm1g4lf7C80xuHLQu/iLgN2Nyq85tZ+6jk1snafs9P0lxgLsDkKW9pc23MrJHB3+3tdm2fpx0R8yNiRkTM2Hv8+HZXx8xKcMvPzCrJKzmbWSX1QPa1dKrL1cAvgQMkrZd0aquuZWY7VrO6vUNNiZM0TtJSSQ+nv2NTuSRdLGlA0mpJh9QcMyft/7CkOWW+QytHe0+OiIkRsXNETI6IK1p1LTPbwZp30+9K/nRK3FnAsoiYCixL7wGOBaambS5wGRRhCZwDHAYcCpwzGJj1tH3Aw8y6S5FrzZnkPMyUuNnAwvR6IXB8TflVUbgTGCNpInAMsDQiNkfEM8BSSswx9j0/M8uTN4F5vKSVNe/nR8T8BsdMiIiN6fUTwIT0ehLweM1+61PZcOV1OfzMLFtG+G2KiBkjvU5EhKQY6fH1uNtrZpla/mzvk6k7S/r7VCrfAEyp2W9yKhuuvC6Hn5lla/GzvYuAwRHbOcCNNeUfT6O+hwNbUvd4CTBT0tg00DEzldXlbq+ZZWnm0xtpStyRFPcG11OM2n4NuC5Nj3sMODHtvhg4DhgAXgBOAYiIzZLOB1ak/c6LiIbrCjj8zCxfk9IvIk4e5qOjh9g3gHnDnGcBsCDn2g4/M8vWCwsbOPzMLFv3R5/Dz8xydcOSLSU4/MwsW6cvUV+Gw8/MsojeWNXF4Wdm2Xog+xx+ZpbPi5maWSX1QPY5/MwsXw9kn8PPzEagB9LP4WdmWQYXM+12Dj8zyyPo6/7sc/iZ2Qg4/Myseka1UGnHcPiZWTZPdTGzyumRdQ0cfmY2Aj2Qfg4/M8vmxUzNrJK6P/ocfmaWa3S/zNYxHH5mNgLdn34OPzPL4sVMzayyeiD7HH5mls+jvWZWTd2fffS1uwJm1n1Ucmt4HmmdpF9JWiVpZSobJ2mppIfT37GpXJIuljQgabWkQ0bzHRx+ZpZFKr+V9P6ImB4RM9L7s4BlETEVWJbeAxwLTE3bXOCy0XwPh5+ZZVPJ/0ZoNrAwvV4IHF9TflUU7gTGSJo40os4/MwsW0bLb7yklTXb3O1OFcAtku6p+WxCRGxMr58AJqTXk4DHa45dn8pGxAMeZpYto0u7qaY7O5S/iogNkvYFlkr6de2HERGSYoTVrMstPzPLVLbT2zghI2JD+vsUcANwKPDkYHc2/X0q7b4BmFJz+ORUNiIOPzPLMviEx2gHPCS9QdKeg6+BmcADwCJgTtptDnBjer0I+Hga9T0c2FLTPc7mbq+ZtcsE4AYVKbkT8IOIuFnSCuA6SacCjwEnpv0XA8cBA8ALwCmjubjDz8yyNeMBj4h4BHjPEOW/BY4eojyAeaO/csHhZ2Z55MfbzKyC/BseZlZdPZB+Dj8zy+bf7TWzSuqBW34OPzPL1wPZ5/Azs3zqgaafw8/MsvTKb3iomDfYGSQ9TTGju9eMBza1uxKWpVf/zd4aEfuM5gSSbqb436eMTRExazTXa5WOCr9eJWllg5UtrMP436z3eWEDM6skh5+ZVZLDb8eY3+4KWDb/m/U43/Mzs0pyy8/MKsnh12TqhdmfZhXgbm8LSNoPOAB4EfgtsC4ift/OOpnZ6zn8mkjS24DPAGOBp4HdgFcoJm5fHxGPtrF6NoTUUq/tAQVARLwiaaeI2NaemlmrOfyaSNKlwHPAT4AtQD/FTPiPUvzS1Ocj4qH21dBySPoI8D8RcX+762LN52d7m+vPgTMj4hfblS+TtBR4G+Dw6yCSzgYOAp6k+IHsJykea1sJnAWcAzj8epDDr7kuBL4s6U7gPmAzsBXYFdiD3nxuududSvGTiE8DbwUOBsZR/H/jYGBd22pmLeXwa64fA38A3gu8D9iF4v7fVOBLwNr2Vc2G8RDwk4hYPlggSRERkgYoBqysB/meXwtI6gf2ohjweCkinmlzlWwYknYDiIiXhvjsS8BXPejRmxx+ZlZJnuRsZpXk8DOzSnL4VYCklyWtkvSApP+UtMcoznWlpA+n19+VNK3OvkdK+ssRXGOdpLIrBZuNiMOvGl6MiOkRcRDFaPTptR9KGtGof0T8Q0TUG8E+EsgOP7MdweFXPbcDb0+tstslLQLWSuqX9K+SVkhaLek0KKZ9SPqWpIck/QzYd/BEkn4uaUZ6PUvSvZLul7QsPd98OvD51Or8a0n7SLo+XWOFpCPSsXtLukXSGknfpTd+GdE6nOf5VUhq4R0L3JyKDgEOiohHJc0FtkTEeyXtCvxC0i0UE30PAKYBEyjmKi7Y7rz7AJcD70vnGhcRmyX9O/B8RFyY9vsBcFFE3CHpLcAS4J0UT1HcERHnSfogxcRjs5Zy+FXD7pJWpde3A1dQdEfvrllsYSbw7sH7ecCbKCZnvw+4OiJeBn4j6dYhzn84cNvguSJi8zD1+BtgWs2qX3tJemO6xofSsf8lyfMireUcftXwYkRMry1IAVS7zJaAT0fEku32O66J9egDDt9+QrGXQLR28D0/G7QE+JSknQEkvUPSG4DbgI+me4ITgfcPceydwPsk7Z+OHZfKnwP2rNnvFuDTg28kDQbybcDfp7JjKR4JNGsph58N+i7F/bx7JT0AfIeiZ3AD8HD67Crgl9sfGBFPA3OBH0m6H7g2ffQT4ITBAQ+KtQ5npAGVtbw26nwuRXiuoej+/l+LvqPZq/x4m5lVklt+ZlZJDj8zqySHn5lVksPPzCrJ4WdmleTwM7NKcviZWSU5/Myskv4fMxzNfmeW5bEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 64, RMSprop"
      ],
      "metadata": {
        "id": "aBqWvZfbDGSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=64\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=64,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=64,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70852fae-e1a9-4943-cd12-adba194d75f0",
        "id": "yrsFgt4EDGSt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa06602-59c4-448e-dd9b-8d3cc4a58e51",
        "id": "vZQ7Aq2nDGSu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.466983\n",
            "Validation set: Average loss: 0.456981, Accuracy: 4224/5000 (84%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.452023\n",
            "Validation set: Average loss: 0.452600, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.448692\n",
            "Validation set: Average loss: 0.450561, Accuracy: 4280/5000 (86%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.445808\n",
            "Validation set: Average loss: 0.449843, Accuracy: 4281/5000 (86%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.443640\n",
            "Validation set: Average loss: 0.451664, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.441492\n",
            "Validation set: Average loss: 0.451301, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.440535\n",
            "Validation set: Average loss: 0.450625, Accuracy: 4273/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.439390\n",
            "Validation set: Average loss: 0.451592, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.438086\n",
            "Validation set: Average loss: 0.450772, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.436909\n",
            "Validation set: Average loss: 0.452041, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.435471\n",
            "Validation set: Average loss: 0.448612, Accuracy: 4299/5000 (86%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.435134\n",
            "Validation set: Average loss: 0.452520, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.433855\n",
            "Validation set: Average loss: 0.452601, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.432819\n",
            "Validation set: Average loss: 0.451923, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.432641\n",
            "Validation set: Average loss: 0.453256, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.431031\n",
            "Validation set: Average loss: 0.453134, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.430858\n",
            "Validation set: Average loss: 0.451423, Accuracy: 4278/5000 (86%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.429986\n",
            "Validation set: Average loss: 0.452833, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.429629\n",
            "Validation set: Average loss: 0.455410, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.429687\n",
            "Validation set: Average loss: 0.452579, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.428246\n",
            "Validation set: Average loss: 0.453755, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.427263\n",
            "Validation set: Average loss: 0.454090, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.427827\n",
            "Validation set: Average loss: 0.453262, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.426109\n",
            "Validation set: Average loss: 0.453945, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.426754\n",
            "Validation set: Average loss: 0.453112, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.425338\n",
            "Validation set: Average loss: 0.454228, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.425371\n",
            "Validation set: Average loss: 0.453392, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.424976\n",
            "Validation set: Average loss: 0.453271, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.425103\n",
            "Validation set: Average loss: 0.455136, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.424390\n",
            "Validation set: Average loss: 0.452721, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.424410\n",
            "Validation set: Average loss: 0.454386, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.423536\n",
            "Validation set: Average loss: 0.454621, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.422769\n",
            "Validation set: Average loss: 0.454760, Accuracy: 4250/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.423203\n",
            "Validation set: Average loss: 0.453015, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.422605\n",
            "Validation set: Average loss: 0.454408, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.422142\n",
            "Validation set: Average loss: 0.454898, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.422425\n",
            "Validation set: Average loss: 0.454473, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.421049\n",
            "Validation set: Average loss: 0.455792, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.421211\n",
            "Validation set: Average loss: 0.454292, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.420897\n",
            "Validation set: Average loss: 0.455280, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.421051\n",
            "Validation set: Average loss: 0.455577, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.420707\n",
            "Validation set: Average loss: 0.455989, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.419789\n",
            "Validation set: Average loss: 0.456214, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.419650\n",
            "Validation set: Average loss: 0.456554, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.419596\n",
            "Validation set: Average loss: 0.454265, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.419042\n",
            "Validation set: Average loss: 0.456747, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.419209\n",
            "Validation set: Average loss: 0.456955, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.418980\n",
            "Validation set: Average loss: 0.456294, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.418177\n",
            "Validation set: Average loss: 0.457490, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.418479\n",
            "Validation set: Average loss: 0.456103, Accuracy: 4246/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# batch_size = 64\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "91b96931-19e5-4456-feb2-a2808ae3a672",
        "id": "j4dA5IQZDGSu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8492\n",
            "F1_SCORE:  0.7849\n",
            "CONFUSION_MATRIX:\n",
            " [[3490  321]\n",
            " [ 433  756]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8896    0.9158    0.9025      3811\n",
            "           1     0.7019    0.6358    0.6673      1189\n",
            "\n",
            "    accuracy                         0.8492      5000\n",
            "   macro avg     0.7958    0.7758    0.7849      5000\n",
            "weighted avg     0.8450    0.8492    0.8466      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 256, RMSprop"
      ],
      "metadata": {
        "id": "cDcXHorFDpq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=256\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=256,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=256,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e555f0b3-827a-47e2-d525-d3d7c23aa9ce",
        "id": "x5wkgFq1DprA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d89eef-6ede-466b-cb48-c95c42002347",
        "id": "_Yov6uEyDprA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.480722\n",
            "Validation set: Average loss: 0.459382, Accuracy: 4216/5000 (84%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.455353\n",
            "Validation set: Average loss: 0.455501, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.448969\n",
            "Validation set: Average loss: 0.455332, Accuracy: 4236/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.446884\n",
            "Validation set: Average loss: 0.453431, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.445984\n",
            "Validation set: Average loss: 0.452788, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.443985\n",
            "Validation set: Average loss: 0.456142, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.443077\n",
            "Validation set: Average loss: 0.454968, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.440277\n",
            "Validation set: Average loss: 0.453084, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.439142\n",
            "Validation set: Average loss: 0.452235, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.438929\n",
            "Validation set: Average loss: 0.451680, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.439606\n",
            "Validation set: Average loss: 0.454204, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.435881\n",
            "Validation set: Average loss: 0.451658, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.434919\n",
            "Validation set: Average loss: 0.454020, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.434699\n",
            "Validation set: Average loss: 0.457111, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.433165\n",
            "Validation set: Average loss: 0.453179, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.432132\n",
            "Validation set: Average loss: 0.453780, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.431937\n",
            "Validation set: Average loss: 0.453058, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.431117\n",
            "Validation set: Average loss: 0.455102, Accuracy: 4235/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.430923\n",
            "Validation set: Average loss: 0.453838, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.429746\n",
            "Validation set: Average loss: 0.456095, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.429634\n",
            "Validation set: Average loss: 0.456939, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.429932\n",
            "Validation set: Average loss: 0.454742, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.427618\n",
            "Validation set: Average loss: 0.454502, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.428133\n",
            "Validation set: Average loss: 0.456053, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.428646\n",
            "Validation set: Average loss: 0.458433, Accuracy: 4230/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.426800\n",
            "Validation set: Average loss: 0.456151, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.426976\n",
            "Validation set: Average loss: 0.456586, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.425583\n",
            "Validation set: Average loss: 0.457381, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.426538\n",
            "Validation set: Average loss: 0.458233, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.424939\n",
            "Validation set: Average loss: 0.461224, Accuracy: 4230/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.424050\n",
            "Validation set: Average loss: 0.456021, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.424029\n",
            "Validation set: Average loss: 0.460696, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.424379\n",
            "Validation set: Average loss: 0.457842, Accuracy: 4234/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.424287\n",
            "Validation set: Average loss: 0.456490, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.423521\n",
            "Validation set: Average loss: 0.457942, Accuracy: 4240/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.422641\n",
            "Validation set: Average loss: 0.458467, Accuracy: 4236/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.424263\n",
            "Validation set: Average loss: 0.456625, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.422157\n",
            "Validation set: Average loss: 0.459453, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.423055\n",
            "Validation set: Average loss: 0.455809, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.422202\n",
            "Validation set: Average loss: 0.458157, Accuracy: 4240/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.422565\n",
            "Validation set: Average loss: 0.462099, Accuracy: 4225/5000 (84%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.421125\n",
            "Validation set: Average loss: 0.460984, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.422922\n",
            "Validation set: Average loss: 0.472418, Accuracy: 4178/5000 (84%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.422495\n",
            "Validation set: Average loss: 0.458237, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.421655\n",
            "Validation set: Average loss: 0.458083, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.421320\n",
            "Validation set: Average loss: 0.456481, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.421132\n",
            "Validation set: Average loss: 0.458144, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.421286\n",
            "Validation set: Average loss: 0.457406, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.421335\n",
            "Validation set: Average loss: 0.459774, Accuracy: 4234/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.419980\n",
            "Validation set: Average loss: 0.458532, Accuracy: 4245/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 256\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "516adf39-b602-4a4c-a54a-ff7b4364bdd2",
        "id": "h514B8O7DprA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.849\n",
            "F1_SCORE:  0.7738\n",
            "CONFUSION_MATRIX:\n",
            " [[3564  247]\n",
            " [ 508  681]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8752    0.9352    0.9042      3811\n",
            "           1     0.7338    0.5728    0.6434      1189\n",
            "\n",
            "    accuracy                         0.8490      5000\n",
            "   macro avg     0.8045    0.7540    0.7738      5000\n",
            "weighted avg     0.8416    0.8490    0.8422      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEECAYAAABeGzPFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWzUlEQVR4nO3df7CcVX3H8ffnXiCAgkkI0BiiMBjBSGugEWhpKUKFgO0EHEXojKaUGmjBX0M7gtMRRXHsFGUUlRokEjoKpCISaSTEAAUcgQQIkQQpt/woieFHDESQHxr49o/nXFnDvbvPudnN7j7P58U8c3fPPj/OmvEz5zznPGcVEZiZ1c1AtytgZtYNDj8zqyWHn5nVksPPzGrJ4WdmteTwM7Na2q7bFWik7XYK7bBLt6thGQ5825u6XQXL8Oijj7BhwwZtzTkGd31zxOYXSu0bLzy1JCJmjfSZpB2BW4BxFFn0vYg4V9JlwF8Am9KufxsRKyUJ+ApwHPB8Kr87nWsO8C9p/89HxIJWdeut8NthF8btd2K3q2EZfnLH17pdBctw2CEzt/ocsflFxu1/Uql9X7znoklNPn4JODIinpO0PXCbpB+lz/45Ir63xf7HAtPSdghwMXCIpInAucBMIIC7JC2KiKeb1c3dXjPLI0AqtzURhefS2+3T1uypi9nA5em424HxkiYDxwBLI2JjCrylwIitzUYOPzPLp4FyW6vTSIOSVgJPUgTYHemj8yWtknShpHGpbArwWMPha1PZaOVNOfzMLF/5lt8kSSsatrmNp4mIlyNiBrAXcLCkA4BzgP2BdwITgU924iv01D0/M+sHKtWqSzZERMsbjRHxjKSbgFkRcUEqfknSt4F/Su/XAVMbDtsrla0Djtii/OZW13TLz8zyteGen6TdJY1Pr3cC3g38PN3HI43uHg/clw5ZBHxIhUOBTRGxHlgCHC1pgqQJwNGprCm3/MwsjwQDg+0402RggaRBiobYwoi4TtKNknanGFpZCZye9l9MMc1liGKqyykAEbFR0ueA5Wm/8yJiY6uLO/zMLF/5bu+oImIVcOAI5UeOsn8AZ4zy2Xxgfs71HX5mlq9Fl7YfOPzMLFPWgEfPcviZWZ7hSc59zuFnZvnc8jOz+hEMtmW0t6scfmaWR7jlZ2Y15Xt+ZlY/Hu01s7pyy8/Maqd9j7d1lcPPzPK522tmteRur5nVjwc8zKyu3PIzs9rxJGczqyeP9ppZXbnlZ2a15Ht+ZlY78mivmdWVW35mVkdy+JlZ3RS9XoefmdWO3PIzs3qqQvj1/5CNmW1zkkptLc6xo6Q7Jd0rabWkz6byfSTdIWlI0lWSdkjl49L7ofT53g3nOieVPyDpmDLfweFnZtnaEX7AS8CREfEOYAYwS9KhwL8CF0bEW4CngVPT/qcCT6fyC9N+SJoOnAS8HZgFfENSy0dQHH5mlkUSGii3NROF59Lb7dMWwJHA91L5AuD49Hp2ek/6/CgVCTsbuDIiXoqIh4Eh4OBW38PhZ2bZ2tTyQ9KgpJXAk8BS4H+BZyJic9plLTAlvZ4CPAaQPt8E7NZYPsIxo/KAh5llyxjwmCRpRcP7eRExb/hNRLwMzJA0HrgG2L99tWzO4Wdm2TLCb0NEzGy1U0Q8I+km4E+A8ZK2S627vYB1abd1wFRgraTtgDcAv2woH9Z4zKjc7TWzPMrYmp1G2j21+JC0E/Bu4H7gJuB9abc5wLXp9aL0nvT5jRERqfykNBq8DzANuLPV13DLz8yytWme32RgQRqZHQAWRsR1ktYAV0r6PHAPcGna/1LgPyQNARspRniJiNWSFgJrgM3AGak73ZTDz8yyCDEwsPWdxohYBRw4QvlDjDBaGxEvAu8f5VznA+fnXN/hZ2b5+v8BD4efmWVSNR5vc/iZWTaHn5nVksPPzGpHXtLKzGrJi5maWV255WdmteTwM7N66v/s6+yzvZJmpZVVhySd3clrmdm2064lrbqpYy2/9Lze1ykeVl4LLJe0KCLWdOqaZtZ5Unseb+u2Tn6Dg4GhiHgoIn4DXEmx4qqZ9bkqtPw6GX6lVleVNFfSCkkrYvMLHayOmbVNG5a06rauD3ikVV3nAQzsvEd0uTpmVkKvt+rK6GT4jWl1VTPrcRVZ2KCT3d7lwLT0G5w7UCw8uKiD1zOzbUCAVG7rZR1r+UXEZklnAkuAQWB+RKzu1PXMbFsRA368rbmIWAws7uQ1zGzbq0K3t+sDHmbWZ/qgS1uGw8/Msgjc7TWzenLLz8zqR275mVkNFVNdHH5mVju9/9xuGf2/NIOZbXPtmOQsaaqkmyStkbRa0sdS+WckrZO0Mm3HNRxzTloi7wFJxzSUZy+f55afmWVrU8tvM3BWRNwtaRfgLklL02cXRsQFW1xzOsWTYm8H3gj8WNJb08fZy+c5/MwsT5vm+UXEemB9ev2spPsZYeWnBrOBKyPiJeBhSUMUS+dBWj4PQNLw8nlNw8/dXjPLMjzPr8xW+pzS3sCBwB2p6ExJqyTNlzQhlY22TF6p5fO25PAzs2wZi5lOGl6vM21zRzjX64GrgY9HxK+Ai4F9gRkULcMvdeI7uNtrZtkyur0bImLm6OfR9hTB952I+D5ARDzR8PklwHXpbbNl8rKXz3PLz8zyqD3L2KvY4VLg/oj4ckP55IbdTgDuS68XASdJGidpH2AacCdjXD7PLT8zyzK8nl8bHAZ8EPiZpJWp7FPAyZJmAAE8ApwGEBGrJS2kGMjYDJwRES8DjGX5PIefmWVqzyTniLiNkX/pY9Rl8CLifOD8Ecqzl89z+JlZNj/ba2b14/X8zKyOvLCBmdWWw8/MaqkC2efwM7NMXszUzOpIFVnPz+FnZtkqkH0OPzPLN1CB9HP4mVm2CmSfw8/M8kie6mJmNTXo0V4zq6MKNPwcfmaWRxTTXfqdw8/MslWg1+vwM7NMJVZp7gcOPzPLVoHsc/iZWR7h0V4zqyl3e82sduSVnM2srir9bK+kiyh+Om5EEfHRjtTIzHpe/0df85bfim1WCzPrG5Uf8IiIBduyImbWJyoyz2+g1Q6Sdpd0gaTFkm4c3rZF5cysNw0PerTamp9DUyXdJGmNpNWSPpbKJ0paKunB9HdCKpekr0oakrRK0kEN55qT9n9Q0pwy36Fl+AHfAe4H9gE+CzwCLC9zcjOrJqXWX6uthc3AWRExHTgUOEPSdOBsYFlETAOWpfcAxwLT0jYXuDjVZSJwLnAIcDBw7nBgNlMm/HaLiEuB30bEf0fE3wFHljjOzCpIFM/2ltmaiYj1EXF3ev0sRSNrCjAbGL7ttgA4Pr2eDVwehduB8ZImA8cASyNiY0Q8DSwFZrX6HmWmuvw2/V0v6T3AL4CJJY4zs4pq9z0/SXsDBwJ3AHtGxPr00ePAnun1FOCxhsPWprLRypsqE36fl/QG4CzgImBX4BMljjOzCpJgsHz4TZLUOHNkXkTM+/3z6fXA1cDHI+JXjcEaESFp1Cl3W6Nl+EXEdenlJuBdnaiEmfWXjIbfhoiYOfp5tD1F8H0nIr6fip+QNDki1qdu7ZOpfB0wteHwvVLZOuCILcpvblWxluEn6duMMNk53fszsxpqR7dXxUkuBe6PiC83fLQImAN8Mf29tqH8TElXUgxubEoBuQT4QsMgx9HAOa2uX6bbe13D6x2BEyju+5lZTbXplt9hwAeBn0lamco+RRF6CyWdCjwKnJg+WwwcBwwBzwOnAETERkmf49VZKOdFxMZWFy/T7b268b2kK4DbWh1nZtUk1JZneyPiNkZ/Uu6oEfYP4IxRzjUfmJ9z/bEsbDAN2GMMx5lZFdRlVRdJz/L79/weBz7Zicr84X5TWXLzl1vvaD3jF0+/0O0qWIbfvPxKW86TMdrbs8p0e3fZFhUxs/4gqrGYaZlne5eVKTOz+mjHEx7d1mw9vx2BnSkmKU7g1RuTu1Ji9rSZVVevB1sZzbq9pwEfB94I3MWr4fcr4GsdrpeZ9ahixZb+T79m6/l9BfiKpI9ExEXbsE5m1uMGyyyJ0uPKfIVXJI0ffiNpgqR/7GCdzKyHFau6qNTWy8qE34cj4pnhN2nJmA93rkpm1usGSm69rMwk50FJSrOrkTQI7NDZaplZL+vxRl0pZcLveuAqSd9M708DftS5KplZL1MfdGnLKBN+n6RYMvr09H4V8Acdq5GZ9bwKZF+pJzxekXQHsC/F6gqTKNbfMrMaErBdBSb6NZvk/Fbg5LRtAK4CiAgvaGpWc1Vv+f0cuBX4q4gYApDk5evN6q4PHl0ro9lo9HuB9cBNki6RdBSjr71lZjWikv/1slHDLyJ+EBEnAfsDN1E86raHpIslHb2tKmhmvaVdP13ZbS3nIUbEryPiuxHx1xQ/DHIPHVrPz8z6w+CASm29LGsSdkQ8HRHzIuI1S0ybWT1UpeU3lmXszazO6rKMvZnZluryhIeZ2e8Md3v7ncPPzLJVoOHn8DOzPEKV+PW2Xl9yy8x6TcmR3jJdY0nzJT0p6b6Gss9IWidpZdqOa/jsHElDkh6QdExD+axUNiTp7DJfw+FnZtnauJLzZcCsEcovjIgZaVsMIGk6cBLw9nTMNyQNpjVGvw4cC0wHTk77NuVur5llKX63tz3niohbJO1dcvfZwJUR8RLwsKQh4OD02VBEPAQg6cq075pmJ3PLz8yyZbT8Jkla0bDNLXmJMyWtSt3iCalsCvBYwz5rU9lo5c2/Q8mKmJn9jlRuAzZExMyGbV6J019MsX7oDIrFVb7Uie/gbq+ZZZHo6GhvRDzx6rV0CXBdersOmNqw616pjCblo3LLz8yyqeQ2pnNLkxvengAMjwQvAk6SNE7SPsA04E5gOTBN0j6SdqAYFFnU6jpu+ZlZluHf7W3LuaQrgCMo7g2uBc4FjpA0AwjgEYofTSMiVktaSDGQsRk4IyJeTuc5E1gCDALzI2J1q2s7/MwsW7s6vRFx8gjFlzbZ/3zg/BHKFwOLc67t8DOzbBV4wMPhZ2Z5qvJ4m8PPzLLJ4WdmddT/0efwM7NccsvPzGpIVGOCsMPPzLK55WdmteRl7M2sdopub/+nn8PPzLJVoNfr8DOzXEJu+ZlZHbnlZ2a143t+ZlZPgoEKTPRz+JlZNt/zM7PaKRYz7XYttp7Dz8yyueVnZrVUhdHejt22TL+3+aSk+1rvbWb9QhS/3lZm62WdHLO5DJjVwfObWVeo9H+9rGPd3oi4RdLenTq/mXWJqtHt9T0/M8tWgezrfvhJmgvMBZgy9U1dro2ZtdLO3+3tpq7P046IeRExMyJm7rbbpG5Xx8xKUMmt5XlGGBiVNFHSUkkPpr8TUrkkfVXSkKRVkg5qOGZO2v9BSXPKfIeuh5+Z9R9JpbYSLuO1A6NnA8siYhqwLL0HOBaYlra5wMWpLhOBc4FDgIOBc4cDs5lOTnW5AvgpsJ+ktZJO7dS1zGzbksptrUTELcDGLYpnAwvS6wXA8Q3ll0fhdmC8pMnAMcDSiNgYEU8DSykx06STo70nd+rcZtZdHb7jt2dErE+vHwf2TK+nAI817Lc2lY1W3lTXBzzMrA+VT79JklY0vJ8XEfPKHhwRISlyqlaWw8/MshSDGaXTb0NEzMy8xBOSJkfE+tStfTKVrwOmNuy3VypbBxyxRfnNrS7iAQ8zy1Pyft9WzIZZBAyP2M4Brm0o/1Aa9T0U2JS6x0uAoyVNSAMdR6eyptzyM7Ns7ZrmlwZGj6DoHq+lGLX9IrAwDZI+CpyYdl8MHAcMAc8DpwBExEZJnwOWp/3Oi4gtB1Few+FnZpna99xuk4HRo0bYN4AzRjnPfGB+zrUdfmaWrQIPeDj8zCxP2ac3ep3Dz8zyVSD9HH5mlq0KCxs4/MwsW/9Hn8PPzHJV5Kafw8/MsvX6EvVlOPzMLIvwVBczq6kKZJ/Dz8zylVyotKc5/MwsWwWyz+FnZvkqkH0OPzMbgwqkn8PPzLJkLmbasxx+ZpZHMND/2efwM7MxcPiZWf20bzHTbnL4mVk2T3Uxs9qpyLoGDj8zG4MKpJ/Dz8yyeTFTM6ul/o8+h5+Z5dq6HyTvGQ4/MxuD/k+/gW5XwMz6y/BipmW2lueSHpH0M0krJa1IZRMlLZX0YPo7IZVL0lclDUlaJemgrfkeDj8zy6aSW0nviogZETEzvT8bWBYR04Bl6T3AscC0tM0FLt6a7+DwM7NsA1KpbYxmAwvS6wXA8Q3ll0fhdmC8pMlj/g5jPdDMaqx9Tb8AbpB0l6S5qWzPiFifXj8O7JleTwEeazh2bSobEw94mFm2jDbdpOF7ecm8iJjX8P7PImKdpD2ApZJ+3nhwRISk2KrKjsLhZ2ZZyg5mJBsa7uW9RkSsS3+flHQNcDDwhKTJEbE+dWufTLuvA6Y2HL5XKhsTd3vNLJtK/tf0HNLrJO0y/Bo4GrgPWATMSbvNAa5NrxcBH0qjvocCmxq6x9nc8jOzbG2a5LwncE36JbjtgO9GxPWSlgMLJZ0KPAqcmPZfDBwHDAHPA6dszcUdfmaWrR3hFxEPAe8YofyXwFEjlAdwxtZfueDwM7NMXszUzGpo+AmPfucBDzOrJbf8zCxbFVp+Dj8zyyMvZmpmNeTf8DCz+qpA+jn8zCybp7qYWS1V4Jafw8/M8lUg+xx+ZpZPFWj6OfzMLEtVnvBQ8axwb5D0FMUqDlUzCdjQ7UpYlqr+m705InbfmhNIup7if58yNkTErK25Xqf0VPhVlaQVzRZ0tN7jf7Pq87O9ZlZLDj8zqyWH37Yxr/Uu1mP8b1ZxvudnZrXklp+Z1ZLDr81UhdmfZjXgbm8HSNob2A94Afgl8EhE/LqbdTKz3+fwayNJ+wIfBSYATwE7Aq9QTNy+OiIe7mL1bASppd7YAwqAiHhF0nYRsbk7NbNOc/i1kaSvA88CPwQ2AYMUM+E/QPHr8p+IiAe6V0PLIen9wP9ExL3drou1n5/tba8/Bs6KiJ9sUb5M0lJgX8Dh10MknQMcADwBPJ7+bgBWAGcD5wIOvwpy+LXXBcBnJN0O3ANsBF4CxgE7U83nlvvdqcAiitsUbwYOBCZS/H/jQOCRrtXMOsrh114/AH4DvBM4HNiB4v7fNODTwJruVc1G8QDww4i4abhAkiIiJA1RDFhZBfmeXwdIGgR2pRjweDEinu5ylWwUknYEiIgXR/js08AXPOhRTQ4/M6slT3I2s1py+JlZLTn8akDSy5JWSrpP0n9K2nkrznWZpPel19+SNL3JvkdI+tMxXOMRSWVXCjYbE4dfPbwQETMi4gCK0ejTGz+UNKZR/4j4+4hoNoJ9BJAdfmbbgsOvfm4F3pJaZbdKWgSskTQo6d8kLZe0StJpUEz7kPQ1SQ9I+jGwx/CJJN0saWZ6PUvS3ZLulbQsPd98OvCJ1Or8c0m7S7o6XWO5pMPSsbtJukHSaknfohq/jGg9zvP8aiS18I4Frk9FBwEHRMTDkuYCmyLinZLGAT+RdAPFRN/9gOnAnhRzFedvcd7dgUuAw9O5JkbERkn/DjwXERek/b4LXBgRt0l6E7AEeBvFUxS3RcR5kt5DMfHYrKMcfvWwk6SV6fWtwKUU3dE7GxZbOBr4o+H7ecAbKCZnHw5cEREvA7+QdOMI5z8UuGX4XBGxcZR6/CUwvWHVr10lvT5d473p2P+S5HmR1nEOv3p4ISJmNBakAGpcZkvARyJiyRb7HdfGegwAh245odhLIFo3+J6fDVsC/IOk7QEkvVXS64BbgA+ke4KTgXeNcOztwOGS9knHTkzlzwK7NOx3A/CR4TeShgP5FuBvUtmxFI8EmnWUw8+GfYvift7dku4DvknRM7gGeDB9djnw0y0PjIingLnA9yXdC1yVPvohcMLwgAfFWocz04DKGl4ddf4sRXiupuj+/l+HvqPZ7/jxNjOrJbf8zKyWHH5mVksOPzOrJYefmdWSw8/MasnhZ2a15PAzs1py+JlZLf0/WwLXf/gdTiYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 512, RMSprop"
      ],
      "metadata": {
        "id": "TvW4u0ZGEBNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=64\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=512,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=512,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c911be37-1339-40a7-faeb-5ab877dcc770",
        "id": "AL6gYiX4GTn8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f289ba-b1ee-426c-aa57-6cc297ebf399",
        "id": "_vz_t_2qGTn9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.492226\n",
            "Validation set: Average loss: 0.462714, Accuracy: 4214/5000 (84%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.456732\n",
            "Validation set: Average loss: 0.458097, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.454374\n",
            "Validation set: Average loss: 0.461240, Accuracy: 4214/5000 (84%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.449198\n",
            "Validation set: Average loss: 0.457567, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.448523\n",
            "Validation set: Average loss: 0.455183, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.447699\n",
            "Validation set: Average loss: 0.454272, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.448386\n",
            "Validation set: Average loss: 0.455874, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.445531\n",
            "Validation set: Average loss: 0.454289, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.443085\n",
            "Validation set: Average loss: 0.455666, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.441554\n",
            "Validation set: Average loss: 0.455134, Accuracy: 4235/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.439274\n",
            "Validation set: Average loss: 0.452832, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.437723\n",
            "Validation set: Average loss: 0.452352, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.440254\n",
            "Validation set: Average loss: 0.452532, Accuracy: 4271/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.437996\n",
            "Validation set: Average loss: 0.453517, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.439086\n",
            "Validation set: Average loss: 0.454619, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.436998\n",
            "Validation set: Average loss: 0.455227, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.435354\n",
            "Validation set: Average loss: 0.454783, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.437207\n",
            "Validation set: Average loss: 0.454176, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.435254\n",
            "Validation set: Average loss: 0.453831, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.435792\n",
            "Validation set: Average loss: 0.453061, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.435054\n",
            "Validation set: Average loss: 0.453526, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.433457\n",
            "Validation set: Average loss: 0.454682, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.433834\n",
            "Validation set: Average loss: 0.454962, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.432642\n",
            "Validation set: Average loss: 0.454663, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.432864\n",
            "Validation set: Average loss: 0.460603, Accuracy: 4222/5000 (84%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.432912\n",
            "Validation set: Average loss: 0.454156, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.431215\n",
            "Validation set: Average loss: 0.453424, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.430625\n",
            "Validation set: Average loss: 0.454752, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.432060\n",
            "Validation set: Average loss: 0.455366, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.429435\n",
            "Validation set: Average loss: 0.454682, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.433356\n",
            "Validation set: Average loss: 0.455286, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.429314\n",
            "Validation set: Average loss: 0.455455, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.429529\n",
            "Validation set: Average loss: 0.456103, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.428779\n",
            "Validation set: Average loss: 0.457702, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.427878\n",
            "Validation set: Average loss: 0.455331, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.428760\n",
            "Validation set: Average loss: 0.456480, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.426677\n",
            "Validation set: Average loss: 0.456560, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.428415\n",
            "Validation set: Average loss: 0.461143, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.426715\n",
            "Validation set: Average loss: 0.457661, Accuracy: 4236/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.427284\n",
            "Validation set: Average loss: 0.460258, Accuracy: 4234/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.426542\n",
            "Validation set: Average loss: 0.465717, Accuracy: 4204/5000 (84%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.427649\n",
            "Validation set: Average loss: 0.456691, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.426725\n",
            "Validation set: Average loss: 0.459413, Accuracy: 4229/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.426208\n",
            "Validation set: Average loss: 0.457875, Accuracy: 4235/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.426531\n",
            "Validation set: Average loss: 0.459828, Accuracy: 4235/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.426679\n",
            "Validation set: Average loss: 0.457802, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.426228\n",
            "Validation set: Average loss: 0.457886, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.425712\n",
            "Validation set: Average loss: 0.468984, Accuracy: 4195/5000 (84%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.425177\n",
            "Validation set: Average loss: 0.459135, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.427863\n",
            "Validation set: Average loss: 0.459340, Accuracy: 4233/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# batch_size = 64\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "67fab5fd-5ed3-4e48-9c56-7eec6bbe8448",
        "id": "IwrnuTygGTn9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8466\n",
            "F1_SCORE:  0.7876\n",
            "CONFUSION_MATRIX:\n",
            " [[3434  377]\n",
            " [ 390  799]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8980    0.9011    0.8995      3811\n",
            "           1     0.6794    0.6720    0.6757      1189\n",
            "\n",
            "    accuracy                         0.8466      5000\n",
            "   macro avg     0.7887    0.7865    0.7876      5000\n",
            "weighted avg     0.8460    0.8466    0.8463      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 64, SGD"
      ],
      "metadata": {
        "id": "2XPrl1HbGTnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=64\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=64,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=64,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6364af31-1b2b-4004-9099-714ef6d4825b",
        "id": "SsQURUB6EBNq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe9fc2b-4872-420b-fc57-c5eb33032923",
        "id": "UjoNYRgvEBNr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.427117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set: Average loss: 0.456579, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.424303\n",
            "Validation set: Average loss: 0.456012, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.423250\n",
            "Validation set: Average loss: 0.455830, Accuracy: 4235/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.422784\n",
            "Validation set: Average loss: 0.455833, Accuracy: 4230/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.422314\n",
            "Validation set: Average loss: 0.455864, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.422046\n",
            "Validation set: Average loss: 0.455919, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.422126\n",
            "Validation set: Average loss: 0.455979, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.421977\n",
            "Validation set: Average loss: 0.456037, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.421826\n",
            "Validation set: Average loss: 0.456082, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.421741\n",
            "Validation set: Average loss: 0.456125, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.421555\n",
            "Validation set: Average loss: 0.456164, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.421569\n",
            "Validation set: Average loss: 0.456190, Accuracy: 4230/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.421527\n",
            "Validation set: Average loss: 0.456226, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.421483\n",
            "Validation set: Average loss: 0.456250, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.421435\n",
            "Validation set: Average loss: 0.456276, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.421522\n",
            "Validation set: Average loss: 0.456301, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.421479\n",
            "Validation set: Average loss: 0.456317, Accuracy: 4234/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.421549\n",
            "Validation set: Average loss: 0.456330, Accuracy: 4234/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.421444\n",
            "Validation set: Average loss: 0.456340, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.421409\n",
            "Validation set: Average loss: 0.456348, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.421430\n",
            "Validation set: Average loss: 0.456355, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.421367\n",
            "Validation set: Average loss: 0.456366, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.421248\n",
            "Validation set: Average loss: 0.456372, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.421484\n",
            "Validation set: Average loss: 0.456376, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.421435\n",
            "Validation set: Average loss: 0.456387, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.421288\n",
            "Validation set: Average loss: 0.456389, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.421310\n",
            "Validation set: Average loss: 0.456399, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.421278\n",
            "Validation set: Average loss: 0.456397, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.421110\n",
            "Validation set: Average loss: 0.456400, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.421268\n",
            "Validation set: Average loss: 0.456405, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.421250\n",
            "Validation set: Average loss: 0.456413, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.421179\n",
            "Validation set: Average loss: 0.456430, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.421280\n",
            "Validation set: Average loss: 0.456434, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.421301\n",
            "Validation set: Average loss: 0.456432, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.421106\n",
            "Validation set: Average loss: 0.456431, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.421166\n",
            "Validation set: Average loss: 0.456433, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.421175\n",
            "Validation set: Average loss: 0.456432, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.421058\n",
            "Validation set: Average loss: 0.456432, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.421198\n",
            "Validation set: Average loss: 0.456440, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.421009\n",
            "Validation set: Average loss: 0.456455, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.421058\n",
            "Validation set: Average loss: 0.456455, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.421101\n",
            "Validation set: Average loss: 0.456460, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.421066\n",
            "Validation set: Average loss: 0.456477, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.421307\n",
            "Validation set: Average loss: 0.456463, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.421024\n",
            "Validation set: Average loss: 0.456462, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.421119\n",
            "Validation set: Average loss: 0.456475, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.421120\n",
            "Validation set: Average loss: 0.456471, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.421063\n",
            "Validation set: Average loss: 0.456478, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.420992\n",
            "Validation set: Average loss: 0.456490, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.421123\n",
            "Validation set: Average loss: 0.456493, Accuracy: 4231/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 512\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "5c9d186e-9f47-4046-986c-89e30cf2f524",
        "id": "rnN0bkrZEBNr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8462\n",
            "F1_SCORE:  0.7745\n",
            "CONFUSION_MATRIX:\n",
            " [[3525  286]\n",
            " [ 483  706]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8795    0.9250    0.9016      3811\n",
            "           1     0.7117    0.5938    0.6474      1189\n",
            "\n",
            "    accuracy                         0.8462      5000\n",
            "   macro avg     0.7956    0.7594    0.7745      5000\n",
            "weighted avg     0.8396    0.8462    0.8412      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 256, SGD"
      ],
      "metadata": {
        "id": "180HaoClF4tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=256\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=256,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=256,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc0f8cd-3e3c-4fb6-ff10-b9327ad3ca6b",
        "id": "DUwUANsLF4tp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40c229a-2d91-4dc8-c529-a7f6a2bf20c3",
        "id": "oVhAtkf3F4tq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.479674\n",
            "Validation set: Average loss: 0.458383, Accuracy: 4225/5000 (84%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.455824\n",
            "Validation set: Average loss: 0.454811, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.451368\n",
            "Validation set: Average loss: 0.454382, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.448017\n",
            "Validation set: Average loss: 0.455864, Accuracy: 4231/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.446319\n",
            "Validation set: Average loss: 0.452750, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.442893\n",
            "Validation set: Average loss: 0.451586, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.441333\n",
            "Validation set: Average loss: 0.452901, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.439926\n",
            "Validation set: Average loss: 0.451977, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.439722\n",
            "Validation set: Average loss: 0.453652, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.438842\n",
            "Validation set: Average loss: 0.453079, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.437295\n",
            "Validation set: Average loss: 0.454801, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.436431\n",
            "Validation set: Average loss: 0.453496, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.435593\n",
            "Validation set: Average loss: 0.457121, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.436003\n",
            "Validation set: Average loss: 0.451957, Accuracy: 4273/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.434506\n",
            "Validation set: Average loss: 0.452887, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.432731\n",
            "Validation set: Average loss: 0.452655, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.431522\n",
            "Validation set: Average loss: 0.453611, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.431708\n",
            "Validation set: Average loss: 0.455447, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.432044\n",
            "Validation set: Average loss: 0.452529, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.431072\n",
            "Validation set: Average loss: 0.453701, Accuracy: 4250/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.430808\n",
            "Validation set: Average loss: 0.454602, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.430746\n",
            "Validation set: Average loss: 0.453236, Accuracy: 4274/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.429878\n",
            "Validation set: Average loss: 0.455128, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.428478\n",
            "Validation set: Average loss: 0.453537, Accuracy: 4271/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.428431\n",
            "Validation set: Average loss: 0.452169, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.429002\n",
            "Validation set: Average loss: 0.454279, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.426497\n",
            "Validation set: Average loss: 0.452653, Accuracy: 4265/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.427502\n",
            "Validation set: Average loss: 0.456708, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.426973\n",
            "Validation set: Average loss: 0.453574, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.426894\n",
            "Validation set: Average loss: 0.454626, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.425560\n",
            "Validation set: Average loss: 0.453002, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.426231\n",
            "Validation set: Average loss: 0.454012, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.425709\n",
            "Validation set: Average loss: 0.455219, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.424617\n",
            "Validation set: Average loss: 0.455413, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.424224\n",
            "Validation set: Average loss: 0.458465, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.424588\n",
            "Validation set: Average loss: 0.454453, Accuracy: 4275/5000 (86%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.423699\n",
            "Validation set: Average loss: 0.457663, Accuracy: 4240/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.423554\n",
            "Validation set: Average loss: 0.455541, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.423046\n",
            "Validation set: Average loss: 0.455757, Accuracy: 4250/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.422611\n",
            "Validation set: Average loss: 0.455191, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.422954\n",
            "Validation set: Average loss: 0.456569, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.423958\n",
            "Validation set: Average loss: 0.457490, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.423388\n",
            "Validation set: Average loss: 0.455735, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.422612\n",
            "Validation set: Average loss: 0.455884, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.421430\n",
            "Validation set: Average loss: 0.457720, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.422548\n",
            "Validation set: Average loss: 0.458758, Accuracy: 4223/5000 (84%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.421904\n",
            "Validation set: Average loss: 0.456060, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.420107\n",
            "Validation set: Average loss: 0.457276, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.420515\n",
            "Validation set: Average loss: 0.466582, Accuracy: 4199/5000 (84%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.422334\n",
            "Validation set: Average loss: 0.456959, Accuracy: 4257/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# batch_size = 64\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "a68e6c75-2400-402e-c8e4-95c2c1e44529",
        "id": "D1OneNHcF4tr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8514\n",
            "F1_SCORE:  0.784\n",
            "CONFUSION_MATRIX:\n",
            " [[3525  286]\n",
            " [ 457  732]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8852    0.9250    0.9047      3811\n",
            "           1     0.7191    0.6156    0.6633      1189\n",
            "\n",
            "    accuracy                         0.8514      5000\n",
            "   macro avg     0.8021    0.7703    0.7840      5000\n",
            "weighted avg     0.8457    0.8514    0.8473      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### batch_size = 512, SGD"
      ],
      "metadata": {
        "id": "82lJClI1HSHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=256\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=512,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=512,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe52b3b-9153-423f-ef5a-984f3b255e2f",
        "id": "R3c9WQj6HSH0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ead38d1-f7b0-406c-ef41-31bce7f4ecee",
        "id": "jaiAAtwWHSH1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.496117\n",
            "Validation set: Average loss: 0.462323, Accuracy: 4206/5000 (84%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.456637\n",
            "Validation set: Average loss: 0.459417, Accuracy: 4220/5000 (84%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.452928\n",
            "Validation set: Average loss: 0.456807, Accuracy: 4235/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.450733\n",
            "Validation set: Average loss: 0.460463, Accuracy: 4224/5000 (84%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.449967\n",
            "Validation set: Average loss: 0.453610, Accuracy: 4270/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.448563\n",
            "Validation set: Average loss: 0.453880, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.445738\n",
            "Validation set: Average loss: 0.453080, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.445186\n",
            "Validation set: Average loss: 0.450907, Accuracy: 4280/5000 (86%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.444745\n",
            "Validation set: Average loss: 0.453185, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.443730\n",
            "Validation set: Average loss: 0.453767, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.444159\n",
            "Validation set: Average loss: 0.454655, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.442951\n",
            "Validation set: Average loss: 0.451434, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.441591\n",
            "Validation set: Average loss: 0.452801, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.441100\n",
            "Validation set: Average loss: 0.461440, Accuracy: 4220/5000 (84%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.440646\n",
            "Validation set: Average loss: 0.452823, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.438767\n",
            "Validation set: Average loss: 0.462321, Accuracy: 4203/5000 (84%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.439891\n",
            "Validation set: Average loss: 0.451100, Accuracy: 4274/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.438450\n",
            "Validation set: Average loss: 0.452806, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.436660\n",
            "Validation set: Average loss: 0.450895, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.434660\n",
            "Validation set: Average loss: 0.450532, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.436246\n",
            "Validation set: Average loss: 0.452929, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.435462\n",
            "Validation set: Average loss: 0.450790, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.432424\n",
            "Validation set: Average loss: 0.450787, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.432857\n",
            "Validation set: Average loss: 0.455189, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.431269\n",
            "Validation set: Average loss: 0.454213, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.431679\n",
            "Validation set: Average loss: 0.451509, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.431535\n",
            "Validation set: Average loss: 0.451615, Accuracy: 4277/5000 (86%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.432470\n",
            "Validation set: Average loss: 0.452552, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.434049\n",
            "Validation set: Average loss: 0.461944, Accuracy: 4233/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.431227\n",
            "Validation set: Average loss: 0.451531, Accuracy: 4272/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.428269\n",
            "Validation set: Average loss: 0.451061, Accuracy: 4278/5000 (86%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.428845\n",
            "Validation set: Average loss: 0.451404, Accuracy: 4265/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.428287\n",
            "Validation set: Average loss: 0.452324, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.426991\n",
            "Validation set: Average loss: 0.460739, Accuracy: 4224/5000 (84%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.431346\n",
            "Validation set: Average loss: 0.459700, Accuracy: 4225/5000 (84%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.431068\n",
            "Validation set: Average loss: 0.450875, Accuracy: 4275/5000 (86%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.427523\n",
            "Validation set: Average loss: 0.455918, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.427020\n",
            "Validation set: Average loss: 0.452306, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.428201\n",
            "Validation set: Average loss: 0.452616, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.425428\n",
            "Validation set: Average loss: 0.452778, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.428110\n",
            "Validation set: Average loss: 0.461219, Accuracy: 4223/5000 (84%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.427365\n",
            "Validation set: Average loss: 0.451514, Accuracy: 4273/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.426207\n",
            "Validation set: Average loss: 0.452566, Accuracy: 4271/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.424655\n",
            "Validation set: Average loss: 0.455138, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.424705\n",
            "Validation set: Average loss: 0.456051, Accuracy: 4244/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.426303\n",
            "Validation set: Average loss: 0.454269, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.425410\n",
            "Validation set: Average loss: 0.454143, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.424473\n",
            "Validation set: Average loss: 0.457766, Accuracy: 4225/5000 (84%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.425242\n",
            "Validation set: Average loss: 0.455881, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.424283\n",
            "Validation set: Average loss: 0.456583, Accuracy: 4246/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# batch_size = 64\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "37548807-1b10-45a4-c6a3-c9ec85e81bc1",
        "id": "8fEYU1CDHSH1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8492\n",
            "F1_SCORE:  0.7965\n",
            "CONFUSION_MATRIX:\n",
            " [[3395  416]\n",
            " [ 338  851]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9095    0.8908    0.9001      3811\n",
            "           1     0.6717    0.7157    0.6930      1189\n",
            "\n",
            "    accuracy                         0.8492      5000\n",
            "   macro avg     0.7906    0.8033    0.7965      5000\n",
            "weighted avg     0.8529    0.8492    0.8508      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size =256 with optimize = adam have accuracy is the highest"
      ],
      "metadata": {
        "id": "s4c9c6MlJ1il"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7) Thử nghiệm thêm các layers mà bạn đã học được trong bài này vào kiến trúc của mình."
      ],
      "metadata": {
        "id": "sUmdD0shIVKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hl = 50\n",
        "# Define the neural network\n",
        "class IncomeNet_improve(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IncomeNet_improve, self).__init__()\n",
        "        self.fc1 = nn.Linear(len(features), hl)\n",
        "        nn.BatchNorm1d(64)\n",
        "        self.fc2 = nn.Linear(hl, hl)\n",
        "        nn.Dropout(0.4)\n",
        "        self.fc3 = nn.Linear(hl, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.nn.Softmax()(self.fc3(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "VqJdzYu8IdgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=256\n",
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).long()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=256,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=256,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f3c913-9e2d-4da9-c10d-def6fa7c8c1f",
        "id": "KP0EhTrUMbSx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance from the network\n",
        "model = IncomeNet_improve()\n",
        "print(model)\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29045146-bd24-4610-cccc-ee0ad2e9406d",
        "id": "htRLPfILMbSx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet_improve(\n",
            "  (fc1): Linear(in_features=108, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.554743\n",
            "Validation set: Average loss: 0.478437, Accuracy: 4157/5000 (83%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.465607\n",
            "Validation set: Average loss: 0.459678, Accuracy: 4225/5000 (84%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.456182\n",
            "Validation set: Average loss: 0.456353, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.451951\n",
            "Validation set: Average loss: 0.454578, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.449126\n",
            "Validation set: Average loss: 0.453893, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.446621\n",
            "Validation set: Average loss: 0.453382, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.445492\n",
            "Validation set: Average loss: 0.451787, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.443572\n",
            "Validation set: Average loss: 0.452239, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.442520\n",
            "Validation set: Average loss: 0.451523, Accuracy: 4273/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.440091\n",
            "Validation set: Average loss: 0.451335, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.440534\n",
            "Validation set: Average loss: 0.451501, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.438461\n",
            "Validation set: Average loss: 0.452222, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.439262\n",
            "Validation set: Average loss: 0.452125, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.438236\n",
            "Validation set: Average loss: 0.451936, Accuracy: 4266/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.436537\n",
            "Validation set: Average loss: 0.453150, Accuracy: 4265/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.435724\n",
            "Validation set: Average loss: 0.452656, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.435610\n",
            "Validation set: Average loss: 0.452700, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.433807\n",
            "Validation set: Average loss: 0.452153, Accuracy: 4260/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.432651\n",
            "Validation set: Average loss: 0.451868, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.433254\n",
            "Validation set: Average loss: 0.453855, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.432562\n",
            "Validation set: Average loss: 0.451349, Accuracy: 4277/5000 (86%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.432574\n",
            "Validation set: Average loss: 0.453109, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.431977\n",
            "Validation set: Average loss: 0.454059, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.431440\n",
            "Validation set: Average loss: 0.455261, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.430279\n",
            "Validation set: Average loss: 0.453690, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.429863\n",
            "Validation set: Average loss: 0.454008, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.430824\n",
            "Validation set: Average loss: 0.453802, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.428765\n",
            "Validation set: Average loss: 0.456439, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.429736\n",
            "Validation set: Average loss: 0.455299, Accuracy: 4250/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.427789\n",
            "Validation set: Average loss: 0.454896, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.427528\n",
            "Validation set: Average loss: 0.453905, Accuracy: 4262/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.428210\n",
            "Validation set: Average loss: 0.455087, Accuracy: 4255/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.426684\n",
            "Validation set: Average loss: 0.456290, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.426977\n",
            "Validation set: Average loss: 0.454281, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.425672\n",
            "Validation set: Average loss: 0.457085, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.426126\n",
            "Validation set: Average loss: 0.455564, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.424142\n",
            "Validation set: Average loss: 0.456317, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.424663\n",
            "Validation set: Average loss: 0.455142, Accuracy: 4254/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.423670\n",
            "Validation set: Average loss: 0.456687, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.422748\n",
            "Validation set: Average loss: 0.455550, Accuracy: 4257/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.422885\n",
            "Validation set: Average loss: 0.454982, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.423557\n",
            "Validation set: Average loss: 0.455564, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.422294\n",
            "Validation set: Average loss: 0.454706, Accuracy: 4264/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.421797\n",
            "Validation set: Average loss: 0.455453, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.421404\n",
            "Validation set: Average loss: 0.456291, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.421946\n",
            "Validation set: Average loss: 0.456201, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.422177\n",
            "Validation set: Average loss: 0.455147, Accuracy: 4261/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.420873\n",
            "Validation set: Average loss: 0.455371, Accuracy: 4258/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.421045\n",
            "Validation set: Average loss: 0.456061, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.422076\n",
            "Validation set: Average loss: 0.459091, Accuracy: 4239/5000 (85%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 256\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "d6d15813-8cde-4de4-c834-b0f98f10c72c",
        "id": "R7CMTP07MbSx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8478\n",
            "F1_SCORE:  0.7696\n",
            "CONFUSION_MATRIX:\n",
            " [[3576  235]\n",
            " [ 526  663]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8718    0.9383    0.9038      3811\n",
            "           1     0.7383    0.5576    0.6354      1189\n",
            "\n",
            "    accuracy                         0.8478      5000\n",
            "   macro avg     0.8050    0.7480    0.7696      5000\n",
            "weighted avg     0.8400    0.8478    0.8400      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8) Thay đổi các khởi tạo trọng số theo các phân phối khác nhau và đánh giá độ chính xác của kết quả huấn luyện."
      ],
      "metadata": {
        "id": "2fpulOkeNCWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def init_weights(m, init_type = 'xavier'):\n",
        "    if type(m) == nn.Linear:\n",
        "      if init_type == 'xavier':\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "      elif init_type == 'normal':\n",
        "        torch.nn.init.normal_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "      elif init_type == 'he':\n",
        "        m.bias.kaiming_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n"
      ],
      "metadata": {
        "id": "KApI848LMREe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### normal distribution "
      ],
      "metadata": {
        "id": "Ts2opoZ_PRZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = IncomeNet_improve()\n",
        "model.apply(lambda m: init_weights(m, init_type = 'normal'))\n",
        "\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Ge_n31OWnY",
        "outputId": "7a039e77-fbe7-467b-c76c-7b397076733e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.675640\n",
            "Validation set: Average loss: 0.603044, Accuracy: 3548/5000 (71%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.586167\n",
            "Validation set: Average loss: 0.566788, Accuracy: 3734/5000 (75%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.559422\n",
            "Validation set: Average loss: 0.554717, Accuracy: 3793/5000 (76%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.555542\n",
            "Validation set: Average loss: 0.555299, Accuracy: 3790/5000 (76%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.556823\n",
            "Validation set: Average loss: 0.554256, Accuracy: 3796/5000 (76%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.556339\n",
            "Validation set: Average loss: 0.553824, Accuracy: 3799/5000 (76%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.555019\n",
            "Validation set: Average loss: 0.554164, Accuracy: 3797/5000 (76%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.554415\n",
            "Validation set: Average loss: 0.552415, Accuracy: 3805/5000 (76%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.553329\n",
            "Validation set: Average loss: 0.552288, Accuracy: 3806/5000 (76%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.553501\n",
            "Validation set: Average loss: 0.552086, Accuracy: 3806/5000 (76%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.553802\n",
            "Validation set: Average loss: 0.552114, Accuracy: 3807/5000 (76%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.551592\n",
            "Validation set: Average loss: 0.551855, Accuracy: 3809/5000 (76%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.553039\n",
            "Validation set: Average loss: 0.551969, Accuracy: 3808/5000 (76%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.551398\n",
            "Validation set: Average loss: 0.552103, Accuracy: 3807/5000 (76%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.552692\n",
            "Validation set: Average loss: 0.551616, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.552369\n",
            "Validation set: Average loss: 0.551857, Accuracy: 3809/5000 (76%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.552490\n",
            "Validation set: Average loss: 0.551605, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.551520\n",
            "Validation set: Average loss: 0.551603, Accuracy: 3809/5000 (76%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.551512\n",
            "Validation set: Average loss: 0.552160, Accuracy: 3807/5000 (76%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.553922\n",
            "Validation set: Average loss: 0.551773, Accuracy: 3808/5000 (76%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.552579\n",
            "Validation set: Average loss: 0.552179, Accuracy: 3806/5000 (76%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.553379\n",
            "Validation set: Average loss: 0.551351, Accuracy: 3811/5000 (76%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.552531\n",
            "Validation set: Average loss: 0.550962, Accuracy: 3813/5000 (76%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.550057\n",
            "Validation set: Average loss: 0.551122, Accuracy: 3812/5000 (76%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.552872\n",
            "Validation set: Average loss: 0.551231, Accuracy: 3812/5000 (76%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.552369\n",
            "Validation set: Average loss: 0.550530, Accuracy: 3815/5000 (76%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.552479\n",
            "Validation set: Average loss: 0.551001, Accuracy: 3813/5000 (76%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.551618\n",
            "Validation set: Average loss: 0.551352, Accuracy: 3811/5000 (76%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.551292\n",
            "Validation set: Average loss: 0.551173, Accuracy: 3812/5000 (76%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.550900\n",
            "Validation set: Average loss: 0.551079, Accuracy: 3812/5000 (76%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.552273\n",
            "Validation set: Average loss: 0.551481, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.553276\n",
            "Validation set: Average loss: 0.551539, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.552308\n",
            "Validation set: Average loss: 0.551401, Accuracy: 3811/5000 (76%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.552795\n",
            "Validation set: Average loss: 0.551594, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.550513\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.552581\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.551543\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.551543\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.552581\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.551889\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.551197\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.550851\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.552581\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.552581\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.553620\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.551889\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.552235\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.551889\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.551543\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.552235\n",
            "Validation set: Average loss: 0.551543, Accuracy: 3810/5000 (76%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "e5UH4t9VO4Pi",
        "outputId": "8dd965f2-ea3d-4a26-dc8b-3e07e6de1b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.762\n",
            "F1_SCORE:  0.4357\n",
            "CONFUSION_MATRIX:\n",
            " [[3806    5]\n",
            " [1185    4]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7626    0.9987    0.8648      3811\n",
            "           1     0.4444    0.0034    0.0067      1189\n",
            "\n",
            "    accuracy                         0.7620      5000\n",
            "   macro avg     0.6035    0.5010    0.4357      5000\n",
            "weighted avg     0.6869    0.7620    0.6607      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEECAYAAABeGzPFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWtUlEQVR4nO3dfbBdVX3G8e+TCwRQMImBNCZRMhjBwNRAI9DSMgg1BGwn4ChCZzRDqYE2+Da0IzhTERTHTlFGUKlBIqGjQCoikUZCDKGAI5AAIZIg5ZaXkhgIMSGCvGjg1z/2OvUQ7j13r3vPyXnZz4fZc89ZZ5+99zHjM2vttfZaigjMzKpmVLsvwMysHRx+ZlZJDj8zqySHn5lVksPPzCrJ4WdmlbRbuy+gnnbbK7THPu2+DMtw2Lvf3u5LsAxPPvkEW7Zs0UiO0bfvOyJ2vFRq33jp2WURMXsk52uVzgq/PfZh9EGntvsyLMPP7vlGuy/BMhx95MwRHyN2vMzog08rte/LD1w+fsQnbJGOCj8z6wICNKLKY0dw+JlZPnV/d4HDz8zyueZnZtUj1/zMrKJc8zOzypFgVF+7r2LEHH5mls/NXjOrJDd7zax63OFhZlXkQc5mVlmu+ZlZ9Qj6ur+3t/vj28x2LVHU/MpsjQ4j7SnpXkkPSlon6cJUfrWkxyWtSduMVC5Jl0nql7RW0uF1x5or6dG0zS3zM1zzM7N8zbnn9wpwXES8IGl34C5JP0mf/VNE/GCn/U8EpqXtSOAK4EhJ44ALgJlAAPdJWhIR2xqd3DU/M8ukptT8ovBCert72hqtpTsHuCZ9725gjKSJwAnA8ojYmgJvOTDkHIIOPzPLJ5XbhjyM+iStATZTBNg96aOLU9P2UkmjU9kk4Km6r29IZYOVN+TwM7M8tcfbymwwXtLqum1e/aEi4tWImAFMBo6QdChwPnAw8F5gHPDZVvwM3/Mzs3zlh7psiYghp4+OiOckrQRmR8QlqfgVSd8F/jG93whMqfva5FS2ETh2p/Lbhzqna35mlq8JzV5J+0kak17vBbwf+GW6j4ckAScDD6WvLAE+lnp9jwK2R8QmYBkwS9JYSWOBWamsIdf8zCxT0x5vmwgsktRHURFbHBE3S7pN0n7FiVgDnJ32XwqcBPQDLwJnAETEVklfBFal/S6KiK1DndzhZ2b5mjDUJSLWAocNUH7cIPsHMH+QzxYCC3PO7/Azszy1Qc5dzuFnZpk8mamZVZVrfmZWSZ7SyswqR57M1MyqyjU/M6siOfzMrGqKVq/Dz8wqR675mVk1OfzMrJIcfmZWSQ4/M6scSe7wMLNqcs3PzCrJ4WdmleTwM7PqUdq6nMPPzLK55mdmlSPEqFHdP6tL9/8CM9v1VHJrdAhpT0n3SnpQ0jpJF6byqZLukdQv6XpJe6Ty0el9f/r8gLpjnZ/KH5F0Qpmf4PAzszxKY/1KbEN4BTguIt4DzABmpyUp/wW4NCLeCWwDzkz7nwlsS+WXpv2QNB04DTgEmA18K60I15DDz8yyNSP8ovBCert72gI4DvhBKl9EsXYvwJz0nvT58Wlt3znAdRHxSkQ8TrG05RFD/QaHn5lla1LND0l9ktYAm4HlwP8Az0XEjrTLBmBSej0JeAogfb4deGt9+QDfGZQ7PMwsi/KmtBovaXXd+wURsaD2JiJeBWZIGgPcCBzcvCttzOFnZnnyJjPdEhEzh9opIp6TtBL4U2CMpN1S7W4ysDHtthGYAmyQtBvwFuDXdeU19d8ZlJu9ZpatGc1eSfulGh+S9gLeDzwMrAQ+lHabC9yUXi9J70mf3xYRkcpPS73BU4FpwL1D/QbX/MwsW5MGOU8EFqWe2VHA4oi4WdJ64DpJXwIeAK5K+18F/LukfmArRQ8vEbFO0mJgPbADmJ+a0w05/MwsXxOyLyLWAocNUP4YA/TWRsTLwIcHOdbFwMU5529ps1fS7DTosF/Sea08l5ntOs3q7W2nltX8UlX2mxTt+A3AKklLImJ9q85pZq0n+fG2oRwB9EfEYxHxO+A6isGIZtbleqHm18rwKzXwUNI8SaslrY4dL7XwcsysaZrwbG+7tb3DIw14XAAwau/9o82XY2YldHqtroxWht+wBh6aWYdTb4RfK5u9q4BpaXqaPSjG5Cxp4fnMbBcQIJXbOlnLan4RsUPSOcAyoA9YGBHrWnU+M9tVxCgvXdlYRCwFlrbyHGa26/VCs7ftHR5m1mW6oElbhsPPzLII3Ow1s2pyzc/Mqkeu+ZlZBRVDXRx+ZlY5nf/cbhkOPzPL1gPZ5/Azs3yu+ZlZ9Xicn5lVkcf5mVll9UKzt/vnojazXa4Zs7pImiJppaT1ktZJ+lQq/4KkjZLWpO2kuu+cn9YEekTSCXXl2esFueZnZnmaN5/fDuDciLhf0j7AfZKWp88ujYhLXndaaTrF1HiHAG8DfirpXenj7PWCHH5mlqU2n99IRcQmYFN6/bykhxlgqYs6c4DrIuIV4PG0fm9ticv+tOQlkmrrBTUMPzd7zSxTucWLcmqHkg6gWMP3nlR0jqS1khZKGpvKBlsXqNR6QTtz+JlZtlGjVGoDxtcWKEvbvJ2PJenNwA3ApyPiN8AVwIHADIqa4Vdb8Rvc7DWzPHnj/LZExMxBDyXtThF834uIHwJExDN1n18J3JzeNloXKHu9INf8zCxLbWKDkTZ7VexwFfBwRHytrnxi3W6nAA+l10uA0ySNljQVmAbcyzDXC3LNz8yyNam392jgo8AvJK1JZZ8DTpc0AwjgCeAsgIhYJ2kxRUfGDmB+RLyarid7vSCHn5lla1Jv710MvLT5oOv+RMTFwMUDlGevF+TwM7M8nszUzKpIns/PzKqqB7LP4Wdm+Ub1QPo5/MwsWw9kn8PPzPKoeRMbtJXDz8yy9bm318yqqAcqfg4/M8sjiuEu3c7hZ2bZeqDV6/Azs0yZc/V1KoefmWXrgexz+JlZHuHeXjOrKDd7zaxyyixL2Q0cfmaWraef7ZV0OcVMqgOKiE+25IrMrON1f/Q1rvmt3mVXYWZdo+c7PCJi0a68EDPrEj0yzm/I1dsk7SfpEklLJd1W23bFxZlZZ6p1egy1NT6GpkhaKWm9pHWSPpXKx0laLunR9HdsKpekyyT1pwXND6871ty0/6OS5pb5DWWWrvwe8DAwFbiQYjWlVWUObma9qRlLV1KswHZuREwHjgLmS5oOnAesiIhpwIr0HuBEiuUqpwHzKBY3R9I44ALgSOAI4IJaYDZSJvzeGhFXAb+PiP+KiL8FjivxPTPrQaJ4trfM1khEbIqI+9Pr5ykqWZOAOUDtttsi4OT0eg5wTRTuBsakNX5PAJZHxNaI2AYsB2YP9TvKDHX5ffq7SdIHgF8B40p8z8x6VLPv+Uk6ADgMuAeYEBGb0kdPAxPS60nAU3Vf25DKBitvqEz4fUnSW4BzgcuBfYHPlPiemfUgCfrKh994SfUjRxZExILXH09vBm4APh0Rv6kP1ogISYMOuRuJIcMvIm5OL7cD72vFRZhZd8mo+G2JiJmDH0e7UwTf9yLih6n4GUkTI2JTatZuTuUbgSl1X5+cyjYCx+5UfvtQFzZk+En6LgMMdk73/sysgprR7FVxkKuAhyPia3UfLQHmAl9Jf2+qKz9H0nUUnRvbU0AuA75c18kxCzh/qPOXafbeXPd6T+AUivt+ZlZRTbrldzTwUeAXktakss9RhN5iSWcCTwKnps+WAicB/cCLwBkAEbFV0hf5wyiUiyJi61AnL9PsvaH+vaRrgbuG+p6Z9SahpjzbGxF3MfiTcscPsH8A8wc51kJgYc75hzOxwTRg/2F8z8x6QVVmdZH0PK+/5/c08NlWXMyBUyfytWv+uRWHNrMmyujt7Vhlmr377IoLMbPuIHpjMtMyz/auKFNmZtXRjCc82q3RfH57AntTDFIcyx9uTO5LidHTZta7Oj3YymjU7D0L+DTwNuA+/hB+vwG+0eLrMrMOVczY0v3p12g+v68DX5f0iYi4fBdek5l1uL4yU6J0uDI/4TVJY2pvJI2V9A8tvCYz62DFrC4qtXWyMuH38Yh4rvYmTRnz8dZdkpl1ulElt05WZpBznySl0dVI6gP2aO1lmVkn6/BKXSllwu8W4HpJ307vzwJ+0rpLMrNOpi5o0pZRJvw+SzFl9Nnp/Vrgj1p2RWbW8Xog+0o94fGapHuAAylmVxhPMf+WmVWQgN16YKBfo0HO7wJOT9sW4HqAiPCEpmYV1+s1v18CdwJ/FRH9AJI8fb1Z1XXBo2tlNOqN/iCwCVgp6UpJxzP43FtmViEq+V8nGzT8IuJHEXEacDCwkuJRt/0lXSFp1q66QDPrLM1aurLdhhyHGBG/jYjvR8RfUywM8gAtms/PzLpD3yiV2jpZ1iDsiNgWEQsi4g1TTJtZNfRKzW8409ibWZX1yDT2nf74nZl1oGZNbCBpoaTNkh6qK/uCpI2S1qTtpLrPzpfUL+kRSSfUlc9OZf2Sziv1GzJ/s5lVXJObvVcDswcovzQiZqRtKYCk6cBpwCHpO9+S1JfmG/gmcCIwHTg97duQm71mlq1Zzd6IuEPSASV3nwNcFxGvAI9L6geOSJ/1R8RjxbXpurTv+kYHc83PzLII0ady2wicI2ltahaPTWWTgKfq9tmQygYrb8jhZ2Z5SjZ5U7N3vKTVddu8Eme4gmIugRkUD1p8tRU/w81eM8uWMaXVloiYmXPsiHim9lrSlcDN6e1GYErdrpNTGQ3KB+Wan5llKdbtLbcN6/jSxLq3pwC1nuAlwGmSRkuaCkwD7gVWAdMkTZW0B0WnyJKhzuOan5lla9ZkppKuBY6laB5vAC4AjpU0AwjgCYoJlImIdZIWU3Rk7ADmR8Sr6TjnAMuAPmBhRKwb6twOPzPL1sTe3tMHKL6qwf4XAxcPUL4UWJpzboefmWWRGGlPbkdw+JlZtu6PPoefmWWqrdvb7Rx+Zpat+6PP4Wdmw9ADFT+Hn5nlqT3e1u0cfmaWTQ4/M6ui7o8+h5+Z5ZJrfmZWQaI3JgVw+JlZNtf8zKySOn1ltjIcfmaWpWj2dn/6OfzMLFsPtHodfmaWS8g1PzOrItf8zKxyfM/PzKpJMKoHBvo5/Mwsm+/5mVnlFJOZtvsqRq4HKq9mtqup5H9DHkdaKGmzpIfqysZJWi7p0fR3bCqXpMsk9UtaK+nwuu/MTfs/Kmlumd/g8DOzbE1ct/dqYPZOZecBKyJiGrAivQc4kWKt3mnAPOCK4lo0jmLJyyOBI4ALaoHZSMvCb6BEN7PuJ4rV28psQ4mIO4CtOxXPARal14uAk+vKr4nC3cCYtMD5CcDyiNgaEduA5bwxUN+glTW/q8tcgJl1m7KN3mHfGJwQEZvS66eBCen1JOCpuv02pLLByhtqWYdHRNwh6YBWHd/M2qR8kxZgvKTVde8XRMSCsl+OiJAUOZdXlnt7zSxbRp1uS0TMzDz8M5ImRsSm1KzdnMo3AlPq9pucyjYCx+5UfvtQJ2l7h4ekeZJWS1q9fdvOTX8z6zS1dXvLbMO0BKj12M4Fbqor/1jq9T0K2J6ax8uAWZLGpo6OWamsobbX/FIVeAHAtEPe05LqrZk1V7OG+Um6lqLWNl7SBope268AiyWdCTwJnJp2XwqcBPQDLwJnAETEVklfBFal/S6KiCFrUm0PPzPrPs2ayTkiTh/ko+MH2DeA+YMcZyGwMOfcrRzqci3wc+AgSRtSiptZD2jiOL+2aWVv72CJbmZdrsNzrRQ3e80sXw+kn8PPzLIIz+piZlXUBffzynD4mVk2h5+ZVZAXMDKzinLNz8wqR/REZ6/Dz8yGoQfSz+FnZtlGMGlBx3D4mVm27o8+h5+Z5eqRm34OPzPL5qEuZlY5wkNdzKyieiD7HH5mlq9Zk5m2k8PPzLL1QPY5/MwsXw9kX/tXbzOzLqSS21CHkZ6Q9AtJa2rr+0oaJ2m5pEfT37GpXJIuk9Qvaa2kw0fyExx+ZpalNplpmf9Kel9EzKhb3/c8YEVETANWpPcAJwLT0jYPuGIkv8PhZ2Z5BKNKbsM0B1iUXi8CTq4rvyYKdwNj0qLmw+LwM7N8TWr2AgHcKuk+SfNS2YS0GDnA08CE9HoS8FTddzeksmFxh4eZZcpq0o6v3ctLFkTEgrr3fx4RGyXtDyyX9Mv6L0dESIoRXvCAHH5mli1jqMuWunt5bxARG9PfzZJuBI4AnpE0MSI2pWbt5rT7RmBK3dcnp7JhcbPXzLKUbfEOlY+S3iRpn9prYBbwELAEmJt2mwvclF4vAT6Wen2PArbXNY+zueZnZvmaM9BvAnBjelpkN+D7EXGLpFXAYklnAk8Cp6b9lwInAf3Ai8AZIzm5w8/MsjVjMtOIeAx4zwDlvwaOH6A8gPkjPnHi8DOzbL3whIfDz8zyeNFyM6uu7k8/h5+ZZfFkpmZWWT2QfQ4/M8vnpSvNrJq6P/scfmaWrweyz+FnZnnkoS5mVlVet9fMKsk1PzOrJIefmVVQ1mSmHcvhZ2ZZeuUJD09mamaV5JqfmWXrhZqfw8/M8siPt5lZBZVflbKzOfzMLF8PpJ/Dz8yyeaiLmVVSD9zyc/iZWb4eyD6Hn5nlUw9U/Rx+ZpalV57wULEOcGeQ9CzFCu29Zjywpd0XYVl69d/sHRGx30gOIOkWiv99ytgSEbNHcr5W6ajw61WSVkfEzHZfh5Xnf7Pe52d7zaySHH5mVkkOv11jQbsvwLL536zH+Z6fmVWSa35mVkkOvyZTL4z+NKsAN3tbQNIBwEHAS8CvgSci4rftvCYzez2HXxNJOhD4JDAWeBbYE3iNYuD2DRHxeBsvzwaQaur1LaAAiIjXJO0WETvac2XWag6/JpL0TeB54MfAdqCPYiT8R4DJwGci4pH2XaHlkPRh4L8j4sF2X4s1n5/tba4/Ac6NiJ/tVL5C0nLgQMDh10EknQ8cCjwDPJ3+bgFWA+cBFwAOvx7k8GuuS4AvSLobeADYCrwCjAb2pjefW+52ZwJLKG5TvAM4DBhH8f+Nw4An2nZl1lIOv+b6EfA74L3AMcAeFPf/pgGfB9a379JsEI8AP46IlbUCSYqIkNRP0WFlPcj3/FpAUh+wL0WHx8sRsa3Nl2SDkLQnQES8PMBnnwe+7E6P3uTwM7NK8iBnM6skh5+ZVZLDrwIkvSppjaSHJP2HpL1HcKyrJX0ovf6OpOkN9j1W0p8N4xxPSCo7U7DZsDj8quGliJgREYdS9EafXf+hpGH1+kfE30VEox7sY4Hs8DPbFRx+1XMn8M5UK7tT0hJgvaQ+Sf8qaZWktZLOgmLYh6RvSHpE0k+B/WsHknS7pJnp9WxJ90t6UNKK9Hzz2cBnUq3zLyTtJ+mGdI5Vko5O332rpFslrZP0HXpjZUTrcB7nVyGphncicEsqOhw4NCIelzQP2B4R75U0GviZpFspBvoeBEwHJlCMVVy403H3A64EjknHGhcRWyX9G/BCRFyS9vs+cGlE3CXp7cAy4N0UT1HcFREXSfoAxcBjs5Zy+FXDXpLWpNd3AldRNEfvrZtsYRbwx7X7ecBbKAZnHwNcGxGvAr+SdNsAxz8KuKN2rIjYOsh1/CUwvW7Wr30lvTmd44Ppu/8pyeMireUcftXwUkTMqC9IAVQ/zZaAT0TEsp32O6mJ1zEKOGrnAcWeAtHawff8rGYZ8PeSdgeQ9C5JbwLuAD6S7glOBN43wHfvBo6RNDV9d1wqfx7Yp26/W4FP1N5IqgXyHcDfpLITKR4JNGsph5/VfIfift79kh4Cvk3RMrgReDR9dg3w852/GBHPAvOAH0p6ELg+ffRj4JRahwfFXIczU4fKev7Q63whRXiuo2j+/m+LfqPZ//PjbWZWSa75mVklOfzMrJIcfmZWSQ4/M6skh5+ZVZLDz8wqyeFnZpXk8DOzSvo/N/S8MVeanukAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### xavier distribution"
      ],
      "metadata": {
        "id": "F8XZIPgmPYxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = IncomeNet_improve()\n",
        "model.apply(lambda m: init_weights(m, init_type = 'xavier'))\n",
        "\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0iSTxLPPBVM",
        "outputId": "96755e03-f947-4129-ea67-4ae51e8b253e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Average loss: 0.505959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set: Average loss: 0.467277, Accuracy: 4178/5000 (84%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.462923\n",
            "Validation set: Average loss: 0.460616, Accuracy: 4206/5000 (84%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.456418\n",
            "Validation set: Average loss: 0.458926, Accuracy: 4219/5000 (84%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.451613\n",
            "Validation set: Average loss: 0.456782, Accuracy: 4227/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.449099\n",
            "Validation set: Average loss: 0.456675, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.447249\n",
            "Validation set: Average loss: 0.456123, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.445667\n",
            "Validation set: Average loss: 0.456549, Accuracy: 4235/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.443408\n",
            "Validation set: Average loss: 0.455355, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.442191\n",
            "Validation set: Average loss: 0.453744, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.440614\n",
            "Validation set: Average loss: 0.454134, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.438224\n",
            "Validation set: Average loss: 0.454266, Accuracy: 4243/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.439091\n",
            "Validation set: Average loss: 0.455127, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.437579\n",
            "Validation set: Average loss: 0.454393, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.436203\n",
            "Validation set: Average loss: 0.454886, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.435253\n",
            "Validation set: Average loss: 0.455007, Accuracy: 4252/5000 (85%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.434561\n",
            "Validation set: Average loss: 0.454031, Accuracy: 4256/5000 (85%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.433278\n",
            "Validation set: Average loss: 0.454747, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.432211\n",
            "Validation set: Average loss: 0.454285, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.431191\n",
            "Validation set: Average loss: 0.454676, Accuracy: 4240/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.430687\n",
            "Validation set: Average loss: 0.455839, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.433036\n",
            "Validation set: Average loss: 0.454637, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.429882\n",
            "Validation set: Average loss: 0.455365, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.428588\n",
            "Validation set: Average loss: 0.455448, Accuracy: 4249/5000 (85%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.428352\n",
            "Validation set: Average loss: 0.455233, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.428021\n",
            "Validation set: Average loss: 0.456607, Accuracy: 4250/5000 (85%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.427048\n",
            "Validation set: Average loss: 0.456418, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.426725\n",
            "Validation set: Average loss: 0.456267, Accuracy: 4240/5000 (85%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.427269\n",
            "Validation set: Average loss: 0.454985, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.425657\n",
            "Validation set: Average loss: 0.456984, Accuracy: 4240/5000 (85%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.425481\n",
            "Validation set: Average loss: 0.456847, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.424767\n",
            "Validation set: Average loss: 0.457166, Accuracy: 4253/5000 (85%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.424047\n",
            "Validation set: Average loss: 0.457693, Accuracy: 4242/5000 (85%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.424384\n",
            "Validation set: Average loss: 0.458015, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.423491\n",
            "Validation set: Average loss: 0.457434, Accuracy: 4239/5000 (85%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.424359\n",
            "Validation set: Average loss: 0.457388, Accuracy: 4229/5000 (85%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.423404\n",
            "Validation set: Average loss: 0.458119, Accuracy: 4217/5000 (84%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.422031\n",
            "Validation set: Average loss: 0.458177, Accuracy: 4241/5000 (85%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.421222\n",
            "Validation set: Average loss: 0.457398, Accuracy: 4246/5000 (85%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.422636\n",
            "Validation set: Average loss: 0.458286, Accuracy: 4232/5000 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.422413\n",
            "Validation set: Average loss: 0.457535, Accuracy: 4245/5000 (85%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.421314\n",
            "Validation set: Average loss: 0.457732, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.421760\n",
            "Validation set: Average loss: 0.457840, Accuracy: 4248/5000 (85%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.419187\n",
            "Validation set: Average loss: 0.459093, Accuracy: 4229/5000 (85%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.419885\n",
            "Validation set: Average loss: 0.459167, Accuracy: 4227/5000 (85%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.419325\n",
            "Validation set: Average loss: 0.459995, Accuracy: 4225/5000 (84%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.421336\n",
            "Validation set: Average loss: 0.458597, Accuracy: 4237/5000 (85%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.419438\n",
            "Validation set: Average loss: 0.457444, Accuracy: 4247/5000 (85%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.418823\n",
            "Validation set: Average loss: 0.459025, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.418278\n",
            "Validation set: Average loss: 0.458724, Accuracy: 4238/5000 (85%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.417265\n",
            "Validation set: Average loss: 0.460286, Accuracy: 4225/5000 (84%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  _, predictions = torch.max(model(x).data, 1)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "gA-9sr68PghJ",
        "outputId": "b33715da-1cec-478b-9204-b0987bea6c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.845\n",
            "F1_SCORE:  0.7784\n",
            "CONFUSION_MATRIX:\n",
            " [[3483  328]\n",
            " [ 447  742]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8863    0.9139    0.8999      3811\n",
            "           1     0.6935    0.6241    0.6569      1189\n",
            "\n",
            "    accuracy                         0.8450      5000\n",
            "   macro avg     0.7899    0.7690    0.7784      5000\n",
            "weighted avg     0.8404    0.8450    0.8421      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9) Thiết lập không gian search và tự động hóa tìm kiếm kiến trúc tốt nhất trên optuna."
      ],
      "metadata": {
        "id": "Ncr46BLoQvFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "HyA_smuCQxn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539c2658-0f9e-4bb1-a7ff-055f2618c3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.6)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.6)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.3.3)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.8.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "TdZ_a7Ok8kX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td\n",
        "\n",
        "# Set random seed for reproducability\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFvbfOeR8lR7",
        "outputId": "03fa5c47-8b38-44b8-8d62-b107f54ada4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9b6b4569d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "# Reshape y target into [-1, 1] to fit with Binary Cross Entropy\n",
        "train_y = torch.Tensor(y_train).view(-1, 1).float()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=16,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).view(-1, 1).float()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=16,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMOLE2Uw8ncT",
        "outputId": "d42a665e-b06b-4501-d815-544044a681c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
        "    layers = []\n",
        "\n",
        "    in_features = len(features)\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 16, 256)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.6)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, 1))\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "NUq2omWV8sXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCHSIZE = 16\n",
        "EPOCHS = 30\n",
        "LOG_INTERVAL = 10\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 300\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 100\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "    loss_criteria = nn.BCELoss()\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            # loss = F.nll_loss(output, target)\n",
        "            loss = loss_criteria(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(test_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = torch.tensor(output.data>=0.5).float()\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(test_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "DSgcIw-M9LSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6So4EaB9mlm",
        "outputId": "0a74cb86-ada8-4972-fec4-6e17f6dd4807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-19 16:52:55,652]\u001b[0m A new study created in memory with name: no-name-c2654ca5-6561-433e-ad5c-c2a54b9558eb\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:53:51,946]\u001b[0m Trial 0 finished with value: 0.83625 and parameters: {'n_layers': 6, 'n_units_l0': 17, 'dropout_l0': 0.5037489524462524, 'n_units_l1': 250, 'dropout_l1': 0.22707355639191787, 'n_units_l2': 41, 'dropout_l2': 0.307229099586679, 'n_units_l3': 143, 'dropout_l3': 0.4669228951876867, 'n_units_l4': 201, 'dropout_l4': 0.34903746525998514, 'n_units_l5': 193, 'dropout_l5': 0.5753719911955282, 'optimizer': 'RMSprop', 'lr': 0.0012927038665341646}. Best is trial 0 with value: 0.83625.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:54:54,716]\u001b[0m Trial 1 finished with value: 0.764375 and parameters: {'n_layers': 6, 'n_units_l0': 30, 'dropout_l0': 0.42597559552159847, 'n_units_l1': 98, 'dropout_l1': 0.38874546618187233, 'n_units_l2': 32, 'dropout_l2': 0.46860840742341525, 'n_units_l3': 243, 'dropout_l3': 0.41835308293319884, 'n_units_l4': 223, 'dropout_l4': 0.24135059764615474, 'n_units_l5': 82, 'dropout_l5': 0.5594866555973765, 'optimizer': 'Adam', 'lr': 0.01414162400378413}. Best is trial 0 with value: 0.83625.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:55:42,837]\u001b[0m Trial 2 finished with value: 0.855 and parameters: {'n_layers': 6, 'n_units_l0': 219, 'dropout_l0': 0.23980919672379444, 'n_units_l1': 248, 'dropout_l1': 0.34986595301960394, 'n_units_l2': 142, 'dropout_l2': 0.438721128866663, 'n_units_l3': 116, 'dropout_l3': 0.5509155907394176, 'n_units_l4': 119, 'dropout_l4': 0.2647080842329154, 'n_units_l5': 57, 'dropout_l5': 0.2538286694810323, 'optimizer': 'RMSprop', 'lr': 6.359102891995616e-05}. Best is trial 2 with value: 0.855.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:56:26,657]\u001b[0m Trial 3 finished with value: 0.855 and parameters: {'n_layers': 6, 'n_units_l0': 156, 'dropout_l0': 0.546416932725484, 'n_units_l1': 242, 'dropout_l1': 0.5629811222217609, 'n_units_l2': 82, 'dropout_l2': 0.2776607917512763, 'n_units_l3': 200, 'dropout_l3': 0.27769292364464093, 'n_units_l4': 37, 'dropout_l4': 0.358142443668286, 'n_units_l5': 238, 'dropout_l5': 0.4291366125995898, 'optimizer': 'RMSprop', 'lr': 0.0005306868132189213}. Best is trial 2 with value: 0.855.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:57:14,523]\u001b[0m Trial 4 finished with value: 0.764375 and parameters: {'n_layers': 6, 'n_units_l0': 75, 'dropout_l0': 0.2017731425185507, 'n_units_l1': 164, 'dropout_l1': 0.41757905591997846, 'n_units_l2': 67, 'dropout_l2': 0.2012977884142202, 'n_units_l3': 111, 'dropout_l3': 0.4988555825793779, 'n_units_l4': 23, 'dropout_l4': 0.3473262279986792, 'n_units_l5': 35, 'dropout_l5': 0.46228042363608696, 'optimizer': 'Adam', 'lr': 0.022072544372762303}. Best is trial 2 with value: 0.855.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:57:59,465]\u001b[0m Trial 5 finished with value: 0.85625 and parameters: {'n_layers': 6, 'n_units_l0': 252, 'dropout_l0': 0.2877905364816796, 'n_units_l1': 45, 'dropout_l1': 0.3745588111056335, 'n_units_l2': 60, 'dropout_l2': 0.37089052058679217, 'n_units_l3': 204, 'dropout_l3': 0.33682754013750693, 'n_units_l4': 189, 'dropout_l4': 0.23661928018713702, 'n_units_l5': 160, 'dropout_l5': 0.24227860550621122, 'optimizer': 'RMSprop', 'lr': 0.0007398165039222654}. Best is trial 5 with value: 0.85625.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:00,552]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:38,893]\u001b[0m Trial 7 finished with value: 0.85375 and parameters: {'n_layers': 5, 'n_units_l0': 129, 'dropout_l0': 0.3333490802829756, 'n_units_l1': 221, 'dropout_l1': 0.4342608086599554, 'n_units_l2': 21, 'dropout_l2': 0.5217660216068944, 'n_units_l3': 58, 'dropout_l3': 0.2803041953148216, 'n_units_l4': 180, 'dropout_l4': 0.2841918913142402, 'optimizer': 'RMSprop', 'lr': 0.0002964626861325747}. Best is trial 5 with value: 0.85625.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:40,348]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:41,573]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:42,738]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:44,183]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:45,781]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:47,076]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:48,427]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:57,908]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:58:59,391]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:59:11,722]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:59:13,501]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:59:15,010]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:59:16,773]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 16:59:31,569]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:00:19,669]\u001b[0m Trial 22 finished with value: 0.8575 and parameters: {'n_layers': 6, 'n_units_l0': 254, 'dropout_l0': 0.5758848594995846, 'n_units_l1': 250, 'dropout_l1': 0.5218223478136437, 'n_units_l2': 65, 'dropout_l2': 0.300846507442468, 'n_units_l3': 165, 'dropout_l3': 0.21526465123562524, 'n_units_l4': 86, 'dropout_l4': 0.20423219187780273, 'n_units_l5': 186, 'dropout_l5': 0.39904902636498135, 'optimizer': 'RMSprop', 'lr': 0.0006016605955517973}. Best is trial 22 with value: 0.8575.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:00:33,106]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:00:34,837]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:20,440]\u001b[0m Trial 25 finished with value: 0.84875 and parameters: {'n_layers': 5, 'n_units_l0': 233, 'dropout_l0': 0.3083059217639677, 'n_units_l1': 199, 'dropout_l1': 0.35980305078955277, 'n_units_l2': 101, 'dropout_l2': 0.37788740731679377, 'n_units_l3': 79, 'dropout_l3': 0.3768526997309283, 'n_units_l4': 56, 'dropout_l4': 0.4391662914240838, 'optimizer': 'RMSprop', 'lr': 0.0013411857858963826}. Best is trial 22 with value: 0.8575.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:28,357]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:30,003]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:32,173]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:33,669]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:34,889]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:36,440]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:01:38,064]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:02:20,461]\u001b[0m Trial 33 finished with value: 0.854375 and parameters: {'n_layers': 6, 'n_units_l0': 49, 'dropout_l0': 0.4809826213989938, 'n_units_l1': 253, 'dropout_l1': 0.5969990226944539, 'n_units_l2': 44, 'dropout_l2': 0.23602481130130323, 'n_units_l3': 188, 'dropout_l3': 0.3319381392023849, 'n_units_l4': 77, 'dropout_l4': 0.40268752153808907, 'n_units_l5': 164, 'dropout_l5': 0.5028192097714494, 'optimizer': 'RMSprop', 'lr': 0.0005024930724027576}. Best is trial 22 with value: 0.8575.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:02:22,046]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-19 17:03:06,249]\u001b[0m Trial 35 finished with value: 0.859375 and parameters: {'n_layers': 6, 'n_units_l0': 130, 'dropout_l0': 0.5962398353412779, 'n_units_l1': 224, 'dropout_l1': 0.43056566016115655, 'n_units_l2': 40, 'dropout_l2': 0.20931746467633816, 'n_units_l3': 140, 'dropout_l3': 0.21598451373784883, 'n_units_l4': 136, 'dropout_l4': 0.22900927956904027, 'n_units_l5': 162, 'dropout_l5': 0.24356749510358033, 'optimizer': 'RMSprop', 'lr': 0.0009295829883427843}. Best is trial 35 with value: 0.859375.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  36\n",
            "  Number of pruned trials:  25\n",
            "  Number of complete trials:  11\n",
            "Best trial:\n",
            "  Value:  0.859375\n",
            "  Params: \n",
            "    n_layers: 6\n",
            "    n_units_l0: 130\n",
            "    dropout_l0: 0.5962398353412779\n",
            "    n_units_l1: 224\n",
            "    dropout_l1: 0.43056566016115655\n",
            "    n_units_l2: 40\n",
            "    dropout_l2: 0.20931746467633816\n",
            "    n_units_l3: 140\n",
            "    dropout_l3: 0.21598451373784883\n",
            "    n_units_l4: 136\n",
            "    dropout_l4: 0.22900927956904027\n",
            "    n_units_l5: 162\n",
            "    dropout_l5: 0.24356749510358033\n",
            "    optimizer: RMSprop\n",
            "    lr: 0.0009295829883427843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model(trial)"
      ],
      "metadata": {
        "id": "tgahjtARBRnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_criteria = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=trial.params['lr'])\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 30 epochs\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "cKcQr9kMD7t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    '''\n",
        "    Train model through data loader and optimizer\n",
        "    Args:\n",
        "      model: model to train\n",
        "      data_loader: data loader to manage batch loading\n",
        "      optimizer: control update gradient descent\n",
        "    '''\n",
        "    # enable train mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        # reset optimizer into zero\n",
        "        optimizer.zero_grad()\n",
        "        # feed forward to compute output and loss\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        # accumulate loss\n",
        "        train_loss += loss.item()\n",
        "        # compute gradient descent\n",
        "        loss.backward()\n",
        "        # update into weight\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "            "
      ],
      "metadata": {
        "id": "e6FgFrF5HD8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data)\n",
        "      \n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out, target).item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            predicted = torch.tensor(out.data >= 0.5).float()\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "            \n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "JJ4xh26QTreR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training through epoch\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1ORhYz8KJ9b",
        "outputId": "04ce1fd8-e877-4cbd-c15a-950bafbfb9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 0.371292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set: Average loss: 0.333605, Accuracy: 4251/5000 (85%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.346428\n",
            "Validation set: Average loss: 0.316668, Accuracy: 4259/5000 (85%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.337579\n",
            "Validation set: Average loss: 0.317903, Accuracy: 4267/5000 (85%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.337365\n",
            "Validation set: Average loss: 0.314058, Accuracy: 4270/5000 (85%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.336444\n",
            "Validation set: Average loss: 0.329410, Accuracy: 4270/5000 (85%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.335988\n",
            "Validation set: Average loss: 0.317533, Accuracy: 4274/5000 (85%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.332751\n",
            "Validation set: Average loss: 0.344599, Accuracy: 4269/5000 (85%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.331192\n",
            "Validation set: Average loss: 0.338554, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.331541\n",
            "Validation set: Average loss: 0.322684, Accuracy: 4287/5000 (86%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.337575\n",
            "Validation set: Average loss: 0.347361, Accuracy: 4281/5000 (86%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.351050\n",
            "Validation set: Average loss: 0.349388, Accuracy: 4274/5000 (85%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.332729\n",
            "Validation set: Average loss: 0.359579, Accuracy: 4283/5000 (86%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.331311\n",
            "Validation set: Average loss: 0.338710, Accuracy: 4291/5000 (86%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.342385\n",
            "Validation set: Average loss: 0.362667, Accuracy: 4279/5000 (86%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.337603\n",
            "Validation set: Average loss: 0.338968, Accuracy: 4282/5000 (86%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.361974\n",
            "Validation set: Average loss: 0.342470, Accuracy: 4278/5000 (86%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.367077\n",
            "Validation set: Average loss: 0.333169, Accuracy: 4277/5000 (86%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.348293\n",
            "Validation set: Average loss: 0.316141, Accuracy: 4268/5000 (85%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.366784\n",
            "Validation set: Average loss: 0.331927, Accuracy: 4274/5000 (85%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.359918\n",
            "Validation set: Average loss: 0.364481, Accuracy: 4288/5000 (86%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.369563\n",
            "Validation set: Average loss: 0.412194, Accuracy: 4287/5000 (86%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.357169\n",
            "Validation set: Average loss: 0.336193, Accuracy: 4263/5000 (85%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.348390\n",
            "Validation set: Average loss: 0.347260, Accuracy: 4214/5000 (84%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.342636\n",
            "Validation set: Average loss: 0.335749, Accuracy: 4282/5000 (86%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.372036\n",
            "Validation set: Average loss: 0.419708, Accuracy: 4297/5000 (86%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.344646\n",
            "Validation set: Average loss: 0.398112, Accuracy: 4284/5000 (86%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.387938\n",
            "Validation set: Average loss: 0.355791, Accuracy: 4280/5000 (86%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.397285\n",
            "Validation set: Average loss: 0.343806, Accuracy: 4278/5000 (86%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.402935\n",
            "Validation set: Average loss: 0.359784, Accuracy: 4284/5000 (86%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.360393\n",
            "Validation set: Average loss: 0.345196, Accuracy: 4280/5000 (86%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  predictions = [1 if i>0.5 else 0 for i in model(x).data]\n",
        "  predictions = torch.tensor(predictions)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "_evaluate(model, x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "G0M_KSNqJzbK",
        "outputId": "a9b5e175-d71a-4680-ffad-54e85571e709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.856\n",
            "F1_SCORE:  0.7868\n",
            "CONFUSION_MATRIX:\n",
            " [[3564  247]\n",
            " [ 473  716]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8828    0.9352    0.9083      3811\n",
            "           1     0.7435    0.6022    0.6654      1189\n",
            "\n",
            "    accuracy                         0.8560      5000\n",
            "   macro avg     0.8132    0.7687    0.7868      5000\n",
            "weighted avg     0.8497    0.8560    0.8505      5000\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Deploy model sử dụng flask app"
      ],
      "metadata": {
        "id": "UUooHV2W9FjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B1. Đăng ký và tạo app trên heroku\n",
        "\n",
        "B2. Khởi tạo project bao gồm file app.py, 2 file model(scaler, income_model), index.html, requirements.txt, Procfile, runtime.txt\n",
        "- app.py: chứa hàm khởi chạy app và api để dự đoán\n",
        "- index.html: phần front_end call api\n",
        "- Requirements.txt: khai báo các dependencies cần thiết\n",
        "- Procfile là file thực thi của heroku khi app được lauch.\n",
        "- runtime.txt: khai báo môi trường chạy\n",
        "B3. Tạo project trên github sau đó push project vừa tạo lên\n",
        "\n",
        "B4. Kết nối app với project github\n",
        "\n",
        "B5. Cuối cùng pull code từ github về heroku và khởi chạy"
      ],
      "metadata": {
        "id": "lml69q1S95sr"
      }
    }
  ]
}