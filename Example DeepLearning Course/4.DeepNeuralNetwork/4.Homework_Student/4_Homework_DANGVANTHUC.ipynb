{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.Homework_DANGVANTHUC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEr1eFvAmug6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết\n",
        "\n",
        "1) Tại sao các mô hình deep learning lại chiếm ưu thế hơn so với các mô hình machine learning truyền thống đối với dữ liệu lớn ?\n",
        "\n",
        "A. Do mô hình deep learning có thể được thiết kế với kích thước tùy ý nên có khả năng xấp xỉ mọi hàm số. Do đó nó có khả năng biểu diễn tốt và hoạt động hiệu quả trên dữ liệu lớn.\n",
        "\n",
        "B. Các mô hình machine learning thường bị overfitting đối với dữ liệu lớn ?\n",
        "\n",
        "C. Các mô hình deep learning có chi phí huấn luyện tốn kém hơn so với machine learning.\n",
        "\n",
        "D. Do kiến trúc của mô hình Machine Learning bao gồm nhiều layers xếp chồng.\n",
        "\n",
        "# Đáp án A\n",
        "2) Ý nghĩa của hàm loss function trong mạng neural network là gì ?\n",
        "\n",
        "A. Là hàm số đánh giá độ chính xác của mô hình.\n",
        "\n",
        "B. Mục tiêu của quá trình huấn luyện là tối thiểu hóa hàm loss function bằng thuật toán gradient descent. Giá trị của hàm số này giúp đo lường mức độ khớp của dự báo từ mô hình trên dữ liệu huấn luyện.\n",
        "\n",
        "C. Khi loss function giảm thì luôn đảm bảo độ chính xác của mô hình tăng.\n",
        "\n",
        "D. Là hàm số cần tối đa hóa trong quá trình huấn luyện.\n",
        "\n",
        "# Đáp án B\n",
        "\n",
        "3) Khi huấn luyện trên các bộ dữ liệu bigdata thì chúng ta nên sử dụng phương pháp nào ?\n",
        "\n",
        "A) Sử dụng gradient descent trên toàn bộ dữ liệu.\n",
        "\n",
        "B) Sử dụng stochastic gradient descent trên từng điểm dữ liệu.\n",
        "\n",
        "C) Mini-batch gradient descent huấn luyện mô hình trên từng tập dữ liệu con có kích thước nhỏ hơn memory CPU/GPU.\n",
        "\n",
        "D) Có thể sử dụng stochastic gradient descent hoặc mini-batch gradient descent.\n",
        "\n",
        "# Đáp án C\n",
        "\n",
        "4) Quá trình feed forward và backpropagation thực hiện những gì ?\n",
        "\n",
        "A) feed forward tính toán output và loss function, backpropagation tính đạo hàm trên từng layer và cập nhật trọng số.\n",
        "\n",
        "B) feed forward cập nhật trọng số cho mô hình, backpropagation tính toán output và loss function.\n",
        "\n",
        "C) feed forward tính ra output của mô hình, backpropagation tính toán loss function\n",
        "\n",
        "\n",
        "D) feed forward được thực hiện sau backpropagation.\n",
        "\n",
        "# Đáp án A\n",
        "\n",
        "5) Tác dụng của batch normalization là gì ?\n",
        "\n",
        "A) Loại bỏ một tỷ lệ ngẫu nhiên số lượng units tại mỗi layer để tạo thành nhiều kiến trúc kết hợp ngẫu nhiên.\n",
        "\n",
        "B) Tìm ra các tham số phân phối là trung bình và phương sai trên từng mini-batch.\n",
        "\n",
        "C) Đồng nhất phân phối xác suất của $z^{[l]}$ trên mỗi layer $l$.\n",
        "\n",
        "D) Giảm thiểu ảnh hưởng của input distribution shift nhằm giúp huấn luyện loss function nhanh và ổn định hơn.\n",
        "\n",
        "# Đáp án D"
      ],
      "metadata": {
        "id": "PDDUcokDmyX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành\n",
        "\n",
        "Xuất phát từ mô hình tốt nhất của bạn xây dựng được đối với bài toán phân loại income classification tại bài trước. Bạn hãy thực hiện một số thử nghiệm sau:\n",
        "\n",
        "6) Thay đổi hàm loss function, batch size và optimizer.\n",
        "\n",
        "7) Thử nghiệm thêm các layers mà bạn đã học được trong bài này vào kiến trúc của mình.\n",
        "\n",
        "8) Thay đổi các khởi tạo trọng số theo các phân phối khác nhau và đánh giá độ chính xác của kết quả huấn luyện.\n",
        "\n",
        "9) Thiết lập không gian search và tự động hóa tìm kiếm kiến trúc tốt nhất trên optuna.\n",
        "\n",
        "10) Deploy model sử dụng flask ap. Tham khảo [Flaskapp tutorial](https://drive.google.com/file/d/1AZNtzrmnhJ-OBgijWoaAqXbPhJ6xL0Po/view?usp=sharing)."
      ],
      "metadata": {
        "id": "zYoLCUgcm1Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6) Thay đổi hàm loss function, batch size và optimizer.**"
      ],
      "metadata": {
        "id": "_wMe5n7fh_FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "def seed_all(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "seed = 42 \n",
        "seed_all(seed)"
      ],
      "metadata": {
        "id": "vuvFPAFCh8sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metric\n",
        "def get_metrics(y_test, y_pred):\n",
        "    print('ACCURACY_SCORE: ', round(accuracy_score(y_test, y_pred), 4))\n",
        "    print('F1_SCORE: ', round(f1_score(y_test, y_pred, average='macro'), 4))\n",
        "    print('CONFUSION_MATRIX:\\n', confusion_matrix(y_test, y_pred),'\\n')\n",
        "    print(classification_report(y_test, y_pred, digits=4), '\\n')"
      ],
      "metadata": {
        "id": "AK_L2Yg3h8qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "1zdcBxQrh8oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize string\n",
        "def str_normalize(s):\n",
        "    # convert into lowercase and replace multiple spaces into single space\n",
        "    s = str(s).strip().lower()\n",
        "    s = re.sub(' +', \" \", s)\n",
        "    return s\n",
        "# Encode category and object columns \n",
        "def process(df):        \n",
        "  for col in df.columns:\n",
        "      if df[col].dtype.name == \"object\" or df[col].dtype.name == \"category\":\n",
        "          df[col] = df[col].apply(str_normalize).astype(\"category\")\n",
        "  return df\n",
        "df_all = process(df_all.copy())\n",
        "IDs=df_all.pop('ID')\n",
        "label = df_all.pop('target_income')\n",
        "df_all_one_hot = pd.get_dummies(df_all)"
      ],
      "metadata": {
        "id": "eg6mEY1Lh8mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_all_one_hot.columns.tolist()\n",
        "label = label.values"
      ],
      "metadata": {
        "id": "IrqPNp1gh8kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_all_one_hot.columns.tolist()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_all_one_hot[features].values, # input variable\n",
        "                                                    label, # output variable\n",
        "                                                    test_size=0.2, # test dataset proportion\n",
        "                                                    # stratify=df_all['target_income'], # assign equal proportion of target label in train/test \n",
        "                                                    random_state=0) # keep train/test split the same if run again. \n",
        "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
        "#normalize\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YWvr5_6h8iI",
        "outputId": "06b34935-93b7-4bb2-da0e-ce4987e66277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 20000, Test Set: 5000 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).float()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=16,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).float()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=3232,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSNwjer-PtHi",
        "outputId": "c6d40b5f-d84f-4ecc-d313-7d47d454eb82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Number of hidden layer nodes\n",
        "hl = 20\n",
        "\n",
        "# Define the neural network\n",
        "class InCome(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InCome, self).__init__()\n",
        "        self.fc1 = nn.Linear(train_x.size(1), hl)\n",
        "        self.fc2 = nn.Linear(hl, hl)\n",
        "        self.fc3 = nn.Linear(hl, 6)\n",
        "        self.fc4 = nn.Linear(6, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.batchnorm = nn.BatchNorm1d(6)\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        x = self.batchnorm(x)\n",
        "        x = torch.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "\n",
        "# Create a model instance from the network\n",
        "model = InCome()\n",
        "model.apply(init_weights)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sF0v9yOPP0q",
        "outputId": "cb58c95d-3555-4fd6-970b-eb564736114b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InCome(\n",
            "  (fc1): Linear(in_features=108, out_features=20, bias=True)\n",
            "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
            "  (fc3): Linear(in_features=20, out_features=6, bias=True)\n",
            "  (fc4): Linear(in_features=6, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (batchnorm): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        #feedforward: calculate y_pred and loss function\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        #print(out.shape,target.shape)\n",
        "        loss = loss_criteria(out, target.reshape(-1,1))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backpropagate: compute gradient descent and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    #Return average loss\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "           \n",
        "            \n",
        "def test(model, data_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data)\n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out, target.reshape(-1,1)).item()\n",
        "            # Calculate the accuracy\n",
        "            #_, predicted = torch.max(out.data, 1)\n",
        "            predicted = [1 if i>0.5 else 0 for i in out.data]\n",
        "            predicted = torch.tensor(predicted)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "            \n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss\n",
        "\n",
        "# Specify the loss criteria (we'll use BINARY CROSS ENTROPY for binary-class classification)\n",
        "loss_criteria = nn.BCELoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 10 epochs\n",
        "epochs = 10\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en1_q4EGPPyU",
        "outputId": "03110b6b-13a6-4e9c-a6e2-065300833375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 0.425737\n",
            "Validation set: Average loss: 0.383856, Accuracy: 4013/5000 (80%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.422731\n",
            "Validation set: Average loss: 0.373284, Accuracy: 4133/5000 (83%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.414855\n",
            "Validation set: Average loss: 0.373943, Accuracy: 4187/5000 (84%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.416254\n",
            "Validation set: Average loss: 0.367741, Accuracy: 4181/5000 (84%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.411346\n",
            "Validation set: Average loss: 0.358023, Accuracy: 4173/5000 (83%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.416845\n",
            "Validation set: Average loss: 0.369314, Accuracy: 3981/5000 (80%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.416553\n",
            "Validation set: Average loss: 0.417522, Accuracy: 3811/5000 (76%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.419967\n",
            "Validation set: Average loss: 0.374144, Accuracy: 3969/5000 (79%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.416771\n",
            "Validation set: Average loss: 0.364788, Accuracy: 4138/5000 (83%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.417504\n",
            "Validation set: Average loss: 0.361412, Accuracy: 4177/5000 (84%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong bài mình có thêm 1 vài chiến lược như thay đổi batchsize = 32, thêm dropout 0.2 và batchnorm , khởi tạo weight Xavier_uniform \n",
        "\n",
        "Khi thay dổi các làm loss khác độ chính xác thấp hơn BCE nên mình dùng BCE"
      ],
      "metadata": {
        "id": "oQwbecZRcdU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s-xIe04PPwO",
        "outputId": "37c7c27c-5844-4521-e42b-d2ffbb614ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 37.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 39.8 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=20c0fbd4e83a0fccaf41b26d374804db1897b6af0dffbb4c2a4cac20cf1d0146\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "LIWUAfr2gnVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "# Reshape y target into [-1, 1] to fit with Binary Cross Entropy\n",
        "train_y = torch.Tensor(y_train).view(-1, 1).float()\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=16,\n",
        "    shuffle=True, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).view(-1, 1).float()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=16,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyhnyj_chiNC",
        "outputId": "b53f0a90-fdbb-41e7-8a7c-1cb23fe508cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
        "    layers = []\n",
        "\n",
        "    in_features = len(features)\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, 1))\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "TFw5bJ5VgwjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCHSIZE = 16\n",
        "EPOCHS = 30\n",
        "LOG_INTERVAL = 10\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 300\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 100\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "    loss_criteria = nn.BCELoss()\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            # loss = F.nll_loss(output, target)\n",
        "            loss = loss_criteria(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(test_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = torch.tensor(output.data>=0.5).float()\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(test_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "3I03MpQtg0Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb4t0xNgg4Fj",
        "outputId": "cf75eb36-b592-4264-8ea9-db20578081da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-20 00:26:57,895]\u001b[0m A new study created in memory with name: no-name-bb498ba7-a990-435e-a57b-84db7f01c352\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:27:41,218]\u001b[0m Trial 0 finished with value: 0.764375 and parameters: {'n_layers': 6, 'n_units_l0': 63, 'dropout_l0': 0.2892944242526006, 'n_units_l1': 52, 'dropout_l1': 0.46551406221282626, 'n_units_l2': 18, 'dropout_l2': 0.20730112551662597, 'n_units_l3': 77, 'dropout_l3': 0.4958448227004014, 'n_units_l4': 58, 'dropout_l4': 0.4118398402134398, 'n_units_l5': 9, 'dropout_l5': 0.2431694069972436, 'optimizer': 'SGD', 'lr': 3.189808946809925e-05}. Best is trial 0 with value: 0.764375.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:28:20,512]\u001b[0m Trial 1 finished with value: 0.846875 and parameters: {'n_layers': 3, 'n_units_l0': 18, 'dropout_l0': 0.3453890333835895, 'n_units_l1': 41, 'dropout_l1': 0.23079371589397613, 'n_units_l2': 30, 'dropout_l2': 0.39868168026758966, 'optimizer': 'RMSprop', 'lr': 0.0013154691815693365}. Best is trial 1 with value: 0.846875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:29:02,526]\u001b[0m Trial 2 finished with value: 0.8575 and parameters: {'n_layers': 4, 'n_units_l0': 80, 'dropout_l0': 0.29594940043617923, 'n_units_l1': 51, 'dropout_l1': 0.49127240157466256, 'n_units_l2': 17, 'dropout_l2': 0.4644820764777837, 'n_units_l3': 44, 'dropout_l3': 0.44890946669556897, 'optimizer': 'RMSprop', 'lr': 0.0003569474830127157}. Best is trial 2 with value: 0.8575.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:29:43,570]\u001b[0m Trial 3 finished with value: 0.760625 and parameters: {'n_layers': 4, 'n_units_l0': 120, 'dropout_l0': 0.33955158121526696, 'n_units_l1': 108, 'dropout_l1': 0.4289809852882104, 'n_units_l2': 105, 'dropout_l2': 0.40019799603172357, 'n_units_l3': 90, 'dropout_l3': 0.4337102932317042, 'optimizer': 'SGD', 'lr': 2.024007833010789e-05}. Best is trial 2 with value: 0.8575.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:30:28,300]\u001b[0m Trial 4 finished with value: 0.764375 and parameters: {'n_layers': 4, 'n_units_l0': 96, 'dropout_l0': 0.243660613688081, 'n_units_l1': 14, 'dropout_l1': 0.47362933770199783, 'n_units_l2': 90, 'dropout_l2': 0.26988705617632025, 'n_units_l3': 27, 'dropout_l3': 0.3578694987201283, 'optimizer': 'RMSprop', 'lr': 0.07290803341237624}. Best is trial 2 with value: 0.8575.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:31:06,741]\u001b[0m Trial 5 finished with value: 0.764375 and parameters: {'n_layers': 2, 'n_units_l0': 47, 'dropout_l0': 0.21467925906323532, 'n_units_l1': 31, 'dropout_l1': 0.26524254375037054, 'optimizer': 'Adam', 'lr': 0.031257085916523875}. Best is trial 2 with value: 0.8575.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:31:09,608]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:31:55,509]\u001b[0m Trial 7 finished with value: 0.858125 and parameters: {'n_layers': 5, 'n_units_l0': 18, 'dropout_l0': 0.47313354986950057, 'n_units_l1': 81, 'dropout_l1': 0.4821079268828953, 'n_units_l2': 29, 'dropout_l2': 0.2613015999679479, 'n_units_l3': 51, 'dropout_l3': 0.2895399651389897, 'n_units_l4': 86, 'dropout_l4': 0.20384284910302156, 'optimizer': 'Adam', 'lr': 0.0009255952196120388}. Best is trial 7 with value: 0.858125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:31:56,888]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:31:59,403]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:32:02,848]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:32:05,808]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:32:08,901]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:32:53,795]\u001b[0m Trial 13 finished with value: 0.85625 and parameters: {'n_layers': 5, 'n_units_l0': 42, 'dropout_l0': 0.4131439848364778, 'n_units_l1': 7, 'dropout_l1': 0.4335513051755514, 'n_units_l2': 33, 'dropout_l2': 0.3125838044583301, 'n_units_l3': 8, 'dropout_l3': 0.3962687607157208, 'n_units_l4': 70, 'dropout_l4': 0.30856957198060286, 'optimizer': 'Adam', 'lr': 0.004029738287830033}. Best is trial 7 with value: 0.858125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:32:56,726]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:33:40,705]\u001b[0m Trial 15 finished with value: 0.858125 and parameters: {'n_layers': 4, 'n_units_l0': 102, 'dropout_l0': 0.3862941687760179, 'n_units_l1': 29, 'dropout_l1': 0.3390806327403187, 'n_units_l2': 57, 'dropout_l2': 0.27124606583593636, 'n_units_l3': 55, 'dropout_l3': 0.4737473881928959, 'optimizer': 'Adam', 'lr': 0.0010336498369045077}. Best is trial 7 with value: 0.858125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:34:29,985]\u001b[0m Trial 16 finished with value: 0.85375 and parameters: {'n_layers': 6, 'n_units_l0': 103, 'dropout_l0': 0.449699252440235, 'n_units_l1': 25, 'dropout_l1': 0.326122280316403, 'n_units_l2': 63, 'dropout_l2': 0.26358224215028714, 'n_units_l3': 93, 'dropout_l3': 0.30359979704040674, 'n_units_l4': 16, 'dropout_l4': 0.2743160842410096, 'n_units_l5': 60, 'dropout_l5': 0.4319855916605915, 'optimizer': 'Adam', 'lr': 0.0019469791814945758}. Best is trial 7 with value: 0.858125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:34:43,171]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:34:47,848]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:34:49,352]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:34:50,934]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:34:57,859]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:35:39,639]\u001b[0m Trial 22 finished with value: 0.854375 and parameters: {'n_layers': 4, 'n_units_l0': 93, 'dropout_l0': 0.38213094427782335, 'n_units_l1': 37, 'dropout_l1': 0.4464922174023155, 'n_units_l2': 61, 'dropout_l2': 0.35254854860573115, 'n_units_l3': 77, 'dropout_l3': 0.44453986788358724, 'optimizer': 'RMSprop', 'lr': 0.0003577839721813756}. Best is trial 7 with value: 0.858125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:35:40,990]\u001b[0m Trial 23 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:35:42,409]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:35:43,883]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:35:45,394]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:36:37,515]\u001b[0m Trial 27 finished with value: 0.850625 and parameters: {'n_layers': 6, 'n_units_l0': 92, 'dropout_l0': 0.43612884396793156, 'n_units_l1': 38, 'dropout_l1': 0.2040489119986926, 'n_units_l2': 53, 'dropout_l2': 0.3325416145551845, 'n_units_l3': 74, 'dropout_l3': 0.3177808666534622, 'n_units_l4': 117, 'dropout_l4': 0.4910087478550267, 'n_units_l5': 126, 'dropout_l5': 0.21748575079723975, 'optimizer': 'Adam', 'lr': 0.0023599177892575708}. Best is trial 7 with value: 0.858125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:36:39,032]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:36:40,471]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:36:41,749]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:36:43,193]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:36:44,737]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 00:37:27,342]\u001b[0m Trial 33 finished with value: 0.855 and parameters: {'n_layers': 4, 'n_units_l0': 15, 'dropout_l0': 0.39283810543662273, 'n_units_l1': 16, 'dropout_l1': 0.4612294529586736, 'n_units_l2': 39, 'dropout_l2': 0.20344254501460415, 'n_units_l3': 28, 'dropout_l3': 0.4146906785049871, 'optimizer': 'Adam', 'lr': 0.003055662300550298}. Best is trial 7 with value: 0.858125.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  34\n",
            "  Number of pruned trials:  21\n",
            "  Number of complete trials:  13\n",
            "Best trial:\n",
            "  Value:  0.858125\n",
            "  Params: \n",
            "    n_layers: 5\n",
            "    n_units_l0: 18\n",
            "    dropout_l0: 0.47313354986950057\n",
            "    n_units_l1: 81\n",
            "    dropout_l1: 0.4821079268828953\n",
            "    n_units_l2: 29\n",
            "    dropout_l2: 0.2613015999679479\n",
            "    n_units_l3: 51\n",
            "    dropout_l3: 0.2895399651389897\n",
            "    n_units_l4: 86\n",
            "    dropout_l4: 0.20384284910302156\n",
            "    optimizer: Adam\n",
            "    lr: 0.0009255952196120388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model(trial)"
      ],
      "metadata": {
        "id": "7QyezNYRg6y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_criteria = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=trial.params['lr'])\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 30 epochs\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "mp9GLB0KkWiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    '''\n",
        "    Train model through data loader and optimizer\n",
        "    Args:\n",
        "      model: model to train\n",
        "      data_loader: data loader to manage batch loading\n",
        "      optimizer: control update gradient descent\n",
        "    '''\n",
        "    # enable train mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        # reset optimizer into zero\n",
        "        optimizer.zero_grad()\n",
        "        # feed forward to compute output and loss\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        # accumulate loss\n",
        "        train_loss += loss.item()\n",
        "        # compute gradient descent\n",
        "        loss.backward()\n",
        "        # update into weight\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "            "
      ],
      "metadata": {
        "id": "eRfxtkGGkaPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training through epoch\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "id": "vF0r-5F0kcnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mình dùng lun của anh Khánh , định modify 1 tí nhưng chạy lâu quá sợ hạn chế thời gian dùng GPU COLAB nên chưa modify lại đượcđược\n",
        "\n",
        "Đây là tham số tốt nhất sau khi chạy\n",
        "----\n",
        "    Study statistics: \n",
        "      Number of finished trials:  34\n",
        "      Number of pruned trials:  21\n",
        "      Number of complete trials:  13\n",
        "    Best trial:\n",
        "      Value:  0.858125\n",
        "      Params: \n",
        "        n_layers: 5\n",
        "        n_units_l0: 18\n",
        "        dropout_l0: 0.47313354986950057\n",
        "        n_units_l1: 81\n",
        "        dropout_l1: 0.4821079268828953\n",
        "        n_units_l2: 29\n",
        "        dropout_l2: 0.2613015999679479\n",
        "        n_units_l3: 51\n",
        "        dropout_l3: 0.2895399651389897\n",
        "        n_units_l4: 86\n",
        "        dropout_l4: 0.20384284910302156\n",
        "        optimizer: Adam\n",
        "        lr: 0.0009255952196120388\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "Ov_fBUrHm9r6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10) Deploy model sử dụng flask ap. Tham khảo Flaskapp tutorial."
      ],
      "metadata": {
        "id": "OtKxxhg2oFcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colabcode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JEzHHR3tl9_2",
        "outputId": "7f87ba54-2333-4777-b555-23720aeeeb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colabcode\n",
            "  Downloading colabcode-0.3.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting uvicorn==0.13.1\n",
            "  Downloading uvicorn-0.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting jupyterlab==3.0.7\n",
            "  Downloading jupyterlab-3.0.7-py3-none-any.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 13.1 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio==1.4.3\n",
            "  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
            "Collecting pyngrok>=5.0.0\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 32.9 MB/s \n",
            "\u001b[?25hCollecting tornado>=6.1.0\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (5.5.0)\n",
            "Collecting nbclassic~=0.2\n",
            "  Downloading nbclassic-0.3.5-py3-none-any.whl (25 kB)\n",
            "Collecting jupyter-server~=1.2\n",
            "  Downloading jupyter_server-1.13.5-py3-none-any.whl (397 kB)\n",
            "\u001b[K     |████████████████████████████████| 397 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting jupyterlab-server~=2.0\n",
            "  Downloading jupyterlab_server-2.10.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (4.9.1)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (21.3)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (3.10.0.2)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.6.1)\n",
            "Collecting jupyter-client>=6.1.1\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (22.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.13.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.1.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.3.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.1.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.8.0)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.13.1)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.4)\n",
            "Collecting jupyter-client>=6.1.1\n",
            "  Downloading jupyter_client-7.1.1-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 48.3 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.1.0-py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 47.6 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.0.6-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 47.4 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.0.5-py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 47.0 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.0.4-py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 48.3 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.0.3-py3-none-any.whl (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 55.4 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.0.2-py3-none-any.whl (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 55.2 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.0.1-py3-none-any.whl (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 49.4 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-7.0.0-py3-none-any.whl (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading jupyter_client-6.1.12-py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.2)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.9.1)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n",
            "Collecting json5\n",
            "  Downloading json5-0.9.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.7.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (4.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.21)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2018.9)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (4.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=1c7e7df73d7718d005e88eecf414d397cb93d458a3dee55e5e96160a4dfba7ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: tornado, sniffio, jupyter-client, websocket-client, anyio, jupyter-server, json5, nbclassic, jupyterlab-server, h11, uvicorn, pyngrok, nest-asyncio, jupyterlab, colabcode\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.4\n",
            "    Uninstalling nest-asyncio-1.5.4:\n",
            "      Successfully uninstalled nest-asyncio-1.5.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n",
            "Successfully installed anyio-3.5.0 colabcode-0.3.0 h11-0.13.0 json5-0.9.6 jupyter-client-6.1.12 jupyter-server-1.13.5 jupyterlab-3.0.7 jupyterlab-server-2.10.3 nbclassic-0.3.5 nest-asyncio-1.4.3 pyngrok-5.1.0 sniffio-1.2.0 tornado-6.1 uvicorn-0.13.1 websocket-client-1.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jupyter_client",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "hBICnkAWo3i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/kaustubhgupta/Technocolab-Final-Project/master/Data/cleaned.csv\",  index_col=None)\n"
      ],
      "metadata": {
        "id": "FpFO2z-ToiWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jKN6N5Fnos6q",
        "outputId": "7ffdad24-e1ae-4037-f60b-582189477428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-96866643-f39c-4368-8e2f-70d3a0c6cebb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>track_id</th>\n",
              "      <th>genre_top</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>153</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.988306</td>\n",
              "      <td>0.255661</td>\n",
              "      <td>0.979774</td>\n",
              "      <td>0.973006</td>\n",
              "      <td>0.121342</td>\n",
              "      <td>0.051740</td>\n",
              "      <td>90.241</td>\n",
              "      <td>0.034018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.970135</td>\n",
              "      <td>0.352946</td>\n",
              "      <td>0.023852</td>\n",
              "      <td>0.957113</td>\n",
              "      <td>0.113261</td>\n",
              "      <td>0.032177</td>\n",
              "      <td>53.758</td>\n",
              "      <td>0.035632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.981657</td>\n",
              "      <td>0.142249</td>\n",
              "      <td>0.912122</td>\n",
              "      <td>0.967294</td>\n",
              "      <td>0.363510</td>\n",
              "      <td>0.087527</td>\n",
              "      <td>91.912</td>\n",
              "      <td>0.034325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>169</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.989141</td>\n",
              "      <td>0.225978</td>\n",
              "      <td>0.722835</td>\n",
              "      <td>0.263076</td>\n",
              "      <td>0.092371</td>\n",
              "      <td>0.053406</td>\n",
              "      <td>94.322</td>\n",
              "      <td>0.028347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>170</td>\n",
              "      <td>Rock</td>\n",
              "      <td>0.886660</td>\n",
              "      <td>0.298518</td>\n",
              "      <td>0.744333</td>\n",
              "      <td>0.920950</td>\n",
              "      <td>0.139587</td>\n",
              "      <td>0.088781</td>\n",
              "      <td>97.880</td>\n",
              "      <td>0.073548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96866643-f39c-4368-8e2f-70d3a0c6cebb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96866643-f39c-4368-8e2f-70d3a0c6cebb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96866643-f39c-4368-8e2f-70d3a0c6cebb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   track_id genre_top  acousticness  ...  speechiness   tempo   valence\n",
              "0       153      Rock      0.988306  ...     0.051740  90.241  0.034018\n",
              "1       154      Rock      0.970135  ...     0.032177  53.758  0.035632\n",
              "2       155      Rock      0.981657  ...     0.087527  91.912  0.034325\n",
              "3       169      Rock      0.989141  ...     0.053406  94.322  0.028347\n",
              "4       170      Rock      0.886660  ...     0.088781  97.880  0.073548\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['track_id', 'genre_top'], axis=1)\n",
        "y = df.genre_top"
      ],
      "metadata": {
        "id": "aRotKzSVozWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "Pkl_Filename = \"model_tree.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(tree, file)"
      ],
      "metadata": {
        "id": "PXwu61BkovbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOXNBnJrpIm0",
        "outputId": "5c4f059e-8495-4992-921c-805b50b26811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 10.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic) (3.10.0.2)\n",
            "Installing collected packages: pydantic\n",
            "Successfully installed pydantic-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Music(BaseModel):\n",
        "    acousticness: float \n",
        "    danceability: float \n",
        "    energy: float \n",
        "    instrumentalness: float \n",
        "    liveness: float \n",
        "    speechiness: float \n",
        "    tempo: float \n",
        "    valence: float\n",
        "    class Config:\n",
        "        schema_extra = {\n",
        "            \"example\": {\n",
        "                \"acousticness\": 0.838816, \n",
        "                \"danceability\": 0.542950, \n",
        "                \"energy\": 0.669215,\n",
        "                \"instrumentalness\": 0.000006,\n",
        "                \"liveness\": 0.105610,\n",
        "                \"speechiness\": 0.391221,\n",
        "                \"tempo\": 111.894,\n",
        "                \"valence\": 0.796073\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "JSlJpd8iow90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOpfM-kJpWTc",
        "outputId": "54702fde-eda3-443a-ae25-fff30d29d772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.74.0-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting starlette==0.17.1\n",
            "  Downloading starlette-0.17.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from starlette==0.17.1->fastapi) (3.10.0.2)\n",
            "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.17.1->fastapi) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.17.1->fastapi) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.17.1->fastapi) (1.2.0)\n",
            "Installing collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.74.0 starlette-0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import pickle\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"model_tree.pkl\", \"rb\"))\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "    return {'message': 'This is the homepage of the API '}\n",
        "\n",
        "\n",
        "@app.post('/predict')\n",
        "def get_music_category(data: Music):\n",
        "    received = data.dict()\n",
        "    acousticness = received['acousticness']\n",
        "    danceability = received['danceability']\n",
        "    energy = received['energy']\n",
        "    instrumentalness = received['instrumentalness']\n",
        "    liveness = received['liveness']\n",
        "    speechiness = received['speechiness']\n",
        "    tempo = received['tempo']\n",
        "    valence = received['valence']\n",
        "    pred_name = model.predict([[acousticness, danceability, energy,\n",
        "                                instrumentalness, liveness, speechiness, tempo, valence]]).tolist()[0]\n",
        "    return {'prediction': pred_name}"
      ],
      "metadata": {
        "id": "Ondqye4NpDHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "metadata": {
        "id": "bk429nl0pRfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "server.run_app(app=app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx9c1lf6pgUm",
        "outputId": "5ae38ed4-5d0d-426f-9927-1c740065c15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://6144-34-78-32-109.ngrok.io\" -> \"http://localhost:10000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [83]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:10000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     79.134.0.132:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     185.122.28.66:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     185.122.28.66:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     185.122.28.66:0 - \"GET /docs HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [83]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b0C_oA6Tph5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}