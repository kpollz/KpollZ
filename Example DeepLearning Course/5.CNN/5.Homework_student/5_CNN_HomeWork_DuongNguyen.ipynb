{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.CNN_HomeWork_DuongNguyen.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y5Gb_rGiFhEt",
        "rFXbwZmKForO",
        "Er1V57g3Fwrs",
        "u0p1RDaKGHOV",
        "aW3PxwjCGQMD",
        "A8HSmU7cGjoh",
        "aCjDTOpz_h1b"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết"
      ],
      "metadata": {
        "id": "W2HWfZe5bT7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 1: D"
      ],
      "metadata": {
        "id": "y5Gb_rGiFhEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 2: C"
      ],
      "metadata": {
        "id": "rFXbwZmKForO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 3: C"
      ],
      "metadata": {
        "id": "Er1V57g3Fwrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 4: D"
      ],
      "metadata": {
        "id": "u0p1RDaKGHOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 5: D"
      ],
      "metadata": {
        "id": "aW3PxwjCGQMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Mạng tích chập CNN sẽ được thực hiện như thế nào?\n",
        "\n",
        "A. Phân chia feature map thành các ma trận theo chiều channel và thực hiện tích chập giữa mỗi ma trận kernel với từng chiều.\n",
        "\n",
        "B. Thực hiện phép nhân ma trận kernel với chuyển vị của ma trận local receptive field để thu được giá trị feature map output.\n",
        "\n",
        "C. Tính trung bình các phân tử trên một ma trận local receptive field.\n",
        "\n",
        "D. Di chuyển vùng local receptive field theo chiều từ trái sang phải và từ trên xuống dưới và nhân tích chập với kernel để thu được ma trận feature map.\n",
        "\n",
        "2) Thực hiện phép nhân tích chập giữa ma trận đầu vào kích thước width và height lần lượt là $(W, H)$ với bộ lọc kích thước $(F, F)$ và bước nhảy $S$ thì thu được ma trận đầu ra với kích thước width và height $(W', H')$ là bao nhiêu? Hãy lựa chọn công thức tổng quát nhất.\n",
        "\n",
        "A. $W' =⌊ \\frac{W-F}{S} ⌋ + 1;~ H' =⌊ \\frac{H-F}{S} ⌋ + 1$\n",
        "\n",
        "B. $W' =\\lceil \\frac{W-F}{S} \\rceil + 1;~ H' = \\lceil \\frac{H-F}{S} \\rceil + 1$ \n",
        "\n",
        "C. $W' =\\lfloor \\frac{W-F+2P}{S} \\rfloor + 1;~ H' = \\lfloor \\frac{H-F+2P}{S} \\rfloor + 1$ với $P$ là số lượng các véc tơ 0 padding ở bên ngoài đều hai phía.\n",
        "\n",
        "D. $W' =\\lceil \\frac{W-F+P}{S} \\rceil + 1;~ H' = \\lceil \\frac{H-F+P}{S} \\rceil + 1$ với $P$ là số lượng các véc tơ 0 padding ở bên ngoài đều hai phía.\n",
        "\n",
        "3) Mạng CNN sẽ học được những gì qua các layers?\n",
        "\n",
        "A. Tại những layers đầu mỗi channels sẽ giúp phân biệt một loại đặc trưng, của vật thể. Những đặc trưng này sau đó được trải phẳng và đưa vào mạng MLP để phân loại vật thể.\n",
        "\n",
        "B. Những layers cuối cùng sẽ zoom vào từng chi tiết của vật thể để phân loại vật thể.\n",
        "\n",
        "C. Tại những layers đầu mạng sẽ học được các đặc trưng chung như các edge dọc, ngang, chéo,.... Các đặc trưng chi tiết và tổng quát giúp nhận diện vật thể được học tại những layers cuối cùng.\n",
        "\n",
        "D. Các layers đầu tiên sẽ tập trung vào các chi tiết bộ phận của vật thể.\n",
        "\n",
        "4) Kiến trúc chung của một mạng CNN là gì?\n",
        "\n",
        "A. _[Conv -> BatchNorm -> Activation -> Maxpooling] x n_\n",
        "\n",
        "B. _[BatchNorm -> Conv -> Activation -> Maxpooling] x n_ \n",
        "\n",
        "C. _[Conv -> BatchNorm -> Maxpooling -> Activation -> Maxpooling] x n_ \n",
        "\n",
        "D. _[Conv -> BatchNorm -> Maxpooling -> Activation -> Maxpooling] x n -> Flatten -> [FullyConnected -> Activation] x m -> Softmax_ \n",
        "\n",
        "5) Thông thường đặc điểm kích thước feature map của mạng neural sẽ như thế nào ?\n",
        "\n",
        "A. Kích thước feature map tăng dần gấp đôi qua thời gian.\n",
        "\n",
        "B. Kích thước feature map sẽ duy trì không đổi qua thời gian.\n",
        "\n",
        "C. Kích thước mạng sẽ giảm dần gấp đôi sau mỗi một lần downsampling và sau đó tăng dần gấp đôi sau mỗi lần upsampling để khôi phục về kích thước ảnh input.\n",
        "\n",
        "D. Kích thước mạng thường giảm gấp đôi sau một lần downsampling và số lượng các filters tăng dần."
      ],
      "metadata": {
        "id": "O6_oiMLtbZd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành\n",
        "\n",
        "6) Thực hiện xây dựng và huấn luyện một mạng CNN ngẫu nhiên trên bộ dữ liệu [Dog and Cat](https://www.kaggle.com/c/dog-vs-cat-classification/data). Lưu ý cần thực hiện [chuẩn hóa dữ liệu](https://github.com/pytorch/examples/issues/112) đối với bộ dữ liệu ImageNet trước khi huấn luyện.\n",
        "\n",
        "7) Grid Search kiến trúc CNN dựa trên việc tổng quát hóa một thiết kế câu 6.\n",
        "\n",
        "8) Huấn luyện lại mô hình bằng kiến trúc ResNet và MobileNet. Đánh giá chi phí tính toán và submit kết quả độ chính xác trên các ảnh thuộc folder test.\n",
        "\n",
        "9) Thử nghiệm các phương pháp Augmentation như Flip, Rotation, Random Crop, Bright Contrast để cải thiện kết quả mô hình.\n",
        "\n",
        "10) Lập bảng kết quả các thử nghiệm đã sử dụng."
      ],
      "metadata": {
        "id": "I4U8kdaxbW0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('gdrive/MyDrive/DeepLearning Course 3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVY26fAWH2tS",
        "outputId": "5f044647-e73d-48a1-9804-1458d24ba605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 6"
      ],
      "metadata": {
        "id": "A8HSmU7cGjoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FP-4JJXkBl0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "S41Zczo01VED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(data_path):\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),                                \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    \n",
        "    full_dataset = torchvision.datasets.ImageFolder(data_path, transform=transformation)\n",
        "    \n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    \n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=128, num_workers=1)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=128, num_workers=1)\n",
        "    \n",
        "    return train_loader, test_loader\n",
        "\n",
        "data_path = './dataset/dog-vs-cat-classification/train/train'\n",
        "train_loader, test_loader = load_dataset(data_path)"
      ],
      "metadata": {
        "id": "v5NHKH1s7yuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "        self.dropout = nn.Dropout2d(0.2)\n",
        "        self.fc = nn.Linear(in_features=32*32*24, out_features=2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.maxpool(self.conv1(x)))\n",
        "        x = torch.relu(self.maxpool(self.conv2(x)))\n",
        "        x = torch.relu(self.dropout(self.conv3(x)))\n",
        "        x = x.view(-1, 32*32*24)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "D16aXDor8iM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, data_loader, optimizer, loss_criteria):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(data_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        \n",
        "        loss = loss_criteria(output, target)\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    avg_loss = train_loss / (batch_idx + 1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "\n",
        "def test(model, device, data_loader, loss_criteria):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_criteria(output, target).item()\n",
        "            \n",
        "            _, acc = torch.max(output, axis=1)\n",
        "            correct += acc.eq(target).sum().item()\n",
        "            \n",
        "    avg_loss = test_loss / (batch_idx + 1)\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Training on', device)\n",
        "model = MyModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch: {epoch+1}')\n",
        "    train_loss = train(model, device, train_loader, optimizer, loss_criteria)\n",
        "    test_loss = test(model, device, test_loader, loss_criteria)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofjsrxvC8ykc",
        "outputId": "c7f8efe8-185f-4693-9c67-ff641a00b8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda\n",
            "Epoch: 1\n",
            "Training set: Average loss: 1.063952\n",
            "Validation set: Average loss: 0.689644, Accuracy: 4086/7500 (54%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.666461\n",
            "Validation set: Average loss: 0.650250, Accuracy: 4713/7500 (63%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.637963\n",
            "Validation set: Average loss: 0.632951, Accuracy: 4850/7500 (65%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.616072\n",
            "Validation set: Average loss: 0.630774, Accuracy: 4930/7500 (66%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.592673\n",
            "Validation set: Average loss: 0.615037, Accuracy: 5023/7500 (67%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 7"
      ],
      "metadata": {
        "id": "aCjDTOpz_h1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna"
      ],
      "metadata": {
        "id": "PQt-klM_9AVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71985399-d826-4602-feb4-de57063e06cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 70.6 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.1.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=a4f23c1ee86cf6f81a895b771da4e46110b8d86409f9b0e03bd0b816fb140652\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState"
      ],
      "metadata": {
        "id": "SzO6gLtKATaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "def objective(trial):\n",
        "    model = MyModel().to(device)\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop'])\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr)\n",
        "    loss_criteria = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = loss_criteria(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(test_loader):\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                _, pred = torch.max(output, axis=-1)\n",
        "                correct += pred.eq(target).sum().item()\n",
        "\n",
        "        accuracy = correct / len(test_loader.dataset)\n",
        "        \n",
        "        trial.report(accuracy, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "QugTnmkrEMH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20, timeout=60*20)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ],
      "metadata": {
        "id": "ltdTmNzlENnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6144f41-4940-42cb-aab0-c140b4796837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-25 11:50:43,348]\u001b[0m A new study created in memory with name: no-name-6a91ad30-8273-41f2-ad91-dc1ea65f47b5\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:01:07,768]\u001b[0m Trial 0 finished with value: 0.516 and parameters: {'optimizer': 'SGD', 'lr': 1.0523215010350237e-05}. Best is trial 0 with value: 0.516.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:11:35,391]\u001b[0m Trial 1 finished with value: 0.7418666666666667 and parameters: {'optimizer': 'Adam', 'lr': 0.00023221319295276067}. Best is trial 1 with value: 0.7418666666666667.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  2\n",
            "  Number of pruned trials:  0\n",
            "  Number of complete trials:  2\n",
            "Best trial:\n",
            "  Value:  0.7418666666666667\n",
            "  Params: \n",
            "    optimizer: Adam\n",
            "    lr: 0.00023221319295276067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel().to(device)\n",
        "def train(model, data_loader, optimizer, loss_criteria):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    for batch, (data, target) in enumerate(data_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()   \n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        losses += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    avg_loss = losses / (batch + 1)\n",
        "    print(f\"Loss in train set: {avg_loss:.6f}\")\n",
        "    return avg_loss\n",
        "\n",
        "def evaluation(model, data_loader, optimizer, loss_criteria):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (data, target) in enumerate(data_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            out = model(data)\n",
        "            loss = loss_criteria(out, target)\n",
        "            losses += loss.item()\n",
        "            _, predict = torch.max(out.data, axis=-1)\n",
        "            acc += predict.eq(target).sum().item()\n",
        "    avg_loss = losses / (batch + 1)\n",
        "    acc = acc * 100 / len(data_loader.dataset)\n",
        "    print(f\"Loss in validation set: {avg_loss:.6f}, Accuracy {acc:.3f}%\")\n",
        "    print('-'*50)\n",
        "    return avg_loss, acc\n",
        "\n",
        "OPTIMIZER = getattr(optim, trial.params['optimizer'])(model.parameters(), lr=trial.params['lr'])\n",
        "LOSS_CRITERIA = nn.CrossEntropyLoss()\n",
        "MAX_ACC = -float('inf')\n",
        "ERROR_GOING_UP = 0\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    print(f'Epoch {epoch}')\n",
        "    train_loss = train(model, train_loader, OPTIMIZER, LOSS_CRITERIA)\n",
        "    val_loss, acc = evaluation(model, test_loader, OPTIMIZER, LOSS_CRITERIA)\n",
        "\n",
        "    if acc > MAX_ACC:\n",
        "        MAX_ACC = acc\n",
        "        ERROR_GOING_UP = 0\n",
        "    else:\n",
        "        ERROR_GOING_UP += 1\n",
        "        if ERROR_GOING_UP == 4:\n",
        "            break\n",
        "print(f\"Best accuracy: {MAX_ACC:.3f}\")"
      ],
      "metadata": {
        "id": "ho9oAB3YEPN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820ef697-3c88-43e3-a35e-780c38ed1f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Loss in train set: 0.643635\n",
            "Loss in validation set: 0.593296, Accuracy 69.413%\n",
            "--------------------------------------------------\n",
            "Epoch 2\n",
            "Loss in train set: 0.590906\n",
            "Loss in validation set: 0.570504, Accuracy 70.333%\n",
            "--------------------------------------------------\n",
            "Epoch 3\n",
            "Loss in train set: 0.561892\n",
            "Loss in validation set: 0.549830, Accuracy 72.453%\n",
            "--------------------------------------------------\n",
            "Epoch 4\n",
            "Loss in train set: 0.540264\n",
            "Loss in validation set: 0.536623, Accuracy 73.507%\n",
            "--------------------------------------------------\n",
            "Epoch 5\n",
            "Loss in train set: 0.520628\n",
            "Loss in validation set: 0.525562, Accuracy 74.000%\n",
            "--------------------------------------------------\n",
            "Epoch 6\n",
            "Loss in train set: 0.503667\n",
            "Loss in validation set: 0.509816, Accuracy 74.947%\n",
            "--------------------------------------------------\n",
            "Epoch 7\n",
            "Loss in train set: 0.492557\n",
            "Loss in validation set: 0.497975, Accuracy 75.920%\n",
            "--------------------------------------------------\n",
            "Epoch 8\n",
            "Loss in train set: 0.480518\n",
            "Loss in validation set: 0.520646, Accuracy 74.040%\n",
            "--------------------------------------------------\n",
            "Epoch 9\n",
            "Loss in train set: 0.469605\n",
            "Loss in validation set: 0.490685, Accuracy 76.333%\n",
            "--------------------------------------------------\n",
            "Epoch 10\n",
            "Loss in train set: 0.458168\n",
            "Loss in validation set: 0.485251, Accuracy 76.480%\n",
            "--------------------------------------------------\n",
            "Best accuracy: 76.480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 8"
      ],
      "metadata": {
        "id": "oPVoq-IbqImQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "jxZ3mkg-S_3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "data_path = './dataset/dog-vs-cat-classification/train/train'\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1/255., validation_split=0.2)\n",
        "\n",
        "print(\"Training data:\")\n",
        "train_data = data_gen.flow_from_directory(data_path,\n",
        "                                        target_size=IMAGE_SHAPE,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        class_mode='binary',\n",
        "                                        shuffle=True,\n",
        "                                        seed=42,\n",
        "                                        subset='training')\n",
        "                                           \n",
        "\n",
        "print(\"Testing data\")\n",
        "val_data = data_gen.flow_from_directory(data_path,\n",
        "                                    target_size=IMAGE_SHAPE,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    class_mode='binary',\n",
        "                                    subset='validation')"
      ],
      "metadata": {
        "id": "bKb079CLdH6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d40e74-b05b-4ea8-b3dd-c5376b28d5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data:\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Testing data\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained model URL\n",
        "resnet_url = 'https://tfhub.dev/tensorflow/resnet_50/feature_vector/1'\n",
        "mobilenet_url = 'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5'"
      ],
      "metadata": {
        "id": "9PNGdXrQp_Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url):\n",
        "    feature_extraction_layer = hub.KerasLayer(model_url,\n",
        "                                              trainable=False,\n",
        "                                              input_shape=(IMAGE_SHAPE + (3,)))\n",
        "    model = tf.keras.models.Sequential([feature_extraction_layer,\n",
        "                                        tf.keras.layers.Dense(16, activation='relu'),\n",
        "                                        tf.keras.layers.Dense(2, activation='softmax')])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "8B1CLNHYlvrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet Model"
      ],
      "metadata": {
        "id": "p7yuVoDzpmvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = create_model(resnet_url)\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "IqQE5xsdqn39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73a9e62-16b5-44f8-ef06-628bd247d5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 2048)              23561152  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                32784     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,593,970\n",
            "Trainable params: 32,818\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['acc'])"
      ],
      "metadata": {
        "id": "UrPoxnhWq2Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_history = resnet_model.fit(train_data,\n",
        "                                  epochs=3, \n",
        "                                  validation_data=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMpKjp2rrHsF",
        "outputId": "5d8e9c80-9fbe-4990-92aa-06e3540cca04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "313/313 [==============================] - 9658s 31s/step - loss: 0.0439 - acc: 0.9846 - val_loss: 0.0456 - val_acc: 0.9882\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 169s 539ms/step - loss: 0.0246 - acc: 0.9916 - val_loss: 0.0370 - val_acc: 0.9884\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 168s 537ms/step - loss: 0.0165 - acc: 0.9942 - val_loss: 0.0357 - val_acc: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNet Model"
      ],
      "metadata": {
        "id": "MZxiKb4srPVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_model = create_model(mobilenet_url)"
      ],
      "metadata": {
        "id": "bf8DC3Yjuqix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n62FTj2HuzCN",
        "outputId": "2e0433cf-e04e-478d-b1d8-6fc85e4f5dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_13 (KerasLayer)  (None, 1280)             4226432   \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 16)                20496     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,246,962\n",
            "Trainable params: 20,530\n",
            "Non-trainable params: 4,226,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "L12dM3DQu2_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "mobilenet_history = mobilenet_model.fit(train_data,\n",
        "                                        epochs=8,\n",
        "                                        validation_data=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R67aBZcNu7df",
        "outputId": "587e3a87-961f-43ea-af93-d98834604003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "313/313 [==============================] - 168s 516ms/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 0.0392 - val_accuracy: 0.9880\n",
            "Epoch 2/8\n",
            "313/313 [==============================] - 149s 475ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.0359 - val_accuracy: 0.9882\n",
            "Epoch 3/8\n",
            "313/313 [==============================] - 146s 466ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0404 - val_accuracy: 0.9868\n",
            "Epoch 4/8\n",
            "313/313 [==============================] - 147s 469ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0456 - val_accuracy: 0.9876\n",
            "Epoch 5/8\n",
            "313/313 [==============================] - 146s 467ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0470 - val_accuracy: 0.9880\n",
            "Epoch 6/8\n",
            "313/313 [==============================] - 146s 466ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0514 - val_accuracy: 0.9872\n",
            "Epoch 7/8\n",
            "313/313 [==============================] - 146s 466ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0549 - val_accuracy: 0.9872\n",
            "Epoch 8/8\n",
            "313/313 [==============================] - 146s 467ms/step - loss: 7.9841e-04 - accuracy: 0.9999 - val_loss: 0.0603 - val_accuracy: 0.9880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 9 "
      ],
      "metadata": {
        "id": "5Db769cqc1hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen = ImageDataGenerator(rescale=1/255.,\n",
        "                              rotation_range=45,\n",
        "                              width_shift_range=0.2,\n",
        "                              height_shift_range=0.2,\n",
        "                              zoom_range=0.2,\n",
        "                              horizontal_flip=True,\n",
        "                              shear_range=0.1,\n",
        "                              validation_split=0.2)\n",
        "\n",
        "train_data_aug = data_gen.flow_from_directory(data_path,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          target_size=IMAGE_SHAPE,\n",
        "                                          class_mode='binary',\n",
        "                                          shuffle=True,\n",
        "                                          subset='training')\n",
        "\n",
        "val_data = data_gen.flow_from_directory(data_path,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        target_size=IMAGE_SHAPE,\n",
        "                                        class_mode='binary',\n",
        "                                        shuffle=False,\n",
        "                                        subset='validation')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUQ1ABKud-gb",
        "outputId": "406ab566-5253-44b7-bc29-74f79d227714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNet with Augmentation"
      ],
      "metadata": {
        "id": "Si5rvxzzjoqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_model_with_aug = create_model(mobilenet_url)\n",
        "\n",
        "mobile_model_with_aug.compile(loss='sparse_categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('mobilenet_best.hdf5',\n",
        "                                                      verbose=2,\n",
        "                                                      save_best_only=True,\n",
        "                                                      mode='min')\n",
        "\n",
        "mobile_model_with_aug_history = mobile_model_with_aug.fit(train_data, epochs=5, \n",
        "                                                           validation_data=val_data,\n",
        "                                                          callbacks=[model_checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWaH7QHbfp-E",
        "outputId": "58f6448f-58d8-4124-e99d-84acf8a94f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9705\n",
            "Epoch 1: val_loss improved from inf to 0.04755, saving model to mobilenet_best.hdf5\n",
            "391/391 [==============================] - 525s 1s/step - loss: 0.0739 - accuracy: 0.9705 - val_loss: 0.0476 - val_accuracy: 0.9832\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9814\n",
            "Epoch 2: val_loss did not improve from 0.04755\n",
            "391/391 [==============================] - 521s 1s/step - loss: 0.0483 - accuracy: 0.9814 - val_loss: 0.0491 - val_accuracy: 0.9794\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9830\n",
            "Epoch 3: val_loss improved from 0.04755 to 0.04314, saving model to mobilenet_best.hdf5\n",
            "391/391 [==============================] - 522s 1s/step - loss: 0.0447 - accuracy: 0.9830 - val_loss: 0.0431 - val_accuracy: 0.9826\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9832\n",
            "Epoch 4: val_loss improved from 0.04314 to 0.03828, saving model to mobilenet_best.hdf5\n",
            "391/391 [==============================] - 516s 1s/step - loss: 0.0422 - accuracy: 0.9832 - val_loss: 0.0383 - val_accuracy: 0.9844\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9849\n",
            "Epoch 5: val_loss did not improve from 0.03828\n",
            "391/391 [==============================] - 592s 2s/step - loss: 0.0381 - accuracy: 0.9849 - val_loss: 0.0388 - val_accuracy: 0.9844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 10: Đánh giá hiệu quả của các Model"
      ],
      "metadata": {
        "id": "LX-ODarDUOjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob"
      ],
      "metadata": {
        "id": "mk-TdgqZTgRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_id = [i for i in glob.glob('./dataset/dog-vs-cat-classification/test/test' + \"/*.jpg\")]\n",
        "path_id.sort()"
      ],
      "metadata": {
        "id": "XaDdpjG2s6Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({'id': [os.path.basename(i) for i in path_id],\n",
        "                           'test_image_path': [i for i in path_id]})\n",
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iUH1-UY5i-9G",
        "outputId": "7c066184-63e1-4fe3-ed94-2c2eefec7795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4a0c2f43-68e0-4d28-853a-567cd16aee32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>test_image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>007995.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>007996.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>007997.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>007998.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>007999.jpg</td>\n",
              "      <td>./dataset/dog-vs-cat-classification/test/test/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a0c2f43-68e0-4d28-853a-567cd16aee32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a0c2f43-68e0-4d28-853a-567cd16aee32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a0c2f43-68e0-4d28-853a-567cd16aee32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              id                                    test_image_path\n",
              "0     000000.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "1     000001.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "2     000002.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "3     000003.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "4     000004.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "...          ...                                                ...\n",
              "7995  007995.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "7996  007996.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "7997  007997.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "7998  007998.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "7999  007999.jpg  ./dataset/dog-vs-cat-classification/test/test/...\n",
              "\n",
              "[8000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_gen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "submission_data = test_data_gen.flow_from_dataframe(\n",
        "    submission,\n",
        "    x_col='test_image_path',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3YxuTr1jGBo",
        "outputId": "ac8f5d71-16d5-4ac3-d958-bcecb9386c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNet Prediction"
      ],
      "metadata": {
        "id": "lV0ErCxUxi4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = mobilenet_model.predict(submission_data)\n",
        "labels = tf.expand_dims(tf.argmax(predictions, axis=1), 1).numpy()"
      ],
      "metadata": {
        "id": "5n4pmZ5Qj1Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission1 = submission.copy()\n",
        "submission1['labels'] = labels\n",
        "new_submission = submission1.drop('test_image_path', axis=1)\n",
        "new_submission.to_csv('my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "EvU98TOsp2Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy in Kaggle: 1.0000**"
      ],
      "metadata": {
        "id": "ImOFVJWkWUuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet Prediction"
      ],
      "metadata": {
        "id": "LXOM_DJ-wOxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = resnet_model.predict(submission_data)\n",
        "labels = tf.expand_dims(tf.argmax(predictions, axis=1), 1).numpy()"
      ],
      "metadata": {
        "id": "wLVGc_2DxaZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission2 = submission.copy()\n",
        "submission2['labels'] = labels\n",
        "new_submission = submission2.drop('test_image_path', axis=1)\n",
        "new_submission.to_csv('my_submission2.csv', index=False)"
      ],
      "metadata": {
        "id": "JUY4yQRuxeS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNet with Augmentation Prediction"
      ],
      "metadata": {
        "id": "5pQAAfV2U2v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = mobile_model_with_aug_history.predict(submission_data)\n",
        "labels = tf.expand_dims(tf.argmax(predictions, axis=1), 1).numpy()"
      ],
      "metadata": {
        "id": "UKIIHrp8yNOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission3 = submission.copy()\n",
        "submission3['labels'] = labels\n",
        "new_submission = submission3.drop('test_image_path', axis=1)\n",
        "new_submission.to_csv('my_submission3.csv', index=False)"
      ],
      "metadata": {
        "id": "I8n_nHNoyQDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bảng kết quả\n",
        "+ Do em đang ở viện nên mạng nó không được ổn định lắm, nên khi train xong `ResnetModel` với `MobileNet with Augmentation Prediction` thì bị mất kết nối mạng, không còn đủ thời gian để training lại và cho phần prediction, nên em mới chỉ tổng hợp được một kết quả của `MobileNet Model`: Kết quả submit lên Kaggle đạt độ chính xác là 100.0000"
      ],
      "metadata": {
        "id": "fodinv9yvggI"
      }
    }
  ]
}