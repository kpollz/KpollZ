{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.PytorchHomeWork_NguyễnDuyĐạt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Lý thuyết\n",
        "\n",
        "**1) Để khởi tạo model trong pytorch chúng ta sử dụng class nào?**\n",
        "\n",
        "A. nn.Module\n",
        "\n",
        "B. nn.Dense\n",
        "\n",
        "C. nn.optim.Adam\n",
        "\n",
        "D. nn.Dropout\n",
        "\n",
        "**2) Để khởi tạo mạng neural network trong pytorch chúng ta cần làm gì ?**\n",
        "\n",
        "A. Kế thừa lại class `nn.Model`. Khởi tạo các layers trong hàm tạo `__init__()` và sử dụng các layers để tính toán dữ liệu trong hàm `forward()`.\n",
        "\n",
        "B. Khởi tạo một object của class `nn.Model` và sử dụng hàm `add()` để thêm từng layer vào mô hình.\n",
        "\n",
        "C. Sử dụng class `nn.Model` để khởi tạo mô hình. Truyền vào bên trong class này một list gồm các layers.\n",
        "\n",
        "D. Kế thừa lại class `nn.Module`. Khởi tạo các layers trong hàm tạo `__init__()` và sử dụng các layers để tính toán dữ liệu trong hàm `forward()`.\n",
        "\n",
        "\n",
        "**3) Các modules chính trong pytorch dùng để xây dựng và huấn luyện model.**\n",
        "\n",
        "A. `torch.nn`: Dùng để khởi tạo các layers và activations function và loss function, `torch.optim`: Khởi tạo optimizer, `torch.data`: Khởi tạo dataset và dataloader.\n",
        "\n",
        "B. `torch.nn`: Dùng để khởi tạo các layers và activations function và loss function, `torch.optim`: Khởi tạo optimizer, `torch.utils.data`: Khởi tạo dataset và dataloader.\n",
        "\n",
        "C. `torch.nn`: Dùng để khởi tạo các layers và activations function, `torch.optim`: Khởi tạo optimizer, `torch.data`: Khởi tạo dataset và dataloader, `torch.loss`: Khởi tạo loss function.\n",
        "\n",
        "D. `torch.nn`: Dùng để khởi tạo các layers và loss function, `torch.optim`: Khởi tạo optimizer, `torch.data`: Khởi tạo dataset và dataloader, `torch.activations`: Khởi tạo activations function.\n",
        "\n",
        "\n",
        "**4) Để customize một Dataset trên pytorch chúng ta cần thực hiện như thế nào?**\n",
        "\n",
        "A. Sử dụng thuộc tính `transformer` để qui định các biến đổi trên dữ liệu. Những biến đổi này được thực hiện trên hàm tạo.\n",
        "\n",
        "B. Khởi tạo một class kế thừa lại `torch.utils.data.Dataset`. Khai báo các thuộc tính cần sử dụng trong hàm tạo của dataset như list đường dẫn, list label. Override lại hàm `__getitem__()` để thực hiện các xử lý trên dữ liệu.\n",
        "\n",
        "C. Kế thừa lại một class `Dataset`. Các điều chỉnh trên dữ liệu được thực hiện trên hàm `transformer()`.\n",
        "\n",
        "D. Sử dụng hàm `__getitem__()` để trả về toàn bộ các quan sát khi huấn luyện. \n",
        "\n",
        "**5) Ý nghĩa của tham số epochs và batch_size trong huấn luyện mô hình là gì?**\n",
        "\n",
        "A. epochs là kích thước của một mini-batch, batch_size là số lượt lặp lại toàn bộ dữ liệu khi huấn luyện.\n",
        "\n",
        "B. epochs là số lượt lặp lại toàn bộ dữ liệu validation khi huấn luyện, batch_size là kích thước của một mini-batch.\n",
        "\n",
        "C. epochs là số lượt lặp lại toàn bộ dữ liệu train khi huấn luyện, batch_size là kích thước của một mini-batch.\n",
        "\n",
        "D. epochs là số lượng vòng lặp, mỗi vòng lặp là một lượt fit mini-batch, trên bộ dữ liệu khi huấn luyện; batch_size là kích thước của một mini-batch."
      ],
      "metadata": {
        "id": "DUXbtwUsAGPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1A - 2D - 3B - 4B - 5C"
      ],
      "metadata": {
        "id": "LK9GfgJxDMxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Thực hành\n",
        "\n",
        "6) Khởi tạo một tensor 3 chiều với định dạng là float và kích thước là 32x32x3\n",
        "\n",
        "7) Nếu coi tensor trên là một bức ảnh RGB với số channel là 3 ở cuối. Hãy truy suất các ma trận ảnh tương ứng với mỗi kênh R, G, B.\n",
        "\n",
        "8) Thực hiện tích hadamard và tích thông thường giữa ma trận R và G.\n",
        "\n",
        "9) Từ bộ dữ liệu [Income-Classification](https://www.kaggle.com/t/090688c8d33a40b68be9e271d6ba6bae) hãy chuẩn hóa dữ liệu và phân chia tập train/test theo tỷ lệ 80/20. \n",
        "\n",
        "10) Xây dựng một mạng deep-neural-network để huấn luyện mô hình trên dữ liệu train và đánh giá mô hình trên dữ liệu test.\n"
      ],
      "metadata": {
        "id": "LzLjMsckAJAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Câu 6: Khởi tạo một tensor 3 chiều với định dạng là float và kích thước là 32x32x3."
      ],
      "metadata": {
        "id": "su06B7E07Rqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t = torch.rand([32, 32, 3], dtype=torch.float64)\n",
        "t"
      ],
      "metadata": {
        "id": "eEGvmgYc2Qs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15d3e31-40f1-47ed-abfa-89e0200c1f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7356, 0.1506, 0.1160],\n",
              "         [0.9201, 0.8104, 0.5750],\n",
              "         [0.4161, 0.3757, 0.8112],\n",
              "         ...,\n",
              "         [0.2289, 0.0611, 0.5017],\n",
              "         [0.1186, 0.5409, 0.7911],\n",
              "         [0.3943, 0.7366, 0.7774]],\n",
              "\n",
              "        [[0.1001, 0.3132, 0.2413],\n",
              "         [0.8061, 0.6112, 0.8709],\n",
              "         [0.1178, 0.6125, 0.7466],\n",
              "         ...,\n",
              "         [0.6328, 0.6377, 0.8382],\n",
              "         [0.7325, 0.3201, 0.5033],\n",
              "         [0.0262, 0.0819, 0.6650]],\n",
              "\n",
              "        [[0.9031, 0.5638, 0.2074],\n",
              "         [0.6307, 0.2115, 0.2337],\n",
              "         [0.5625, 0.6955, 0.8222],\n",
              "         ...,\n",
              "         [0.9484, 0.8707, 0.8217],\n",
              "         [0.3001, 0.4326, 0.2442],\n",
              "         [0.4432, 0.8909, 0.0492]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.4390, 0.5637, 0.5212],\n",
              "         [0.9711, 0.3240, 0.8437],\n",
              "         [0.8682, 0.2408, 0.1367],\n",
              "         ...,\n",
              "         [0.4063, 0.2953, 0.9677],\n",
              "         [0.9370, 0.2820, 0.4670],\n",
              "         [0.3505, 0.4730, 0.2607]],\n",
              "\n",
              "        [[0.7712, 0.9265, 0.3977],\n",
              "         [0.8366, 0.5054, 0.3541],\n",
              "         [0.2399, 0.5775, 0.8100],\n",
              "         ...,\n",
              "         [0.1683, 0.6897, 0.8915],\n",
              "         [0.7120, 0.4951, 0.8530],\n",
              "         [0.1802, 0.7802, 0.3572]],\n",
              "\n",
              "        [[0.1517, 0.6864, 0.7412],\n",
              "         [0.5950, 0.4361, 0.5753],\n",
              "         [0.4984, 0.5777, 0.8630],\n",
              "         ...,\n",
              "         [0.1531, 0.0506, 0.4373],\n",
              "         [0.1966, 0.6408, 0.9286],\n",
              "         [0.3516, 0.9413, 0.6691]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Câu 7: Nếu coi tensor trên là một bức ảnh RGB với số channel là 3 ở cuối. Hãy truy suất các ma trận ảnh tương ứng với mỗi kênh R, G, B."
      ],
      "metadata": {
        "id": "OjJyHgKKBpVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"red_matrix\")\n",
        "R = t[:, : ,:1]\n",
        "print(R)\n",
        "print(\"------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"green_matrix\")\n",
        "G = t[:, : ,1:2]\n",
        "print(G)\n",
        "print(\"------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"blue_matrix\")\n",
        "B = t[:, : ,2:3]\n",
        "print(B)\n",
        "print(\"------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYubhQqeBu-V",
        "outputId": "9f18bbb9-0091-44af-92eb-075b05bf4b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "red_matrix\n",
            "tensor([[[0.7356],\n",
            "         [0.9201],\n",
            "         [0.4161],\n",
            "         ...,\n",
            "         [0.2289],\n",
            "         [0.1186],\n",
            "         [0.3943]],\n",
            "\n",
            "        [[0.1001],\n",
            "         [0.8061],\n",
            "         [0.1178],\n",
            "         ...,\n",
            "         [0.6328],\n",
            "         [0.7325],\n",
            "         [0.0262]],\n",
            "\n",
            "        [[0.9031],\n",
            "         [0.6307],\n",
            "         [0.5625],\n",
            "         ...,\n",
            "         [0.9484],\n",
            "         [0.3001],\n",
            "         [0.4432]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.4390],\n",
            "         [0.9711],\n",
            "         [0.8682],\n",
            "         ...,\n",
            "         [0.4063],\n",
            "         [0.9370],\n",
            "         [0.3505]],\n",
            "\n",
            "        [[0.7712],\n",
            "         [0.8366],\n",
            "         [0.2399],\n",
            "         ...,\n",
            "         [0.1683],\n",
            "         [0.7120],\n",
            "         [0.1802]],\n",
            "\n",
            "        [[0.1517],\n",
            "         [0.5950],\n",
            "         [0.4984],\n",
            "         ...,\n",
            "         [0.1531],\n",
            "         [0.1966],\n",
            "         [0.3516]]], dtype=torch.float64)\n",
            "------------------------------------------------------------------------------------------------\n",
            "green_matrix\n",
            "tensor([[[0.1506],\n",
            "         [0.8104],\n",
            "         [0.3757],\n",
            "         ...,\n",
            "         [0.0611],\n",
            "         [0.5409],\n",
            "         [0.7366]],\n",
            "\n",
            "        [[0.3132],\n",
            "         [0.6112],\n",
            "         [0.6125],\n",
            "         ...,\n",
            "         [0.6377],\n",
            "         [0.3201],\n",
            "         [0.0819]],\n",
            "\n",
            "        [[0.5638],\n",
            "         [0.2115],\n",
            "         [0.6955],\n",
            "         ...,\n",
            "         [0.8707],\n",
            "         [0.4326],\n",
            "         [0.8909]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5637],\n",
            "         [0.3240],\n",
            "         [0.2408],\n",
            "         ...,\n",
            "         [0.2953],\n",
            "         [0.2820],\n",
            "         [0.4730]],\n",
            "\n",
            "        [[0.9265],\n",
            "         [0.5054],\n",
            "         [0.5775],\n",
            "         ...,\n",
            "         [0.6897],\n",
            "         [0.4951],\n",
            "         [0.7802]],\n",
            "\n",
            "        [[0.6864],\n",
            "         [0.4361],\n",
            "         [0.5777],\n",
            "         ...,\n",
            "         [0.0506],\n",
            "         [0.6408],\n",
            "         [0.9413]]], dtype=torch.float64)\n",
            "------------------------------------------------------------------------------------------------\n",
            "blue_matrix\n",
            "tensor([[[0.1160],\n",
            "         [0.5750],\n",
            "         [0.8112],\n",
            "         ...,\n",
            "         [0.5017],\n",
            "         [0.7911],\n",
            "         [0.7774]],\n",
            "\n",
            "        [[0.2413],\n",
            "         [0.8709],\n",
            "         [0.7466],\n",
            "         ...,\n",
            "         [0.8382],\n",
            "         [0.5033],\n",
            "         [0.6650]],\n",
            "\n",
            "        [[0.2074],\n",
            "         [0.2337],\n",
            "         [0.8222],\n",
            "         ...,\n",
            "         [0.8217],\n",
            "         [0.2442],\n",
            "         [0.0492]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.5212],\n",
            "         [0.8437],\n",
            "         [0.1367],\n",
            "         ...,\n",
            "         [0.9677],\n",
            "         [0.4670],\n",
            "         [0.2607]],\n",
            "\n",
            "        [[0.3977],\n",
            "         [0.3541],\n",
            "         [0.8100],\n",
            "         ...,\n",
            "         [0.8915],\n",
            "         [0.8530],\n",
            "         [0.3572]],\n",
            "\n",
            "        [[0.7412],\n",
            "         [0.5753],\n",
            "         [0.8630],\n",
            "         ...,\n",
            "         [0.4373],\n",
            "         [0.9286],\n",
            "         [0.6691]]], dtype=torch.float64)\n",
            "------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Câu 8: Thực hiện tích hadamard và tích thông thường giữa ma trận R và G."
      ],
      "metadata": {
        "id": "l_j7o5ATCKhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_Hadamard_product\")\n",
        "print(R*G)\n",
        "print(\"------------------------------------------------------------------------------------------------\")\n",
        "print(\"_Inner_product\")\n",
        "(R.T)@G"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNsCkS9aCKLL",
        "outputId": "89d8e900-04a6-42bc-cbb2-c140e5e80ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_Hadamard_product\n",
            "tensor([[[0.1108],\n",
            "         [0.7456],\n",
            "         [0.1563],\n",
            "         ...,\n",
            "         [0.0140],\n",
            "         [0.0642],\n",
            "         [0.2904]],\n",
            "\n",
            "        [[0.0313],\n",
            "         [0.4927],\n",
            "         [0.0721],\n",
            "         ...,\n",
            "         [0.4035],\n",
            "         [0.2345],\n",
            "         [0.0021]],\n",
            "\n",
            "        [[0.5092],\n",
            "         [0.1334],\n",
            "         [0.3912],\n",
            "         ...,\n",
            "         [0.8258],\n",
            "         [0.1298],\n",
            "         [0.3949]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.2474],\n",
            "         [0.3146],\n",
            "         [0.2090],\n",
            "         ...,\n",
            "         [0.1200],\n",
            "         [0.2643],\n",
            "         [0.1658]],\n",
            "\n",
            "        [[0.7145],\n",
            "         [0.4228],\n",
            "         [0.1386],\n",
            "         ...,\n",
            "         [0.1160],\n",
            "         [0.3525],\n",
            "         [0.1406]],\n",
            "\n",
            "        [[0.1042],\n",
            "         [0.2595],\n",
            "         [0.2880],\n",
            "         ...,\n",
            "         [0.0078],\n",
            "         [0.1260],\n",
            "         [0.3310]]], dtype=torch.float64)\n",
            "------------------------------------------------------------------------------------------------\n",
            "_Inner_product\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 8.4818],\n",
              "         [ 9.2602],\n",
              "         [ 6.9343],\n",
              "         ...,\n",
              "         [ 6.7589],\n",
              "         [ 8.2867],\n",
              "         [ 6.8109]],\n",
              "\n",
              "        [[ 9.3232],\n",
              "         [11.3142],\n",
              "         [ 7.4948],\n",
              "         ...,\n",
              "         [ 7.6736],\n",
              "         [ 9.4740],\n",
              "         [ 7.4326]],\n",
              "\n",
              "        [[10.2254],\n",
              "         [11.5192],\n",
              "         [ 8.7425],\n",
              "         ...,\n",
              "         [ 9.0165],\n",
              "         [ 9.1567],\n",
              "         [ 7.4183]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 8.0810],\n",
              "         [ 8.4757],\n",
              "         [ 6.4269],\n",
              "         ...,\n",
              "         [ 6.8121],\n",
              "         [ 6.8788],\n",
              "         [ 6.4226]],\n",
              "\n",
              "        [[ 8.7568],\n",
              "         [11.5597],\n",
              "         [ 8.2880],\n",
              "         ...,\n",
              "         [ 7.2642],\n",
              "         [ 8.6578],\n",
              "         [ 7.1275]],\n",
              "\n",
              "        [[ 9.0581],\n",
              "         [ 9.3933],\n",
              "         [ 6.8673],\n",
              "         ...,\n",
              "         [ 6.9225],\n",
              "         [ 7.5894],\n",
              "         [ 7.0134]]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Câu 9: Từ bộ dữ liệu [Income-Classification](https://www.kaggle.com/t/090688c8d33a40b68be9e271d6ba6bae) hãy chuẩn hóa dữ liệu và phân chia tập train/test theo tỷ lệ 80/20. "
      ],
      "metadata": {
        "id": "F_xfhh7WDIpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H6TgzZfDY1-",
        "outputId": "fdab69da-5e22-4ae8-ed1e-b10872ad737f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train_IC.csv\", index_col = 0)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "ZAawolp1Dciu",
        "outputId": "4df66f63-0e88-40ab-bfec-50a9a6b6ebe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-41833407-8711-4bf7-8516-e973a8852cc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>work_type</th>\n",
              "      <th>final_weight</th>\n",
              "      <th>education</th>\n",
              "      <th>total_education_yrs</th>\n",
              "      <th>marital_state</th>\n",
              "      <th>job</th>\n",
              "      <th>status</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>nationality</th>\n",
              "      <th>target_income</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>Private</td>\n",
              "      <td>175925</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>113601</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>112137</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>South</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>153078</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>Private</td>\n",
              "      <td>375515</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>47</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>188386</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>US</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>71864</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24</td>\n",
              "      <td>Private</td>\n",
              "      <td>395297</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>44</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>138975</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>42</td>\n",
              "      <td>?</td>\n",
              "      <td>167678</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>Ecuador</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41833407-8711-4bf7-8516-e973a8852cc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41833407-8711-4bf7-8516-e973a8852cc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41833407-8711-4bf7-8516-e973a8852cc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       age         work_type  ...  nationality target_income\n",
              "ID                            ...                           \n",
              "0       45           Private  ...           US             0\n",
              "1       23           Private  ...           US             0\n",
              "2       22           Private  ...        South             0\n",
              "3       27           Private  ...           US             0\n",
              "4       18           Private  ...           US             0\n",
              "...    ...               ...  ...          ...           ...\n",
              "24995   47         State-gov  ...           US             1\n",
              "24996   23           Private  ...           US             0\n",
              "24997   24           Private  ...           US             0\n",
              "24998   44  Self-emp-not-inc  ...           US             0\n",
              "24999   42                 ?  ...      Ecuador             0\n",
              "\n",
              "[25000 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xử lí missing data dạng \"?\"\n",
        "df = df.replace('?', np.NaN)\n",
        "df = df.fillna(method=\"ffill\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "xUHJ3kMtDlDW",
        "outputId": "e715f210-6caf-49c6-9bc6-4a3744f1ddc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4615ee99-a653-4db2-8072-014d849d0c26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>work_type</th>\n",
              "      <th>final_weight</th>\n",
              "      <th>education</th>\n",
              "      <th>total_education_yrs</th>\n",
              "      <th>marital_state</th>\n",
              "      <th>job</th>\n",
              "      <th>status</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>nationality</th>\n",
              "      <th>target_income</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>Private</td>\n",
              "      <td>175925</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>113601</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>112137</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>South</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>153078</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>Private</td>\n",
              "      <td>375515</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>47</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>188386</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>US</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>71864</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24</td>\n",
              "      <td>Private</td>\n",
              "      <td>395297</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>44</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>138975</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>42</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>167678</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>Ecuador</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4615ee99-a653-4db2-8072-014d849d0c26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4615ee99-a653-4db2-8072-014d849d0c26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4615ee99-a653-4db2-8072-014d849d0c26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       age         work_type  ...  nationality target_income\n",
              "ID                            ...                           \n",
              "0       45           Private  ...           US             0\n",
              "1       23           Private  ...           US             0\n",
              "2       22           Private  ...        South             0\n",
              "3       27           Private  ...           US             0\n",
              "4       18           Private  ...           US             0\n",
              "...    ...               ...  ...          ...           ...\n",
              "24995   47         State-gov  ...           US             1\n",
              "24996   23           Private  ...           US             0\n",
              "24997   24           Private  ...           US             0\n",
              "24998   44  Self-emp-not-inc  ...           US             0\n",
              "24999   42  Self-emp-not-inc  ...      Ecuador             0\n",
              "\n",
              "[25000 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuẩn hóa dữ liệu và\n",
        "from sklearn import preprocessing\n",
        " \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        " \n",
        "df['work_type'] = label_encoder.fit_transform(df['work_type'])\n",
        "df['education'] = label_encoder.fit_transform(df['education'])\n",
        "df['marital_state'] = label_encoder.fit_transform(df['marital_state'])\n",
        "df['job'] = label_encoder.fit_transform(df['job'])\n",
        "df['status'] = label_encoder.fit_transform(df['status'])\n",
        "df['ethnicity'] = label_encoder.fit_transform(df['ethnicity'])\n",
        "df['sex'] = label_encoder.fit_transform(df['sex'])\n",
        "df['nationality'] = label_encoder.fit_transform(df['nationality'])\n",
        "\n",
        "df['final_weight'] = df['final_weight'] /10000\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "vcal7EeXErvx",
        "outputId": "0d012484-267e-4ac2-ffcf-4ce5d21e0573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1e3cc91a-64ba-46dc-9399-bd14779492e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>work_type</th>\n",
              "      <th>final_weight</th>\n",
              "      <th>education</th>\n",
              "      <th>total_education_yrs</th>\n",
              "      <th>marital_state</th>\n",
              "      <th>job</th>\n",
              "      <th>status</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>nationality</th>\n",
              "      <th>target_income</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11090</th>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>16.6549</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17340</th>\n",
              "      <td>49</td>\n",
              "      <td>3</td>\n",
              "      <td>15.5489</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19960</th>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>24.1025</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>48</td>\n",
              "      <td>3</td>\n",
              "      <td>3.8950</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15574</th>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>38.7270</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e3cc91a-64ba-46dc-9399-bd14779492e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e3cc91a-64ba-46dc-9399-bd14779492e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e3cc91a-64ba-46dc-9399-bd14779492e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       age  work_type  final_weight  ...  hrs_per_week  nationality  target_income\n",
              "ID                                   ...                                          \n",
              "11090   36          3       16.6549  ...            55           38              1\n",
              "17340   49          3       15.5489  ...            40           38              0\n",
              "19960   25          3       24.1025  ...            18           38              0\n",
              "76      48          3        3.8950  ...            89           38              0\n",
              "15574   32          3       38.7270  ...            40           38              1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Phân chia tập train/test theo tỷ lệ 80/20\n",
        "from sklearn.model_selection import train_test_split\n",
        "   \n",
        "df_train, df_test = train_test_split(df, test_size=0.2, stratify = df['target_income'])\n",
        "X_train = df_train.copy()\n",
        "y_train = X_train.pop(\"target_income\")\n",
        "\n",
        "X_test = df_test.copy()\n",
        "y_test = X_test.pop(\"target_income\")\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5vl1E1iFAsJ",
        "outputId": "8885cafe-53b8-4166-fc2c-53a74a57c717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 14) (20000,)\n",
            "(5000, 14) (5000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Câu 10: Xây dựng một mạng deep-neural-network để huấn luyện mô hình trên dữ liệu train và đánh giá mô hình trên dữ liệu test."
      ],
      "metadata": {
        "id": "yW5yu91gGOP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVq3uHZLHPOY",
        "outputId": "5c48b7d5-69e2-444a-bbbb-f725a4c64d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch @ https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu111/torchaudio-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.11.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu111/torchvision-0.11.1%2Bcu111-cp37-cp37m-linux_x86_64.whl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "z6sc9RIhHVw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td"
      ],
      "metadata": {
        "id": "RV2AAXV1HZQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(X_train.values).float()\n",
        "train_y = torch.Tensor(y_train.values).long()\n",
        "\n",
        "train_ds = td.TensorDataset(train_x,train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size=20,\n",
        "    shuffle=False, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(X_test.values).float()\n",
        "test_y = torch.Tensor(y_test.values).long()\n",
        "test_ds = td.TensorDataset(test_x,test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size=20,\n",
        "    shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "XLXpYXcwH_YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['age', 'work_type', 'final_weight', 'education', 'total_education_yrs', 'marital_state', 'job', 'status',\n",
        "            'ethnicity', 'sex', 'capital_gain', 'capital_loss', 'hrs_per_week', 'nationality']\n",
        "label = 'target_income'\n",
        "\n",
        "income_classes = ['0', '1']"
      ],
      "metadata": {
        "id": "ZZWI7k9Vcp5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of hidden layer nodes\n",
        "hl = 10\n",
        "\n",
        "# Define the neural network\n",
        "class IncomeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IncomeNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(len(features), hl)\n",
        "        self.fc2 = nn.Linear(hl, hl)\n",
        "        self.fc3 = nn.Linear(hl, len(income_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Create a model instance from the network\n",
        "model = IncomeNet()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxJoFEaEbNO1",
        "outputId": "19a06bc9-b436-4f3d-ce18-7d7ff6af424e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncomeNet(\n",
            "  (fc1): Linear(in_features=14, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
            "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        #feedforward: calculate y_pred and loss function\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backpropagate: compute gradient descent and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    #Return average loss\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "           \n",
        "            \n",
        "def test(model, data_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data)\n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out, target).item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "            \n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss\n",
        "\n",
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwPSMQhodF4t",
        "outputId": "e88a3c17-873e-4631-b674-503f2eab85a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 0.644624\n",
            "Validation set: Average loss: 0.426134, Accuracy: 3990/5000 (80%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.458971\n",
            "Validation set: Average loss: 0.421447, Accuracy: 4037/5000 (81%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.450323\n",
            "Validation set: Average loss: 0.402115, Accuracy: 4092/5000 (82%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.402572\n",
            "Validation set: Average loss: 0.401725, Accuracy: 4101/5000 (82%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.393529\n",
            "Validation set: Average loss: 0.385798, Accuracy: 4126/5000 (83%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.380886\n",
            "Validation set: Average loss: 0.378588, Accuracy: 4130/5000 (83%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.372266\n",
            "Validation set: Average loss: 0.372357, Accuracy: 4130/5000 (83%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.366524\n",
            "Validation set: Average loss: 0.369376, Accuracy: 4130/5000 (83%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.373523\n",
            "Validation set: Average loss: 0.368576, Accuracy: 4124/5000 (82%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.360059\n",
            "Validation set: Average loss: 0.368557, Accuracy: 4121/5000 (82%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.361198\n",
            "Validation set: Average loss: 0.363216, Accuracy: 4121/5000 (82%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.365101\n",
            "Validation set: Average loss: 0.389319, Accuracy: 3924/5000 (78%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.379460\n",
            "Validation set: Average loss: 0.387749, Accuracy: 3918/5000 (78%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.376636\n",
            "Validation set: Average loss: 0.384776, Accuracy: 3918/5000 (78%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.372369\n",
            "Validation set: Average loss: 0.381062, Accuracy: 3906/5000 (78%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.371615\n",
            "Validation set: Average loss: 0.381775, Accuracy: 3904/5000 (78%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.370412\n",
            "Validation set: Average loss: 0.381045, Accuracy: 3906/5000 (78%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.369781\n",
            "Validation set: Average loss: 0.379685, Accuracy: 3897/5000 (78%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.368472\n",
            "Validation set: Average loss: 0.383621, Accuracy: 3906/5000 (78%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.371412\n",
            "Validation set: Average loss: 0.378666, Accuracy: 3911/5000 (78%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.367933\n",
            "Validation set: Average loss: 0.378096, Accuracy: 3905/5000 (78%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.367113\n",
            "Validation set: Average loss: 0.377081, Accuracy: 3915/5000 (78%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.371073\n",
            "Validation set: Average loss: 0.376718, Accuracy: 3910/5000 (78%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.366664\n",
            "Validation set: Average loss: 0.381228, Accuracy: 3907/5000 (78%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.367908\n",
            "Validation set: Average loss: 0.375252, Accuracy: 3914/5000 (78%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.365442\n",
            "Validation set: Average loss: 0.375155, Accuracy: 3907/5000 (78%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.364355\n",
            "Validation set: Average loss: 0.376869, Accuracy: 3901/5000 (78%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.364299\n",
            "Validation set: Average loss: 0.373184, Accuracy: 3909/5000 (78%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.362906\n",
            "Validation set: Average loss: 0.371658, Accuracy: 3912/5000 (78%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.363035\n",
            "Validation set: Average loss: 0.373543, Accuracy: 3915/5000 (78%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.365396\n",
            "Validation set: Average loss: 0.375467, Accuracy: 3906/5000 (78%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.362026\n",
            "Validation set: Average loss: 0.373956, Accuracy: 3908/5000 (78%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.361912\n",
            "Validation set: Average loss: 0.374133, Accuracy: 3906/5000 (78%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.361310\n",
            "Validation set: Average loss: 0.375121, Accuracy: 3906/5000 (78%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.361390\n",
            "Validation set: Average loss: 0.377304, Accuracy: 3904/5000 (78%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.361194\n",
            "Validation set: Average loss: 0.373049, Accuracy: 3902/5000 (78%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.361466\n",
            "Validation set: Average loss: 0.374591, Accuracy: 3908/5000 (78%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.360699\n",
            "Validation set: Average loss: 0.374344, Accuracy: 3908/5000 (78%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.360935\n",
            "Validation set: Average loss: 0.374995, Accuracy: 3904/5000 (78%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.360397\n",
            "Validation set: Average loss: 0.374768, Accuracy: 3905/5000 (78%)\n",
            "\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.360298\n",
            "Validation set: Average loss: 0.374218, Accuracy: 3899/5000 (78%)\n",
            "\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.361143\n",
            "Validation set: Average loss: 0.374873, Accuracy: 3909/5000 (78%)\n",
            "\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.359383\n",
            "Validation set: Average loss: 0.371734, Accuracy: 3925/5000 (78%)\n",
            "\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.360277\n",
            "Validation set: Average loss: 0.374423, Accuracy: 3901/5000 (78%)\n",
            "\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.359434\n",
            "Validation set: Average loss: 0.375223, Accuracy: 3903/5000 (78%)\n",
            "\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.358563\n",
            "Validation set: Average loss: 0.373564, Accuracy: 3907/5000 (78%)\n",
            "\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.359014\n",
            "Validation set: Average loss: 0.374330, Accuracy: 3912/5000 (78%)\n",
            "\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.358806\n",
            "Validation set: Average loss: 0.374730, Accuracy: 3905/5000 (78%)\n",
            "\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.358165\n",
            "Validation set: Average loss: 0.374977, Accuracy: 3900/5000 (78%)\n",
            "\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.358307\n",
            "Validation set: Average loss: 0.374046, Accuracy: 3903/5000 (78%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(epoch_nums, training_loss)\n",
        "plt.plot(epoch_nums, validation_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "N1nIDnbbmGm1",
        "outputId": "254bb121-15bd-4fcc-c203-69e5754d9675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Hàm loss giảm dần sau mỗi epoch, mô hình tìm trọng số và độ lệch phù hợp để dự đoán đúng các nhãn.\n",
        "+ Hàm loss training và validaion có trend gần như nhau càng về sau cho thấy mô hình khả năng cao không bị overfitting."
      ],
      "metadata": {
        "id": "uCf717a4m-6U"
      }
    }
  ]
}