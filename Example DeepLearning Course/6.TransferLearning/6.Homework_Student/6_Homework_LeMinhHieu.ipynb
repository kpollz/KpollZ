{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.Homework_LeMinhHieu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết"
      ],
      "metadata": {
        "id": "3oII0r_lpubh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Transfer Learning thường được thực hiện trên hai dữ liệu nguồn (huấn luyện mô hình nguồn) và dữ liệu đích (huấn luyện mô hình đích) thế nào ?\n",
        "\n",
        "\n",
        "A. Dữ liệu nguồn và dữ liệu đích có sự liên quan tới nhau. Những đặc trưng trong dữ liệu đích xuất hiện ở những dữ liệu nguồn.\n",
        "\n",
        "B. Dữ liệu nguồn có số lượng classes lớn hơn dữ liệu đích.\n",
        "\n",
        "C. Kích thước của dữ liệu nguồn rất nhỏ.\n",
        "\n",
        "D. Dữ liệu đích ít liên quan tới dữ liệu nguồn.\n",
        "\n",
        "***Đáp án: A.***"
      ],
      "metadata": {
        "id": "l5Ty0elJpzS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Khi nào thì chúng ta nên thực hiện fine tuning trên toàn bộ các layers của mô hình đích ?\n",
        "\n",
        "A. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước lớn.\n",
        "\n",
        "B. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước nhỏ.\n",
        "\n",
        "C. Dữ liệu đích có kích thước nhỏ và dữ liệu mục tiêu có kích thước lớn.\n",
        "\n",
        "D. Cả hai dữ liệu đích và mục tiêu đều có kích thước nhỏ.\n",
        "\n",
        "***Đáp án: A.***\n"
      ],
      "metadata": {
        "id": "wHXvMCwaxlyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Các phương pháp augmentation nào sẽ kết hợp nội dung từ hai ảnh lẫn nhau và tạo ra một nhãn mềm (_soft label_) cho ảnh?\n",
        "\n",
        "A. Rotation, Random Crop, MixUp\n",
        "\n",
        "B. Bright Constrast, Color Shift, Addition Noise\n",
        "\n",
        "C. CutMix, MixUp\n",
        "\n",
        "D. Flip, Information Loss\n",
        "\n",
        "***Đáp án: C.***\n"
      ],
      "metadata": {
        "id": "NOweiRmVrNeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Quá trình xây dựng một mô hình AI trong dự án là một chu trình Machine Learning Cycle kế hợp giữa huấn luyện và gán nhãn dữ liệu. Để tiết kiệm chi phí gán nhãn chúng ta nên sử dụng phương pháp nào ?\n",
        "\n",
        "A. Lấy mẫu ngẫu nhiên từ tập unlabeled dataset để thực hiện gán nhãn.\n",
        "\n",
        "B. Sử dụng Active Learning để lựa chọn mẫu mang lại thông tin giúp cải thiện nhiều nhất cho hiệu suất mô hình.\n",
        "\n",
        "C. Lựa chọn mô hình pretrained lớn nhất có thể.\n",
        "\n",
        "D. Chỉ lựa các dữ liệu có thông tin rõ ràng, có thể phân biệt được bởi con người.\n",
        "\n",
        "***Đáp án: B.***"
      ],
      "metadata": {
        "id": "D_mh5GpdtA6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Mô hình lớn thường đạt độ chính xác cao nhưng không deploy được trên các thiết bị edge device, IoT,... Trong khi mô hình nhỏ có thể deploy được nhưng thường có độ chính xác thấp. Phương pháp nào có thể giúp mô hình nhỏ cải thiện được độ chính xác ? Có thể lựa chọn nhiều đáp án.\n",
        "\n",
        "A. Sử dụng active learning để lựa chọn các mẫu đại diện cho tổng thể để huấn luyện mô hình nhỏ.\n",
        "\n",
        "B. Áp dụng augmentation để huấn luyện mô hình nhỏ.\n",
        "\n",
        "C. Fine tuning các layers của mô hình lớn sang mô hình nhỏ.\n",
        "\n",
        "D. Sử dụng knowledge distillation để chuyển giao tri thức từ mô hình lớn sang mô hình nhỏ.\n",
        "\n",
        "***Đáp án: A, B, D.***"
      ],
      "metadata": {
        "id": "aVBcCa80uqaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành"
      ],
      "metadata": {
        "id": "RLNVdWEupwu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Từ bộ dữ liệu [Dog and Cat](https://www.kaggle.com/c/dog-vs-cat-classification/data), hãy huấn luyện một mô hình large (chẳng hạn ResNet50) bằng cách fine-tuning lại các trọng số từ pretrained model của bộ dữ liệu ImageNet. Huấn luyện trên 5 epochs.\n",
        "\n",
        "7) Hãy huấn luyện một mô hình small (chẳng hạn MobileNetV3) không sử dụng pretrained model trên 1 epochs.\n",
        "\n",
        "8) Sử dụng mô hình large làm teacher để cải thiện mô hình small là student theo phương pháp knowledge distillation.\n",
        "\n",
        "9) Áp dụng thêm các kĩ thuật data augmentation kết hợp ảnh khác nhãn để tạo thành nhãn mềm và huấn luyện cải thiện tiếp model student.\n",
        "\n",
        "10) Giả định cần huấn luyện tiếp mô hình student với các dữ liệu mới chưa được gán nhãn. Hãy xây dựng một kĩ thuật lựa chọn mẫu dựa trên đánh giá uncertainty."
      ],
      "metadata": {
        "id": "TiNt8X4zxsvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) \n",
        "Từ bộ dữ liệu Dog and Cat, hãy huấn luyện một mô hình large (chẳng hạn ResNet50) bằng cách fine-tuning lại các trọng số từ pretrained model của bộ dữ liệu ImageNet. Huấn luyện trên 5 epochs."
      ],
      "metadata": {
        "id": "hXLGca7HN4-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o7VJfRiW8Tjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b998f4a4-843b-4b5c-fd99-d81fffc7f395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import time\n",
        "import pickle\n",
        "import pprint\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import tqdm\n",
        "import random\n",
        "import torchvision.transforms as T\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Fe7LSbeV4--U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/Colab Notebooks/TowardDataScience/lesson5/train/train'\n",
        "TEST_DIR = '/content/drive/MyDrive/Colab Notebooks/TowardDataScience/lesson5/test/test'\n",
        "train_images = glob.glob(TRAIN_DIR+\"/**/**.jpg\")\n",
        "test_images = glob.glob(TEST_DIR+\"/**.jpg\")"
      ],
      "metadata": {
        "id": "4z--_RRo4_Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dogs_list = [img for img in train_images if img.split(\"/\")[-2] == \"dogs\"]\n",
        "cats_list = [img for img in train_images if img.split(\"/\")[-2] == \"cats\"]\n",
        "\n",
        "print(\"Dogs Images: \",len(dogs_list))\n",
        "print(\"Cats Images: \",len(cats_list))\n",
        "\n",
        "class_to_int = {\"dogs\" : 0, \"cats\" : 1}\n",
        "int_to_class = {0 : \"dogs\", 1 : \"cats\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_0EtL6N4_aV",
        "outputId": "fceea242-3acd-4c14-fe7a-38b93999cb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dogs Images:  10000\n",
            "Cats Images:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "class CatDogDataset(Dataset):\n",
        "    def __init__(self, imgs, class_to_int, mode = \"train\", \n",
        "                 transforms = None):\n",
        "        super().__init__()\n",
        "        self.imgs = imgs\n",
        "        self.class_to_int = class_to_int\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.imgs[idx]\n",
        "        if self.mode == \"train\" or self.mode == \"val\":\n",
        "            img = Image.open(image_name)\n",
        "            # img = img.resize((256, 256))\n",
        "            ### Preparing class label\n",
        "            label = self.class_to_int[image_name.split(\"/\")[-2]]\n",
        "            label = torch.tensor(label, dtype = torch.float32)\n",
        "            ### Apply Transforms on image\n",
        "            img = self.transforms(img)\n",
        "            return img, label\n",
        "        elif self.mode == \"test\":\n",
        "            img = Image.open(image_name)\n",
        "            # img = img.resize((256, 256))\n",
        "            ### Apply Transforms on image\n",
        "            img = self.transforms(img)\n",
        "            return img, image_name\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "bytdi4L_4_dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_transform():\n",
        "    return T.Compose([\n",
        "        T.RandomHorizontalFlip(p=0.5), # Random flip with probability = 0.5\n",
        "        T.RandomRotation(15), # Random rotation with angle <= 15\n",
        "        # T.ColorJitter(brightness=.5, hue=.3), # Bright contrast\n",
        "        T.Resize((256, 256)),\n",
        "        T.RandomResizedCrop(224), # Random crop Image with shape 224\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)), # Normalize according to ImageNet distribution\n",
        "    ])\n",
        "    \n",
        "def get_val_transform():\n",
        "    return T.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "    ])"
      ],
      "metadata": {
        "id": "yDiIIsr49ZAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs, val_imgs = train_test_split(train_images, test_size = 0.2)"
      ],
      "metadata": {
        "id": "y38_7SVh9anD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CatDogDataset(train_imgs, class_to_int, mode = \"train\", \n",
        "                              transforms = get_train_transform())\n",
        "val_dataset = CatDogDataset(val_imgs, class_to_int, mode = \"val\", \n",
        "                            transforms = get_val_transform())\n",
        "test_dataset = CatDogDataset(test_images, class_to_int, mode = \"test\", \n",
        "                             transforms = get_val_transform())\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    num_workers = 2,\n",
        "    batch_size = 32,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    dataset = val_dataset,\n",
        "    num_workers = 2,\n",
        "    batch_size = 16,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_data_loader = DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    num_workers = 2,\n",
        "    batch_size = 1,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "0xEy8kGp9dgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "model = resnet50(pretrained = True)\n",
        "\n",
        "# Modifying Head - classifier\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 1, bias = True),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "YFDcgjCl-5o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.33)\n",
        "\n",
        "#Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Logs - Helpful for plotting after training finishes\n",
        "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "\n",
        "# setup device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Loading model to device\n",
        "model.to(device)\n",
        "\n",
        "# No of epochs \n",
        "warm_up_epochs = 5\n",
        "epochs = 15"
      ],
      "metadata": {
        "id": "ULbcRi_PGFyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, trues):\n",
        "    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n",
        "    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n",
        "    acc = np.sum(acc) / len(preds)\n",
        "    return (acc * 100)"
      ],
      "metadata": {
        "id": "2qDf0_8e_NbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(train_data_loader, model, optimizer):\n",
        "    epoch_loss = []\n",
        "    epoch_acc = []\n",
        "    start_time = time.time()\n",
        "    # model.to(device)\n",
        "    model.train()\n",
        "    \n",
        "    for images, labels in train_data_loader:\n",
        "        \n",
        "        #Loading images and labels to device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
        "        \n",
        "        #Reseting Gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #Forward\n",
        "        preds = model(images)\n",
        "        \n",
        "        #Calculating Loss\n",
        "        _loss = criterion(preds, labels)\n",
        "        loss = _loss.item()\n",
        "        epoch_loss.append(loss)\n",
        "        \n",
        "        #Calculating Accuracy\n",
        "        acc = accuracy(preds, labels)\n",
        "        epoch_acc.append(acc)\n",
        "        \n",
        "        #Backward\n",
        "        _loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    ###Overall Epoch Results\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    \n",
        "    ###Acc and Loss\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "    epoch_acc = np.mean(epoch_acc)\n",
        "    \n",
        "    ###Storing results to logs\n",
        "    train_logs[\"loss\"].append(epoch_loss)\n",
        "    train_logs[\"accuracy\"].append(epoch_acc)\n",
        "    train_logs[\"time\"].append(total_time)\n",
        "        \n",
        "    return epoch_loss, epoch_acc, total_time"
      ],
      "metadata": {
        "id": "kB6oS9Yb_R50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_one_epoch(val_data_loader, model, best_val_acc, model_name):\n",
        "    epoch_loss = []\n",
        "    epoch_acc = []\n",
        "    start_time = time.time()\n",
        "    # model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    for images, labels in val_data_loader:\n",
        "        \n",
        "        #Loading images and labels to device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
        "        \n",
        "        #Forward\n",
        "        preds = model(images)\n",
        "        \n",
        "        #Calculating Loss\n",
        "        _loss = criterion(preds, labels)\n",
        "        loss = _loss.item()\n",
        "        epoch_loss.append(loss)\n",
        "        \n",
        "        #Calculating Accuracy\n",
        "        acc = accuracy(preds, labels)\n",
        "        epoch_acc.append(acc)\n",
        "    \n",
        "    ###Overall Epoch Results\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    \n",
        "    ###Acc and Loss\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "    epoch_acc = np.mean(epoch_acc)\n",
        "    \n",
        "    ###Storing results to logs\n",
        "    val_logs[\"loss\"].append(epoch_loss)\n",
        "    val_logs[\"accuracy\"].append(epoch_acc)\n",
        "    val_logs[\"time\"].append(total_time)\n",
        "    \n",
        "    ###Saving best model\n",
        "    if epoch_acc > best_val_acc:\n",
        "        best_val_acc = epoch_acc\n",
        "        torch.save(model.state_dict(),model_name+\"_best.pth\")\n",
        "        \n",
        "    return epoch_loss, epoch_acc, total_time, best_val_acc"
      ],
      "metadata": {
        "id": "O-NllnsA_WK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
        "\n",
        "#Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Logs - Helpful for plotting after training finishes\n",
        "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "\n",
        "# setup device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Loading model to device\n",
        "model.to(device)\n",
        "\n",
        "# No of epochs \n",
        "warm_up_epochs = 5\n",
        "epochs = 15"
      ],
      "metadata": {
        "id": "5DDyq2hf1gv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0\n",
        "for epoch in range(warm_up_epochs):\n",
        "    ###Training\n",
        "    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nTraining\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    \n",
        "    ###Validation\n",
        "    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"resnet50\")\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nValidating\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cb900kI_zNp",
        "outputId": "33fcea31-5e07-4756-e09f-655612f80b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training\n",
            "Epoch 1\n",
            "Loss : 0.6898\n",
            "Acc : 55.8062\n",
            "Time : 2920.5163\n",
            "\n",
            "Validating\n",
            "Epoch 1\n",
            "Loss : 0.6469\n",
            "Acc : 59.675\n",
            "Time : 748.515\n",
            "\n",
            "Training\n",
            "Epoch 2\n",
            "Loss : 0.6405\n",
            "Acc : 62.4562\n",
            "Time : 355.0851\n",
            "\n",
            "Validating\n",
            "Epoch 2\n",
            "Loss : 0.6579\n",
            "Acc : 57.975\n",
            "Time : 33.6967\n",
            "\n",
            "Training\n",
            "Epoch 3\n",
            "Loss : 0.621\n",
            "Acc : 65.2438\n",
            "Time : 355.2121\n",
            "\n",
            "Validating\n",
            "Epoch 3\n",
            "Loss : 0.7015\n",
            "Acc : 55.6\n",
            "Time : 33.3593\n",
            "\n",
            "Training\n",
            "Epoch 4\n",
            "Loss : 0.6035\n",
            "Acc : 67.25\n",
            "Time : 355.5995\n",
            "\n",
            "Validating\n",
            "Epoch 4\n",
            "Loss : 0.6716\n",
            "Acc : 62.675\n",
            "Time : 33.4663\n",
            "\n",
            "Training\n",
            "Epoch 5\n",
            "Loss : 0.5953\n",
            "Acc : 68.075\n",
            "Time : 354.8348\n",
            "\n",
            "Validating\n",
            "Epoch 5\n",
            "Loss : 0.5904\n",
            "Acc : 68.25\n",
            "Time : 33.7083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) \n",
        "Hãy huấn luyện một mô hình small (chẳng hạn MobileNetV3) không sử dụng pretrained model trên 1 epochs."
      ],
      "metadata": {
        "id": "J5LwLRP4OD3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import mobilenet_v3_small\n",
        "model = mobilenet_v3_small()\n",
        "\n",
        "# Modifying Head - classifier\n",
        "model.classifier._modules['3']  = nn.Sequential(\n",
        "    nn.Linear(1024, 1, bias = True),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "mAsfe8R11Gve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xavier initialize\n",
        "for layer in model.classifier[3]:\n",
        "  if isinstance(layer, nn.modules.linear.Linear):\n",
        "    nn.init.xavier_uniform_(layer.weight)"
      ],
      "metadata": {
        "id": "OHocGC-QagyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Logs - Helpful for plotting after training finishes\n",
        "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "\n",
        "# setup device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Loading model to device\n",
        "model.to(device)\n",
        "\n",
        "# No of epochs \n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "iINYg_uuOKKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "learning_rate = 0.00001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
        "\n",
        "params_1x = [param for name, param in model.named_parameters()\n",
        "             if name not in [\"classifier.1.0.weight\", \"classifier.1.0.bias\"]]\n",
        "trainer = torch.optim.SGD([{'params': params_1x},\n",
        "                            {'params': model.classifier.parameters(), 'lr': learning_rate * 10}],\n",
        "                        lr=learning_rate, weight_decay=0.001)"
      ],
      "metadata": {
        "id": "WwalNrA0aJWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    ###Training\n",
        "    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nTraining\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    \n",
        "    ###Validation\n",
        "    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"mobilenet_v3_small\")\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nValidating\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKa3tbjFP3eA",
        "outputId": "2b5eb6b8-bec3-469a-fd18-ed90074cc1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training\n",
            "Epoch 1\n",
            "Loss : 0.6856\n",
            "Acc : 55.225\n",
            "Time : 144.2665\n",
            "\n",
            "Validating\n",
            "Epoch 1\n",
            "Loss : 0.6919\n",
            "Acc : 51.475\n",
            "Time : 26.8806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qhHZHkdqb9A2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}