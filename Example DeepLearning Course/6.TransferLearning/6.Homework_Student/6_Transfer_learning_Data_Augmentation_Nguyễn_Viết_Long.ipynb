{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.Transfer learning&Data Augmentation_Nguyễn Viết Long",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết"
      ],
      "metadata": {
        "id": "3oII0r_lpubh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Transfer Learning thường được thực hiện trên hai dữ liệu nguồn (huấn luyện mô hình nguồn) và dữ liệu đích (huấn luyện mô hình đích) thế nào ?\n",
        "\n",
        "\n",
        "A. Dữ liệu nguồn và dữ liệu đích có sự liên quan tới nhau. Những đặc trưng trong dữ liệu đích xuất hiện ở những dữ liệu nguồn.\n",
        "\n",
        "B. Dữ liệu nguồn có số lượng classes lớn hơn dữ liệu đích.\n",
        "\n",
        "C. Kích thước của dữ liệu nguồn rất nhỏ.\n",
        "\n",
        "D. Dữ liệu đích ít liên quan tới dữ liệu nguồn.\n",
        "\n",
        "=> Đáp án A"
      ],
      "metadata": {
        "id": "l5Ty0elJpzS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Khi nào thì chúng ta nên thực hiện fine tuning trên toàn bộ các layers của mô hình đích ?\n",
        "\n",
        "A. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước lớn.\n",
        "\n",
        "B. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước nhỏ.\n",
        "\n",
        "C. Dữ liệu đích có kích thước nhỏ và dữ liệu mục tiêu có kích thước lớn.\n",
        "\n",
        "D. Cả hai dữ liệu đích và mục tiêu đều có kích thước nhỏ.\n",
        "\n",
        "=> Đáp án A"
      ],
      "metadata": {
        "id": "wHXvMCwaxlyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Các phương pháp augmentation nào sẽ kết hợp nội dung từ hai ảnh lẫn nhau và tạo ra một nhãn mềm (_soft label_) cho ảnh?\n",
        "\n",
        "A. Rotation, Random Crop, MixUp\n",
        "\n",
        "B. Bright Constrast, Color Shift, Addition Noise\n",
        "\n",
        "C. CutMix, MixUp\n",
        "\n",
        "D. Flip, Information Loss \n",
        "\n",
        "=> Đáp án C"
      ],
      "metadata": {
        "id": "NOweiRmVrNeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Quá trình xây dựng một mô hình AI trong dự án là một chu trình Machine Learning Cycle kế hợp giữa huấn luyện và gán nhãn dữ liệu. Để tiết kiệm chi phí gán nhãn chúng ta nên sử dụng phương pháp nào ?\n",
        "\n",
        "A. Lấy mẫu ngẫu nhiên từ tập unlabeled dataset để thực hiện gán nhãn.\n",
        "\n",
        "B. Sử dụng Active Learning để lựa chọn mẫu mang lại thông tin giúp cải thiện nhiều nhất cho hiệu suất mô hình.\n",
        "\n",
        "C. Lựa chọn mô hình pretrained lớn nhất có thể.\n",
        "\n",
        "D. Chỉ lựa các dữ liệu có thông tin rõ ràng, có thể phân biệt được bởi con người.\n",
        "\n",
        "=> Đáp án B"
      ],
      "metadata": {
        "id": "D_mh5GpdtA6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Mô hình lớn thường đạt độ chính xác cao nhưng không deploy được trên các thiết bị edge device, IoT,... Trong khi mô hình nhỏ có thể deploy được nhưng thường có độ chính xác thấp. Phương pháp nào có thể giúp mô hình nhỏ cải thiện được độ chính xác ? Có thể lựa chọn nhiều đáp án.\n",
        "\n",
        "A. Sử dụng active learning để lựa chọn các mẫu đại diện cho tổng thể để huấn luyện mô hình nhỏ.\n",
        "\n",
        "B. Áp dụng augmentation để huấn luyện mô hình nhỏ.\n",
        "\n",
        "C. Fine tuning các layers của mô hình lớn sang mô hình nhỏ.\n",
        "\n",
        "D. Sử dụng knowledge distillation để chuyển giao tri thức từ mô hình lớn sang mô hình nhỏ.\n",
        "\n",
        "=> Đáp án B, C, D"
      ],
      "metadata": {
        "id": "aVBcCa80uqaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành"
      ],
      "metadata": {
        "id": "RLNVdWEupwu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Từ bộ dữ liệu [Dog and Cat](https://www.kaggle.com/c/dog-vs-cat-classification/data), hãy huấn luyện một mô hình large (chẳng hạn ResNet50) bằng cách fine-tuning lại các trọng số từ pretrained model của bộ dữ liệu ImageNet. Huấn luyện trên 5 epochs.\n",
        "\n",
        "7) Hãy huấn luyện một mô hình small (chẳng hạn MobileNetV3) không sử dụng pretrained model trên 1 epochs.\n",
        "\n",
        "8) Sử dụng mô hình large làm teacher để cải thiện mô hình small là student theo phương pháp knowledge distillation.\n",
        "\n",
        "9) Áp dụng thêm các kĩ thuật data augmentation kết hợp ảnh khác nhãn để tạo thành nhãn mềm và huấn luyện cải thiện tiếp model student.\n",
        "\n",
        "10) Giả định cần huấn luyện tiếp mô hình student với các dữ liệu mới chưa được gán nhãn. Hãy xây dựng một kĩ thuật lựa chọn mẫu dựa trên đánh giá uncertainty."
      ],
      "metadata": {
        "id": "TiNt8X4zxsvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Huấn luyện large model Resnet50 sử dụng fine-tuning trên 5 epochs"
      ],
      "metadata": {
        "id": "rf2eFke3lVg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aveDlUwUjD6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a067b41e-505d-4e38-ae5e-9106d2d427e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "UQ8rOczhjWrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab91601-f946-426b-8dba-81474c5b723c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "train_dir = '/content/drive/MyDrive/train/train'\n",
        "test_dir = '/content/drive/MyDrive/test/test'\n",
        "train_images = glob.glob(train_dir + \"/**/**.jpg\")\n",
        "test_images = glob.glob(test_dir + \"/**.jpg\")"
      ],
      "metadata": {
        "id": "xYkfyNAJeeFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mGuivZrg4gf",
        "outputId": "0fce3a21-caba-4517-eda9-a87adb7dc308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/train/train/cats/cat.9072.jpg',\n",
              " '/content/drive/MyDrive/train/train/cats/cat.9356.jpg',\n",
              " '/content/drive/MyDrive/train/train/cats/cat.916.jpg',\n",
              " '/content/drive/MyDrive/train/train/cats/cat.9384.jpg',\n",
              " '/content/drive/MyDrive/train/train/cats/cat.8956.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dogs_list = [img for img in train_images if img.split(\"/\")[-2] == \"dogs\"]\n",
        "cats_list = [img for img in train_images if img.split(\"/\")[-2] == \"cats\"]\n",
        "\n",
        "print(\"The number of dogs images: \",len(dogs_list))\n",
        "print(\"The number of cats images: \",len(cats_list))\n",
        "\n",
        "class_to_int = {\"dogs\" : 0, \"cats\" : 1}\n",
        "int_to_class = {0 : \"dogs\", 1 : \"cats\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_c7AyZSiX7S",
        "outputId": "484da6cc-0cfe-42e8-8e31-012f4e2cb256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of dogs images:  12500\n",
            "The number of cats images:  12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "print(\"Getting Data...\")\n",
        "datagen = ImageDataGenerator(rescale=1./255, # normalize pixel values\n",
        "                             validation_split=0.3, # hold back 30% of the images for validation\n",
        "                             rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,\n",
        "                             zoom_range=0.2,shear_range=0.2)\n",
        "\n",
        "print(\"Preparing training dataset...\")\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "\n",
        "print(\"Preparing validation dataset...\")\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "classnames = list(train_generator.class_indices.keys())\n",
        "print('Data generators ready')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M16AUMgCmBEI",
        "outputId": "8d188996-e41a-475d-f767-03248a588c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting Data...\n",
            "Preparing training dataset...\n",
            "Found 17500 images belonging to 2 classes.\n",
            "Preparing validation dataset...\n",
            "Found 7500 images belonging to 2 classes.\n",
            "Data generators ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "resnet_model = Sequential()\n",
        "pretrained_model = tf.keras.applications.ResNet50(input_shape=(128,128,3),\n",
        "                                include_top=False,pooling='avg',\n",
        "                                classes=2,weights='imagenet')\n",
        "# Đóng băng các lớp layers để ko train nữa\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable=False\n",
        "# => Trainable params = 0\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512,'relu'))\n",
        "resnet_model.add(Dropout(0.4))\n",
        "resnet_model.add(Dense(2,'softmax'))"
      ],
      "metadata": {
        "id": "sFSaozKqqnoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvNXOYe2r_cc",
        "outputId": "0a42d12e-858d-4155-a11b-390416aefab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,637,826\n",
            "Trainable params: 1,050,114\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " resnet_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "metadata": {
        "id": "KnSdFzrps__g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5 \n",
        "history_resnet = resnet_model.fit(\n",
        "                        train_generator,\n",
        "                        steps_per_epoch = train_generator.samples // batch_size,\n",
        "                        validation_data = validation_generator, \n",
        "                        validation_steps = validation_generator.samples // batch_size,\n",
        "                        epochs = epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89yspnAitdih",
        "outputId": "bc494af6-f525-4572-c2d3-f8ff86a13fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "546/546 [==============================] - 494s 906ms/step - loss: 0.6794 - acc: 0.5678 - val_loss: 0.6834 - val_acc: 0.5437\n",
            "Epoch 2/5\n",
            "546/546 [==============================] - 454s 832ms/step - loss: 0.6729 - acc: 0.5830 - val_loss: 0.6731 - val_acc: 0.5838\n",
            "Epoch 3/5\n",
            "546/546 [==============================] - 395s 724ms/step - loss: 0.6690 - acc: 0.5920 - val_loss: 0.6554 - val_acc: 0.6237\n",
            "Epoch 4/5\n",
            "546/546 [==============================] - 346s 633ms/step - loss: 0.6665 - acc: 0.5943 - val_loss: 0.6737 - val_acc: 0.5819\n",
            "Epoch 5/5\n",
            "546/546 [==============================] - 321s 588ms/step - loss: 0.6622 - acc: 0.6042 - val_loss: 0.6690 - val_acc: 0.5813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Huấn luyện small model MobileNetV3 không sử dụng pretrained model trên 1 epoch"
      ],
      "metadata": {
        "id": "kW5Md98xw4fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  mobilenet_model = Sequential()\n",
        "  pretrained_model = tf.keras.applications.MobileNetV2(input_shape=(128,128,3),\n",
        "                                include_top=False,pooling='avg',\n",
        "                                weights='imagenet')\n",
        "  # Đóng băng các lớp layers để ko train nữa\n",
        "  for layer in pretrained_model.layers:\n",
        "    layer.trainable=False\n",
        "  # => Trainable params = 0\n",
        "  mobilenet_model.add(Flatten())\n",
        "  mobilenet_model.add(Dense(2,'softmax'))\n",
        "  mobilenet_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm8vTAJxxI8D",
        "outputId": "274a6c4c-693c-4294-c4de-6bb631800bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "history_mobilenet_model = mobilenet_model.fit(\n",
        "                          train_generator,\n",
        "                          steps_per_epoch = train_generator.samples // batch_size,\n",
        "                          validation_data = validation_generator, \n",
        "                          validation_steps = validation_generator.samples // batch_size,\n",
        "                          epochs = epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8etWTkwxWeO",
        "outputId": "5a3259cd-76dc-4589-b095-85bb9c79f99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "546/546 [==============================] - 670s 1s/step - loss: 1.6959 - acc: 0.5268 - val_loss: 1.3208 - val_acc: 0.5212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Sử dụng mô hình large làm teacher để cải thiện mô hình small là student theo phương pháp knowledge distillation."
      ],
      "metadata": {
        "id": "Bl-2fgsCiblo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WVy6tFENxjkR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}