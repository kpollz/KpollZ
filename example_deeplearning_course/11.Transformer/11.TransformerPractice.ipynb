{"cells":[{"cell_type":"markdown","metadata":{"id":"xcq32C_Vl9h8"},"source":["`transformers` is a package enable you to train/load and create a model in hugging face in easy way."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12852,"status":"ok","timestamp":1649598313130,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"},"user_tz":-420},"id":"S7TyExjRmFyc","outputId":"5dc2c676-1bb6-4f91-9d6b-722353dfccd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 4.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 32.8 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.18.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"xjHD16FZmesG"},"source":["`bertviz` is package that support to make the visualization of sublayers of BERT model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16736,"status":"ok","timestamp":1649598329858,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"},"user_tz":-420},"id":"OxAX1Q8lmsj8","outputId":"27a92479-ef3d-49ab-e5c4-c58026d8899b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bertviz\n","  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n","\u001b[?25l\r\u001b[K     |██                              | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 30 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 61 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 71 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 102 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 112 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 122 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 133 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 143 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 153 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 157 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.63.0)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.10.0+cu111)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bertviz) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from bertviz) (2019.12.20)\n","Collecting boto3\n","  Downloading boto3-1.21.37-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 42.4 MB/s \n","\u001b[?25hRequirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.18.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 46.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->bertviz) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.0.49)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.11.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (1.21.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.5.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.7)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.7 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting botocore<1.25.0,>=1.24.37\n","  Downloading botocore-1.24.37-py3-none-any.whl (8.7 MB)\n","\u001b[K     |████████████████████████████████| 8.7 MB 13.9 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.37->boto3->bertviz) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.37->boto3->bertviz) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.0->bertviz) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (3.0.4)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 35.6 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.0->bertviz) (1.1.0)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, boto3, bertviz\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed bertviz-1.4.0 boto3-1.21.37 botocore-1.24.37 jmespath-1.0.0 s3transfer-0.5.2 sentencepiece-0.1.96 urllib3-1.25.11\n"]}],"source":["!pip install bertviz"]},{"cell_type":"markdown","metadata":{"id":"kKufm7EAmzrt"},"source":["Make sure you click `RESTART RUNTIME` buttom in order to enable to use package in runtime."]},{"cell_type":"markdown","metadata":{"id":"Raf9GyUgvt9D"},"source":["# 1. Visualization BERT sublayers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":786,"output_embedded_package_id":"1FeqD5pJzx9w_z2Rz4wabXotiQnU_HcFL","referenced_widgets":["5e443910adb04c039744afe93182377b","dee87801286945de94798536eff6941a","adb9b75c0d7f40a98fca5ace115a1ea1","68399d9a120b44e2bd86b28ae9efd773","e761413e76684f1ebefb105f75d864c7","2a801a1b15014e549feb382f5f72af59","b47b28c8c1594b17b505fc47b62ca3f7","cdeab47d23c44e9c9418b772b1c7670d","18c8e381b4c1452fae63bfe12d01069d","d043a3f26a124efc98a8874357176189","af1a7cdfd99e40e99edb52103d52468b","80782a9beb5a4576988c6b119684183b","3c4e0f122d934b41a47335b243053034","9d4d90fd846c4f778c3aca90d23e2ed1","c9104094ab85418e8962065a675b7a3a","898010a752724aae85d54e39ba9c29c9","4a590dc678a7411d90d835e363054e1c","a69f21fc636542fe9339176e783b62d5","c6dd36740e994508807031789f640d02","53d929970da24feab8813ea093932850","4ab52a28a49e44089e3cb81313c729c4","3310bf004b234b11878866bbef76231c","90296aef39fb487a93f1d68a7753f7ba","2005539612b54897b576185eb975eb53","0c3231f47d4f4403bb37cc3aa401bba7","03f3ee80f82c4d5da8cfd84b5a52309f","5b42b9f9ac6a4572a3ee9687d11ad627","83de15505a724f56ba978dfa433eedb5","29432fc5f94843d7b0064eb5ebe21a8a","6f65fe0e7de94a24bcacc36200536bdb","acd7b52154894c92a4ea7af43a60c088","61f2397976e94d1e9fceae5b3861da61","61d89ca432a447059ceb67da5fa113ab","3e3c428a1f674a65b2e5588596e52313","ee1b27e0fab448e281c705f6b2fdf9b4","fd0b845f59064f29a0332dca5e622a9f","78af810e7fb647c6bb70dc4c5d2b8c08","11215ee96dca48be8db3f3e14febc28c","e04c0316da7a4ef7b93fdada6da952a7","e430be2e986f4c4993faada6d9926fdd","40dcb117109e4b959956a2592c49e24d","75e1581314c94430b0445fe41657d0e8","27c663099a83440e970181fb3695f066","22c48d4164c04ea882a0b8b5b56e142d"]},"executionInfo":{"elapsed":86097,"status":"ok","timestamp":1649598448634,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"},"user_tz":-420},"id":"rpL_C-c1mCq9","outputId":"45daa673-1b7f-45b2-8ea6-849f7211ba60"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","from bertviz.transformers_neuron_view import BertModel\n","from bertviz.neuron_view import show\n","\n","model_ckpt = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","model = BertModel.from_pretrained(model_ckpt)\n","text = \"I am a machine learning engineer who is currently working on some big NLP projects\"\n","show(model, \"bert\", tokenizer, text, display_mode=\"light\", layer=0, head=8)"]},{"cell_type":"markdown","metadata":{"id":"Ep22TB6JvSXT"},"source":["# 2. Component is inside Transformer"]},{"cell_type":"markdown","metadata":{"id":"nJytheS5v6Y_"},"source":["## 2.1. Scaled dot-product attention"]},{"cell_type":"markdown","metadata":{"id":"kAU1TqpRotOD"},"source":["The first thing we need to do is tokenize the input text into list of indices by tokenizer."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tk2SIQjDojAT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649598625385,"user_tz":-420,"elapsed":461,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"}},"outputId":"2f68a977-c9a2-4f46-d31e-aefcc5fbc588"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1045,  2572,  1037,  3698,  4083,  3992,  2040,  2003,  2747,  2551,\n","          2006,  2070,  2502, 17953,  2361,  3934]])"]},"metadata":{},"execution_count":2}],"source":["inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n","inputs.input_ids"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4FTppKJgo_Hn","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1649598634719,"user_tz":-420,"elapsed":594,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"}},"outputId":"b2a87893-498c-4ca0-f159-181bab78c18a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'I am a machine learning engineer who is currently working on some big NLP projects'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["text"]},{"cell_type":"markdown","metadata":{"id":"PmFHcdkio8aN"},"source":["Each indice in the input indices list is mapped to an unique word in dictionary. Those indices in the next step are projected into a new feature space that represents an embedding vector for each of them. Process of transformation is made of `torch.nn.Embedding` layer that acts as a look up table for each indice."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2_o2ctF0o7pp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649598950172,"user_tz":-420,"elapsed":1175,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"}},"outputId":"d32ae2c9-6339-4878-e37c-ab2341c0bb86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30522, 768)"]},"metadata":{},"execution_count":4}],"source":["import torch.nn as nn\n","from transformers import AutoConfig\n","\n","config = AutoConfig.from_pretrained(model_ckpt)\n","token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n","token_emb"]},{"cell_type":"markdown","metadata":{"id":"VshKDywWqwKd"},"source":["Normally, BERT model transform each word into vector of 768 dimensionalities. Feed forward `inputs.input_ids` through `token_emb` to achive the matrix embedding of whole sequence with shape `(batch_size, seq_length, embedding_size)`."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ZecUIs5froiR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649598954385,"user_tz":-420,"elapsed":442,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"}},"outputId":"9458343b-58a6-4513-eeeb-95c76bf23261"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 16, 768])"]},"metadata":{},"execution_count":5}],"source":["input_embs = token_emb(inputs.input_ids)\n","input_embs.shape"]},{"cell_type":"markdown","metadata":{"id":"pr_GlQ1Pr_T4"},"source":["Next, we caculate the self-attention through `scaled_dot_product_attention()` function:\n","\n","![](https://imgur.com/3CVYGDi.png)\n","\n","Figure 1: Scale dot-product attention mechanism."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"RZETS5DWr2yA","executionInfo":{"status":"ok","timestamp":1649599065570,"user_tz":-420,"elapsed":409,"user":{"displayName":"khanhblog AI","userId":"06481533334230032014"}}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from math import sqrt\n","\n","def scaled_dot_product_attention(query, key, value):\n","    dim_k = query.size(-1)\n","    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n","    weights = F.softmax(scores, dim=-1)\n","    return torch.bmm(weights, value)"]},{"cell_type":"markdown","metadata":{"id":"KVSht78Ss1Xk"},"source":["`torch.bmm()` is a function that compute the batch matix multiplication. The batch dimension is kept outside and we only multiply two matrix based on two remain dimensions. In this case `weights` has shape `(batch, seq_length, seq_length)` and `value` has shape `(batch, seq_length, hidden_size)`. Thus in return, the output unchanges batch and multiply matrix `(seq_length, seq_length)` with `(seq_length, hidden_size)` to create `(seq_length, hidden_size)`. Finally output is `(batch, seq_length, hidden_size)`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPV9ARviuy4V"},"outputs":[],"source":["query = key = value = input_embs\n","weighted_value = scaled_dot_product_attention(query, key, value)\n","weighted_value.shape"]},{"cell_type":"markdown","metadata":{"id":"-oaA8SCQyFsj"},"source":["## 2.2. Multi-head Attention\n","\n","weights and values vector are used as input to compute the final linear projection output values vector for each self-attention layer. That is not all story about attention idea. Further, we do self-attention multiple times and in parallelization that seem to be more benefical for model enable to study variety aspects of sentiment of sequence. Those process are carried in the same time, thus we can train and inference them faster on parallel GPUs system. Of course, it saves both the time and performance in return.\n","\n","![](https://imgur.com/D6mLEJW.png)\n","\n","Figure 2: Multi-head attention architecture.\n","\n","We consider each linear combination which is a weighted value vector in the output of an attention layer like a head. Thus, multiple output vectors are named as multi-head attention output. They are concatenated in the next step and do linear projection again to get output with the same shape as the input of a sublayer. That is to guarantee we can apply multiple stacked sublayers in a deep sequence without error shape."]},{"cell_type":"markdown","metadata":{"id":"U0HsF7G63cI9"},"source":["Firstly, we wrap self-attention in to a `nn.Module` under the name `AttentionHead()` in order to facilitate packaging module and reusing it in later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vK0a6VUFyIec"},"outputs":[],"source":["class AttentionHead(nn.Module):\n","    def __init__(self, embed_dim, head_dim):\n","        super().__init__()\n","        self.q = nn.Linear(embed_dim, head_dim)\n","        self.k = nn.Linear(embed_dim, head_dim)\n","        self.v = nn.Linear(embed_dim, head_dim)\n","\n","    def forward(self, hidden_state):\n","        attn_outputs = scaled_dot_product_attention(\n","            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n","        return attn_outputs"]},{"cell_type":"markdown","metadata":{"id":"NiP5XbuB4PW0"},"source":["Based on `AttentionHead()` class to initialize multiple-head and then concatenate them and do the linear projection."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2yfI5xY4hyA"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        embed_dim = config.hidden_size # 768\n","        num_heads = config.num_attention_heads # 128\n","        head_dim = embed_dim // num_heads\n","        self.heads = nn.ModuleList(\n","            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n","        )\n","        self.output_linear = nn.Linear(embed_dim, embed_dim)\n","\n","    def forward(self, hidden_state):\n","        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n","        x = self.output_linear(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tY5naA6F45E4"},"outputs":[],"source":["multihead_attn = MultiHeadAttention(config)\n","attn_output = multihead_attn(input_embs)\n","attn_output.size()"]},{"cell_type":"markdown","metadata":{"id":"0gls_Z7-6RM5"},"source":["## 2.3. Feed forward layer\n","\n","Feed forward are two fully connected layers plugged after Multi-head Attention to make a complete sublayer of Transformer. They are just simply wrapped into `nn.Module` like that: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zmkid7Y-6VO9"},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n","        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","\n","    def forward(self, x):\n","        x = self.linear_1(x)\n","        x = self.gelu(x)\n","        x = self.linear_2(x)\n","        x = self.dropout(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNaCbWW26Z_P"},"outputs":[],"source":["feed_forward = FeedForward(config)\n","ff_outputs = feed_forward(attn_output)\n","ff_outputs.size()"]},{"cell_type":"markdown","metadata":{"id":"qdYDrGcD7F5C"},"source":["## 2.4. A sublayer\n","\n","\n","In experiment we prove that models are faster convergence and approach to the optimal point when interleaves normalization between `Multi-head attention` layer and `Feed Forward` layer. There are two style of apply normalization:\n","\n","* Post layer norm: Apply them after Multi-head attention layers and they are located outside skip connection.\n","\n","* Pre layer norm: Norm layers are added right in front of Multi-head attention and are within skip connection range. "]},{"cell_type":"markdown","metadata":{"id":"Wrt_jR_Y72f1"},"source":["![](https://imgur.com/b2hrwmi.png)\n","\n","Figure 3: Post layer norm\n","\n","![](https://imgur.com/fbSsI2F.png)\n","\n","Figure 4: Pre layer norm\n","\n","In below we apply in `pre layer norm`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wi-kHxrP-W5f"},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n","        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n","        self.attention = MultiHeadAttention(config)\n","        self.feed_forward = FeedForward(config)\n","\n","    def forward(self, x):\n","        # Apply layer normalization and then copy input into query, key, value\n","        hidden_state = self.layer_norm_1(x)\n","        # Apply attention with a skip connection\n","        x = x + self.attention(hidden_state)\n","        # Apply feed-forward layer with a skip connection\n","        x = x + self.feed_forward(self.layer_norm_2(x))\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4vjJWaM_etF"},"outputs":[],"source":["encoder_layer = TransformerEncoderLayer(config)\n","encoder_layer(input_embs).size()"]},{"cell_type":"markdown","metadata":{"id":"eq4xSagIAISW"},"source":["We draw a remark that the output shape of the whole process of the sublayer is the same as the input shape"]},{"cell_type":"markdown","metadata":{"id":"xCPAkiGuADHj"},"source":["## 2.5. Positional Embedding"]},{"cell_type":"markdown","metadata":{"id":"uGJ3t1xj-KqF"},"source":["Positional embeddings are based on a simple, yet very effective idea: augment the token embeddings with a position-dependent pattern of values arranged in a vector. If the pattern is characteristic for each position, the attention heads and feed-forward layers in each stack can learn to incorporate positional information in their transformations.\n","\n","There are several ways to achieve this and one of the most popular approaches, especially when the pretraining dataset is sufficiently large, is to use a learnable pattern. This works exactly the same way as the token embeddings but using the position index instead of the token ID as input. With that approach an efficient way of encoding the position of tokens is learned during pretraining."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hb3uYQZPAZq8"},"outputs":[],"source":["class Embeddings(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.token_embeddings = nn.Embedding(config.vocab_size,\n","                                             config.hidden_size)\n","        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n","                                               config.hidden_size)\n","        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n","        self.dropout = nn.Dropout()\n","\n","    def forward(self, input_ids):\n","        # Create position IDs for input sequence\n","        seq_length = input_ids.size(1)\n","        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n","        # create token and position embeddings\n","        token_embeddings = self.token_embeddings(input_ids)\n","        position_embeddings = self.position_embeddings(position_ids)\n","        # Combine token and position embeddings\n","        embeddings = token_embeddings + position_embeddings\n","        embeddings = self.layer_norm(embeddings)\n","        embeddings = self.dropout(embeddings)\n","        return embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j0DDRVX_AgSJ"},"outputs":[],"source":["embedding_layer = Embeddings(config)\n","embedding_layer(inputs.input_ids).size()"]},{"cell_type":"markdown","metadata":{"id":"uPeHABBlBdDz"},"source":["# 3. Full Encoder\n","\n","Now we have all module that are necessary to build a complete Encoder. In the next step, we adapt those modules to a pipeline which applies positional embedding in the first and forwards to number of sublayers in the following."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gAsT_UMCBZss"},"outputs":[],"source":["class TransformerEncoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.embeddings = Embeddings(config)\n","        self.layers = nn.ModuleList([TransformerEncoderLayer(config)\n","                                     for _ in range(config.num_hidden_layers)])\n","\n","    def forward(self, x):\n","        x = self.embeddings(x)\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FJdHZ9ZZCraz"},"outputs":[],"source":["encoder = TransformerEncoder(config)\n","encoder(inputs.input_ids).size()"]},{"cell_type":"markdown","metadata":{"id":"hx1ULl1CC5GT"},"source":["# 4. Bodies and Heads\n","\n","So now that we have a full transformer encoder model we would like to build a classifier with it. The model is usually divided into a task independant body and a task specific head. What we’ve built so far is the body and we now need to attach a classification head to that body. Just simply add Linear Projection:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlEOvojkDETd"},"outputs":[],"source":["class TransformerForSequenceClassification(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.encoder = TransformerEncoder(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","    def forward(self, x):\n","        x = self.encoder(x)[:, 0, :]\n","        x = self.dropout(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60qZ9hbuDMKj"},"outputs":[],"source":["config.num_labels = 2\n","encoder_classifier = TransformerForSequenceClassification(config)\n","encoder_classifier(inputs.input_ids).size()"]},{"cell_type":"markdown","metadata":{"id":"icuwv9K7DI3o"},"source":["# 5. Transformer Decoder\n","\n","The decoder has two attention sublayers:\n","\n","**Masked multi-head attention:** Ensures that the tokens we generate at each timestep are only based on the past outputs and the current token being predicted. Without this, the decoder could cheat during training by simply copying the target translations, so masking the inputs ensures the task is not trivial.\n","\n","**Encoder-decoder attention:** Performs multi-head attention over the output key and value vectors of the encoder stack, with the intermediate representation of the decoder acting as the queries. This way the encoder-decoder attention layer learns how to relate tokens from two different sequences such as two different languages.\n","\n","![](https://imgur.com/ttdW8nt.png)\n","\n","Figure 5: Decoder architecture.\n","\n","\n","Let’s take a look at the modifications we need to include masking in self-attention, and leave the implementation of the encoder-decoder attention layer as a homework problem. The trick with masked self-attention is to introduce a mask matrix with ones on the lower diagonal and zeros above:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2NmeDjxFxUJ"},"outputs":[],"source":["seq_len = inputs.input_ids.size(-1)\n","mask = torch.tril(torch.ones(seq_len, seq_len)).view(1, seq_len, seq_len)\n","mask[0]"]},{"cell_type":"markdown","metadata":{"id":"K0epSEx-GcMw"},"source":["Here we’ve used PyTorch’s tril function to create the lower triangular matrix. Once we have this mask matrix, we can the prevent each attention head from peeking at future tokens by using `torch.Tensor.masked_fill` to replace all the zeros with negative infinity:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M_cM7jkPHE_B"},"outputs":[],"source":["def scaled_dot_product_attention(query, key, value, mask=None):\n","    dim_k = query.size(-1)\n","    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n","    weights = F.softmax(scores, dim=-1)\n","    return weights.bmm(value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZNMVG5mHqzr"},"outputs":[],"source":["class AttentionHeadMasked(nn.Module):\n","    def __init__(self, embed_dim, head_dim):\n","        super().__init__()\n","        self.q = nn.Linear(embed_dim, head_dim)\n","        self.k = nn.Linear(embed_dim, head_dim)\n","        self.v = nn.Linear(embed_dim, head_dim)\n","\n","    def forward(self, x, e_k, e_v):\n","        '''\n","        x: input in decoder\n","        e_k: keys vector from encoder\n","        e_v: values vector from encoder\n","        '''\n","        batch_size, seq_len, chanel = x.shape\n","        mask = torch.tril(torch.ones(batch_size, seq_len, seq_len))\n","        # Truncate mask, e_k, e_v to current position of word.\n","        mask = mask[:, :seq_len, :seq_len]\n","        e_k = e_k[:, :seq_len, :]\n","        e_v = e_v[:, :seq_len, :]\n","        attn_outputs = scaled_dot_product_attention(\n","            self.q(x), self.k(e_k), self.v(e_v), mask)\n","        return attn_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I76StUESORJb"},"outputs":[],"source":["class MultiHeadAttentionMasked(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        embed_dim = config.hidden_size # 768\n","        num_heads = config.num_attention_heads # 128\n","        head_dim = embed_dim // num_heads\n","        self.heads = nn.ModuleList(\n","            [AttentionHeadMasked(embed_dim, head_dim) for _ in range(num_heads)]\n","        )\n","        self.output_linear = nn.Linear(embed_dim, embed_dim)\n","\n","    def forward(self, x, e_h, e_v):\n","        '''\n","        x: input in decoder\n","        e_k: keys vector from encoder\n","        e_v: values vector from encoder\n","        '''\n","        x = torch.cat([h(x, e_h, e_v) for h in self.heads], dim=-1)\n","        x = self.output_linear(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuzbky6kJ1mU"},"outputs":[],"source":["multihead_attn_msk = MultiHeadAttentionMasked(config)\n","input_embs = token_emb(inputs.input_ids)\n","e_k = e_v = encoder(inputs.input_ids)\n","# Assume that we only touch to 4'th position of words in sequence.\n","attn_output_dec = multihead_attn_msk(input_embs[:,:4, :], e_k, e_v)\n","attn_output_dec.size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kB6YLlPCRrt-"},"outputs":[],"source":["class TransformerDecoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n","        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n","        self.attention = MultiHeadAttentionMasked(config)\n","        self.feed_forward = FeedForward(config)\n","\n","    def forward(self, x, e_k, e_v):\n","        '''\n","        x: input in decoder\n","        e_k: keys vector from encoder\n","        e_v: values vector from encoder\n","        '''\n","        # Apply layer normalization and then copy input into query, key, value\n","        hidden_state = self.layer_norm_1(x)\n","        # Apply attention with a skip connection\n","        x = x + self.attention(hidden_state, e_k, e_v)\n","        # Apply feed-forward layer with a skip connection\n","        x = x + self.feed_forward(self.layer_norm_2(x))\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqb5r4Y9SC1P"},"outputs":[],"source":["decoder_layer = TransformerDecoderLayer(config)\n","# Assume that we only touch to 4'th position of words in sequence.\n","decoder_layer(input_embs[:,:4, :], e_k, e_v).size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xx_XAn_yRVRp"},"outputs":[],"source":["class TransformerDecoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.embeddings = Embeddings(config)\n","        self.layers = nn.ModuleList([TransformerDecoderLayer(config)\n","                                     for _ in range(config.num_hidden_layers)])\n","\n","    def forward(self, x, e_k, e_v):\n","        '''\n","        x: input in decoder\n","        e_k: keys vector from encoder\n","        e_v: values vector from encoder\n","        '''\n","        for layer in self.layers:\n","            x = layer(x, e_k, e_v)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCw3MzMAS1Hm"},"outputs":[],"source":["decoder = TransformerDecoder(config)\n","decoder(input_embs[:,:4, :], e_k, e_v).size()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"11.TransformerPractice.ipynb","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03f3ee80f82c4d5da8cfd84b5a52309f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61f2397976e94d1e9fceae5b3861da61","placeholder":"​","style":"IPY_MODEL_61d89ca432a447059ceb67da5fa113ab","value":" 226k/226k [00:00&lt;00:00, 313kB/s]"}},"0c3231f47d4f4403bb37cc3aa401bba7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f65fe0e7de94a24bcacc36200536bdb","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_acd7b52154894c92a4ea7af43a60c088","value":231508}},"11215ee96dca48be8db3f3e14febc28c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18c8e381b4c1452fae63bfe12d01069d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2005539612b54897b576185eb975eb53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83de15505a724f56ba978dfa433eedb5","placeholder":"​","style":"IPY_MODEL_29432fc5f94843d7b0064eb5ebe21a8a","value":"Downloading: 100%"}},"22c48d4164c04ea882a0b8b5b56e142d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27c663099a83440e970181fb3695f066":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29432fc5f94843d7b0064eb5ebe21a8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a801a1b15014e549feb382f5f72af59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3310bf004b234b11878866bbef76231c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c4e0f122d934b41a47335b243053034":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a590dc678a7411d90d835e363054e1c","placeholder":"​","style":"IPY_MODEL_a69f21fc636542fe9339176e783b62d5","value":"Downloading: 100%"}},"3e3c428a1f674a65b2e5588596e52313":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee1b27e0fab448e281c705f6b2fdf9b4","IPY_MODEL_fd0b845f59064f29a0332dca5e622a9f","IPY_MODEL_78af810e7fb647c6bb70dc4c5d2b8c08"],"layout":"IPY_MODEL_11215ee96dca48be8db3f3e14febc28c"}},"40dcb117109e4b959956a2592c49e24d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a590dc678a7411d90d835e363054e1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ab52a28a49e44089e3cb81313c729c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d929970da24feab8813ea093932850":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b42b9f9ac6a4572a3ee9687d11ad627":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e443910adb04c039744afe93182377b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dee87801286945de94798536eff6941a","IPY_MODEL_adb9b75c0d7f40a98fca5ace115a1ea1","IPY_MODEL_68399d9a120b44e2bd86b28ae9efd773"],"layout":"IPY_MODEL_e761413e76684f1ebefb105f75d864c7"}},"61d89ca432a447059ceb67da5fa113ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61f2397976e94d1e9fceae5b3861da61":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68399d9a120b44e2bd86b28ae9efd773":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d043a3f26a124efc98a8874357176189","placeholder":"​","style":"IPY_MODEL_af1a7cdfd99e40e99edb52103d52468b","value":" 28.0/28.0 [00:00&lt;00:00, 130B/s]"}},"6f65fe0e7de94a24bcacc36200536bdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75e1581314c94430b0445fe41657d0e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78af810e7fb647c6bb70dc4c5d2b8c08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27c663099a83440e970181fb3695f066","placeholder":"​","style":"IPY_MODEL_22c48d4164c04ea882a0b8b5b56e142d","value":" 455k/455k [00:00&lt;00:00, 577kB/s]"}},"80782a9beb5a4576988c6b119684183b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c4e0f122d934b41a47335b243053034","IPY_MODEL_9d4d90fd846c4f778c3aca90d23e2ed1","IPY_MODEL_c9104094ab85418e8962065a675b7a3a"],"layout":"IPY_MODEL_898010a752724aae85d54e39ba9c29c9"}},"83de15505a724f56ba978dfa433eedb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"898010a752724aae85d54e39ba9c29c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90296aef39fb487a93f1d68a7753f7ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2005539612b54897b576185eb975eb53","IPY_MODEL_0c3231f47d4f4403bb37cc3aa401bba7","IPY_MODEL_03f3ee80f82c4d5da8cfd84b5a52309f"],"layout":"IPY_MODEL_5b42b9f9ac6a4572a3ee9687d11ad627"}},"9d4d90fd846c4f778c3aca90d23e2ed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6dd36740e994508807031789f640d02","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53d929970da24feab8813ea093932850","value":570}},"a69f21fc636542fe9339176e783b62d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acd7b52154894c92a4ea7af43a60c088":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"adb9b75c0d7f40a98fca5ace115a1ea1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdeab47d23c44e9c9418b772b1c7670d","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18c8e381b4c1452fae63bfe12d01069d","value":28}},"af1a7cdfd99e40e99edb52103d52468b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b47b28c8c1594b17b505fc47b62ca3f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6dd36740e994508807031789f640d02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9104094ab85418e8962065a675b7a3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ab52a28a49e44089e3cb81313c729c4","placeholder":"​","style":"IPY_MODEL_3310bf004b234b11878866bbef76231c","value":" 570/570 [00:00&lt;00:00, 4.18kB/s]"}},"cdeab47d23c44e9c9418b772b1c7670d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d043a3f26a124efc98a8874357176189":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dee87801286945de94798536eff6941a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a801a1b15014e549feb382f5f72af59","placeholder":"​","style":"IPY_MODEL_b47b28c8c1594b17b505fc47b62ca3f7","value":"Downloading: 100%"}},"e04c0316da7a4ef7b93fdada6da952a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e430be2e986f4c4993faada6d9926fdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e761413e76684f1ebefb105f75d864c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee1b27e0fab448e281c705f6b2fdf9b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e04c0316da7a4ef7b93fdada6da952a7","placeholder":"​","style":"IPY_MODEL_e430be2e986f4c4993faada6d9926fdd","value":"Downloading: 100%"}},"fd0b845f59064f29a0332dca5e622a9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40dcb117109e4b959956a2592c49e24d","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75e1581314c94430b0445fe41657d0e8","value":466062}}}}},"nbformat":4,"nbformat_minor":0}