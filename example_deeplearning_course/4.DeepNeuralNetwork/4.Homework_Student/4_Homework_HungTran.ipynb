{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.Homework_HungTran.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEr1eFvAmug6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết\n",
        "\n",
        "1) Tại sao các mô hình deep learning lại chiếm ưu thế hơn so với các mô hình machine learning truyền thống đối với dữ liệu lớn ?\n",
        "\n",
        "**A. Do mô hình deep learning có thể được thiết kế với kích thước tùy ý nên có khả năng xấp xỉ mọi hàm số. Do đó nó có khả năng biểu diễn tốt và hoạt động hiệu quả trên dữ liệu lớn.**\n",
        "\n",
        "B. Các mô hình machine learning thường bị overfitting đối với dữ liệu lớn ?\n",
        "\n",
        "C. Các mô hình deep learning có chi phí huấn luyện tốn kém hơn so với machine learning.\n",
        "\n",
        "D. Do kiến trúc của mô hình Machine Learning bao gồm nhiều layers xếp chồng.\n",
        "\n",
        "\n",
        "2) Ý nghĩa của hàm loss function trong mạng neural network là gì ?\n",
        "\n",
        "A. Là hàm số đánh giá độ chính xác của mô hình.\n",
        "\n",
        "**B. Mục tiêu của quá trình huấn luyện là tối thiểu hóa hàm loss function bằng thuật toán gradient descent. Giá trị của hàm số này giúp đo lường mức độ khớp của dự báo từ mô hình trên dữ liệu huấn luyện.**\n",
        "\n",
        "C. Khi loss function giảm thì luôn đảm bảo độ chính xác của mô hình tăng.\n",
        "\n",
        "D. Là hàm số cần tối đa hóa trong quá trình huấn luyện.\n",
        "\n",
        "\n",
        "3) Khi huấn luyện trên các bộ dữ liệu bigdata thì chúng ta nên sử dụng phương pháp nào ?\n",
        "\n",
        "A) Sử dụng gradient descent trên toàn bộ dữ liệu.\n",
        "\n",
        "B) Sử dụng stochastic gradient descent trên từng điểm dữ liệu.\n",
        "\n",
        "**C) Mini-batch gradient descent huấn luyện mô hình trên từng tập dữ liệu con có kích thước nhỏ hơn memory CPU/GPU.**\n",
        "\n",
        "D) Có thể sử dụng stochastic gradient descent hoặc mini-batch gradient descent.\n",
        "\n",
        "\n",
        "4) Quá trình feed forward và backpropagation thực hiện những gì ?\n",
        "\n",
        "**A) feed forward tính toán output và loss function, backpropagation tính đạo hàm trên từng layer và cập nhật trọng số.**\n",
        "\n",
        "B) feed forward cập nhật trọng số cho mô hình, backpropagation tính toán output và loss function.\n",
        "\n",
        "C) feed forward tính ra output của mô hình, backpropagation tính toán loss function\n",
        "\n",
        "D) feed forward được thực hiện sau backpropagation.\n",
        "\n",
        "5) Tác dụng của batch normalization là gì ?\n",
        "\n",
        "A) Loại bỏ một tỷ lệ ngẫu nhiên số lượng units tại mỗi layer để tạo thành nhiều kiến trúc kết hợp ngẫu nhiên.\n",
        "\n",
        "B) Tìm ra các tham số phân phối là trung bình và phương sai trên từng mini-batch.\n",
        "\n",
        "C) Đồng nhất phân phối xác suất của $z^{[l]}$ trên mỗi layer $l$.\n",
        "\n",
        "**D) Giảm thiểu ảnh hưởng của input distribution shift nhằm giúp huấn luyện loss function nhanh và ổn định hơn.**"
      ],
      "metadata": {
        "id": "PDDUcokDmyX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành\n",
        "\n",
        "Xuất phát từ mô hình tốt nhất của bạn xây dựng được đối với bài toán phân loại income classification tại bài trước. Bạn hãy thực hiện một số thử nghiệm sau:\n",
        "\n",
        "6) Thay đổi hàm loss function, batch size và optimizer.\n",
        "\n",
        "7) Thử nghiệm thêm các layers mà bạn đã học được trong bài này vào kiến trúc của mình.\n",
        "\n",
        "8) Thay đổi các khởi tạo trọng số theo các phân phối khác nhau và đánh giá độ chính xác của kết quả huấn luyện.\n",
        "\n",
        "9) Thiết lập không gian search và tự động hóa tìm kiếm kiến trúc tốt nhất trên optuna.\n",
        "\n",
        "10) Deploy model sử dụng flask ap. Tham khảo [Flaskapp tutorial](https://drive.google.com/file/d/1AZNtzrmnhJ-OBgijWoaAqXbPhJ6xL0Po/view?usp=sharing)."
      ],
      "metadata": {
        "id": "zYoLCUgcm1Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries and dataset"
      ],
      "metadata": {
        "id": "3cKC_XpW_oFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.utils.data as td"
      ],
      "metadata": {
        "id": "muKJjYIzTDWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Kaggle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gur5KZbmZ21f",
        "outputId": "a3907dd7-50e2-40f0-fe0b-05e3bcde82e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "XKq6j_BIaB2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train.csv', header = 0)\n",
        "data = data.drop(['ID'], axis = 1)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "L8lxTWSYai5x",
        "outputId": "e7c24738-427e-4d09-fd96-cfad958905e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d60da7f4-790b-41bb-862f-f9b13e9c4973\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>work_type</th>\n",
              "      <th>final_weight</th>\n",
              "      <th>education</th>\n",
              "      <th>total_education_yrs</th>\n",
              "      <th>marital_state</th>\n",
              "      <th>job</th>\n",
              "      <th>status</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>nationality</th>\n",
              "      <th>target_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>Private</td>\n",
              "      <td>175925</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>113601</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>112137</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>South</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>153078</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>Private</td>\n",
              "      <td>375515</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d60da7f4-790b-41bb-862f-f9b13e9c4973')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d60da7f4-790b-41bb-862f-f9b13e9c4973 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d60da7f4-790b-41bb-862f-f9b13e9c4973');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age work_type  final_weight  ... hrs_per_week  nationality target_income\n",
              "0   45   Private        175925  ...           40           US             0\n",
              "1   23   Private        113601  ...           30           US             0\n",
              "2   22   Private        112137  ...           20        South             0\n",
              "3   27   Private        153078  ...           40           US             0\n",
              "4   18   Private        375515  ...           20           US             0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "vwO_EC9H_s2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.replace('?', np.nan)\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O0ruTkiasCV",
        "outputId": "cf870ef7-7be5-4569-b9b6-51a5b15b278c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 15 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   age                  25000 non-null  int64 \n",
            " 1   work_type            23621 non-null  object\n",
            " 2   final_weight         25000 non-null  int64 \n",
            " 3   education            25000 non-null  object\n",
            " 4   total_education_yrs  25000 non-null  int64 \n",
            " 5   marital_state        25000 non-null  object\n",
            " 6   job                  23616 non-null  object\n",
            " 7   status               25000 non-null  object\n",
            " 8   ethnicity            25000 non-null  object\n",
            " 9   sex                  25000 non-null  object\n",
            " 10  capital_gain         25000 non-null  int64 \n",
            " 11  capital_loss         25000 non-null  int64 \n",
            " 12  hrs_per_week         25000 non-null  int64 \n",
            " 13  nationality          24557 non-null  object\n",
            " 14  target_income        25000 non-null  int64 \n",
            "dtypes: int64(7), object(8)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRHxHqIsbC99",
        "outputId": "c9ca9a8e-723c-40e2-d99a-aa81c19e1e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 15 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   age                  25000 non-null  int64 \n",
            " 1   work_type            25000 non-null  object\n",
            " 2   final_weight         25000 non-null  int64 \n",
            " 3   education            25000 non-null  object\n",
            " 4   total_education_yrs  25000 non-null  int64 \n",
            " 5   marital_state        25000 non-null  object\n",
            " 6   job                  25000 non-null  object\n",
            " 7   status               25000 non-null  object\n",
            " 8   ethnicity            25000 non-null  object\n",
            " 9   sex                  25000 non-null  object\n",
            " 10  capital_gain         25000 non-null  int64 \n",
            " 11  capital_loss         25000 non-null  int64 \n",
            " 12  hrs_per_week         25000 non-null  int64 \n",
            " 13  nationality          25000 non-null  object\n",
            " 14  target_income        25000 non-null  int64 \n",
            "dtypes: int64(7), object(8)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoder for category attributes\n",
        "def encode_and_bind(dataframe, features_to_encode):\n",
        "  dummies = pd.get_dummies(dataframe[features_to_encode])\n",
        "  result = pd.concat([data, dummies], axis = 1)\n",
        "  result = result.drop([features_to_encode], axis = 1)\n",
        "  return result\n",
        "\n",
        "features_to_encode = ['work_type', 'education', 'marital_state', 'job', 'status', 'ethnicity', 'sex', 'nationality']\n",
        "for feature in features_to_encode:\n",
        "    data = encode_and_bind(data, feature)\n",
        "\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGQ7O0rqbLiI",
        "outputId": "3554194d-8972-42af-fe9d-667042625cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Columns: 106 entries, age to Yugoslavia\n",
            "dtypes: int64(7), uint8(99)\n",
            "memory usage: 3.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_copy = data.copy()\n",
        "labels = data['target_income']\n",
        "data_copy.pop('target_income')\n",
        "data_X = data_copy\n",
        "data_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "C4_ST4LzeNiB",
        "outputId": "d2bbb149-6f68-4aad-f8c8-f29b4cffbcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-09e90750-0b1a-40e0-9119-7da3776eae1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>final_weight</th>\n",
              "      <th>total_education_yrs</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hrs_per_week</th>\n",
              "      <th>Federal-gov</th>\n",
              "      <th>Local-gov</th>\n",
              "      <th>Never-worked</th>\n",
              "      <th>Private</th>\n",
              "      <th>Self-emp-inc</th>\n",
              "      <th>Self-emp-not-inc</th>\n",
              "      <th>State-gov</th>\n",
              "      <th>Without-pay</th>\n",
              "      <th>10th</th>\n",
              "      <th>11th</th>\n",
              "      <th>12th</th>\n",
              "      <th>1st-4th</th>\n",
              "      <th>5th-6th</th>\n",
              "      <th>7th-8th</th>\n",
              "      <th>9th</th>\n",
              "      <th>Assoc-acdm</th>\n",
              "      <th>Assoc-voc</th>\n",
              "      <th>Bachelors</th>\n",
              "      <th>Doctorate</th>\n",
              "      <th>HS-grad</th>\n",
              "      <th>Masters</th>\n",
              "      <th>Preschool</th>\n",
              "      <th>Prof-school</th>\n",
              "      <th>Some-college</th>\n",
              "      <th>Divorced</th>\n",
              "      <th>Married-AF-spouse</th>\n",
              "      <th>Married-civ-spouse</th>\n",
              "      <th>Married-spouse-absent</th>\n",
              "      <th>Never-married</th>\n",
              "      <th>Separated</th>\n",
              "      <th>Widowed</th>\n",
              "      <th>Adm-clerical</th>\n",
              "      <th>Armed-Forces</th>\n",
              "      <th>Craft-repair</th>\n",
              "      <th>...</th>\n",
              "      <th>Canada</th>\n",
              "      <th>China</th>\n",
              "      <th>Columbia</th>\n",
              "      <th>Cuba</th>\n",
              "      <th>Dominican-Republic</th>\n",
              "      <th>Ecuador</th>\n",
              "      <th>El-Salvador</th>\n",
              "      <th>England</th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Greece</th>\n",
              "      <th>Guatemala</th>\n",
              "      <th>Haiti</th>\n",
              "      <th>Holand-Netherlands</th>\n",
              "      <th>Honduras</th>\n",
              "      <th>Hong</th>\n",
              "      <th>Hungary</th>\n",
              "      <th>India</th>\n",
              "      <th>Iran</th>\n",
              "      <th>Ireland</th>\n",
              "      <th>Italy</th>\n",
              "      <th>Jamaica</th>\n",
              "      <th>Japan</th>\n",
              "      <th>Laos</th>\n",
              "      <th>Mexico</th>\n",
              "      <th>Nicaragua</th>\n",
              "      <th>Outlying-US(Guam-USVI-etc)</th>\n",
              "      <th>Peru</th>\n",
              "      <th>Philippines</th>\n",
              "      <th>Poland</th>\n",
              "      <th>Portugal</th>\n",
              "      <th>Puerto-Rico</th>\n",
              "      <th>Scotland</th>\n",
              "      <th>South</th>\n",
              "      <th>Taiwan</th>\n",
              "      <th>Thailand</th>\n",
              "      <th>Trinadad&amp;Tobago</th>\n",
              "      <th>US</th>\n",
              "      <th>Vietnam</th>\n",
              "      <th>Yugoslavia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>175925</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>113601</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>112137</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>153078</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>375515</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>47</td>\n",
              "      <td>188386</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>23</td>\n",
              "      <td>71864</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24</td>\n",
              "      <td>395297</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>44</td>\n",
              "      <td>138975</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>42</td>\n",
              "      <td>167678</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 105 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09e90750-0b1a-40e0-9119-7da3776eae1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09e90750-0b1a-40e0-9119-7da3776eae1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09e90750-0b1a-40e0-9119-7da3776eae1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       age  final_weight  total_education_yrs  ...  US  Vietnam  Yugoslavia\n",
              "0       45        175925                    9  ...   1        0           0\n",
              "1       23        113601                   10  ...   1        0           0\n",
              "2       22        112137                   10  ...   0        0           0\n",
              "3       27        153078                   15  ...   1        0           0\n",
              "4       18        375515                    7  ...   1        0           0\n",
              "...    ...           ...                  ...  ...  ..      ...         ...\n",
              "24995   47        188386                   13  ...   1        0           0\n",
              "24996   23         71864                   10  ...   1        0           0\n",
              "24997   24        395297                   10  ...   1        0           0\n",
              "24998   44        138975                    9  ...   1        0           0\n",
              "24999   42        167678                    7  ...   0        0           0\n",
              "\n",
              "[25000 rows x 105 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train test split"
      ],
      "metadata": {
        "id": "VmMjPxGM_yPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels.values"
      ],
      "metadata": {
        "id": "6Wh2G9-pe8Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_X.values, labels, test_size = 0.3, stratify = data['target_income'], random_state = 0)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17pr1SoP90BN",
        "outputId": "559b73c0-8c16-4530-d044-37beeceaf0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17500, 105) (17500,)\n",
            "(7500, 105) (7500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "UwkPF1yhbRz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optuna tuning"
      ],
      "metadata": {
        "id": "ysHlyoLt_4R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qJAeX0OcG14",
        "outputId": "3087cfa7-3061-4fbc-f8d0-a7a69d2a819c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 42.1 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=a78a5a563022f4177070445a99734ec1d48dd05645468997a7cb8e91ff8ddd6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ICTkf5f0cKNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddfV1yITcVBo",
        "outputId": "7c192cfb-9437-4bda-ea0f-ec3da8845e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3a9c4cceb0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = torch.Tensor(X_train).float()\n",
        "train_y = torch.Tensor(y_train).view(-1, 1).float()\n",
        "\n",
        "train_ds = td.TensorDataset(train_X, train_y)\n",
        "train_loader = td.DataLoader(train_ds, batch_size = 32, shuffle = True, num_workers = 1)\n",
        "\n",
        "test_X = torch.Tensor(X_test).float()\n",
        "test_y = torch.Tensor(y_test).view(-1, 1).float()\n",
        "test_ds = td.TensorDataset(test_X, test_y)\n",
        "test_loader = td.DataLoader(test_ds, batch_size = 32, shuffle = False, num_workers = 1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36GmK-nFcYMX",
        "outputId": "e1d9dc93-417b-40db-ebed-685f180239cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "  n_layers = trial.suggest_int('n_layers', 2, 7)\n",
        "  layers = []\n",
        "\n",
        "  in_features = len(features)\n",
        "  for i in range(n_layers):\n",
        "    out_features = trial.suggest_int('u_units_l{}'.format(i), 4, 128)\n",
        "    layers.append(nn.Linear(in_features, out_features))\n",
        "    layers.append(nn.Sigmoid())\n",
        "    p = trial.suggest_float('dropout_l{}'.format(i), 0.2, 0.7)\n",
        "    layers.append(nn.Dropout(p))\n",
        "\n",
        "    in_features = out_features\n",
        "\n",
        "  layers.append(nn.Linear(in_features, 1))\n",
        "  layers.append(nn.Sigmoid())\n",
        "\n",
        "  return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "monrAdIydXC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCHSIZE = 32\n",
        "EPOCHS = 40\n",
        "LOG_INTERVAL = 15\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 400\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 200\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "    loss_criteria = nn.BCELoss()\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            # loss = F.nll_loss(output, target)\n",
        "            loss = loss_criteria(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(test_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = torch.tensor(output.data>=0.5).float()\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(test_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "_AGEUCSNhCi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = data_X.columns.tolist()"
      ],
      "metadata": {
        "id": "XjPROU5fiXHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=150, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGHPfE3uiLvv",
        "outputId": "b33bec0f-b58e-4c06-8953-34044839c48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-02-20 01:42:51,105]\u001b[0m A new study created in memory with name: no-name-d51094a2-d1fb-450a-83ab-bcf18f93db3b\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:44:20,547]\u001b[0m Trial 0 finished with value: 0.75921875 and parameters: {'n_layers': 7, 'u_units_l0': 12, 'dropout_l0': 0.22074522868484459, 'u_units_l1': 33, 'dropout_l1': 0.3427439436391131, 'u_units_l2': 77, 'dropout_l2': 0.35845989276477497, 'u_units_l3': 8, 'dropout_l3': 0.2548517803293576, 'u_units_l4': 118, 'dropout_l4': 0.4326469781273068, 'u_units_l5': 110, 'dropout_l5': 0.20205860803479786, 'u_units_l6': 23, 'dropout_l6': 0.6744007039013558, 'optimizer': 'SGD', 'lr': 0.0002268741030941148}. Best is trial 0 with value: 0.75921875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:45:57,254]\u001b[0m Trial 1 finished with value: 0.85453125 and parameters: {'n_layers': 3, 'u_units_l0': 112, 'dropout_l0': 0.41695631912883246, 'u_units_l1': 84, 'dropout_l1': 0.46921903796103864, 'u_units_l2': 39, 'dropout_l2': 0.6688990914571771, 'optimizer': 'Adam', 'lr': 0.0022475564865183256}. Best is trial 1 with value: 0.85453125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:47:36,612]\u001b[0m Trial 2 finished with value: 0.85609375 and parameters: {'n_layers': 5, 'u_units_l0': 68, 'dropout_l0': 0.21997119253681757, 'u_units_l1': 43, 'dropout_l1': 0.5625327544315595, 'u_units_l2': 94, 'dropout_l2': 0.5009879669421431, 'u_units_l3': 87, 'dropout_l3': 0.33754065546284195, 'u_units_l4': 76, 'dropout_l4': 0.4490565092532711, 'optimizer': 'Adam', 'lr': 0.0012555978637793705}. Best is trial 2 with value: 0.85609375.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:49:13,943]\u001b[0m Trial 3 finished with value: 0.8559375 and parameters: {'n_layers': 5, 'u_units_l0': 123, 'dropout_l0': 0.39026234272513893, 'u_units_l1': 57, 'dropout_l1': 0.28078896199942655, 'u_units_l2': 93, 'dropout_l2': 0.3256192000725425, 'u_units_l3': 121, 'dropout_l3': 0.6164558821371711, 'u_units_l4': 120, 'dropout_l4': 0.20977558083630404, 'optimizer': 'Adam', 'lr': 0.004769184994745383}. Best is trial 2 with value: 0.85609375.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:29,085]\u001b[0m Trial 4 finished with value: 0.75921875 and parameters: {'n_layers': 4, 'u_units_l0': 105, 'dropout_l0': 0.3140887299905189, 'u_units_l1': 87, 'dropout_l1': 0.6862867157685277, 'u_units_l2': 18, 'dropout_l2': 0.5384077109202294, 'u_units_l3': 96, 'dropout_l3': 0.5299891466562464, 'optimizer': 'SGD', 'lr': 4.590102814884069e-05}. Best is trial 2 with value: 0.85609375.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:31,518]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:33,633]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:35,833]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:38,071]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:40,409]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:42,379]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:44,760]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:47,412]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:49,621]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:52,093]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:54,364]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:50:56,902]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:52:21,308]\u001b[0m Trial 17 finished with value: 0.85515625 and parameters: {'n_layers': 3, 'u_units_l0': 128, 'dropout_l0': 0.3410871212887592, 'u_units_l1': 62, 'dropout_l1': 0.6250820042878609, 'u_units_l2': 127, 'dropout_l2': 0.4570045387811451, 'optimizer': 'Adam', 'lr': 0.0022402663223874742}. Best is trial 2 with value: 0.85609375.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:52:33,778]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:52:36,095]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\u001b[32m[I 2022-02-20 01:53:49,171]\u001b[0m Trial 20 finished with value: 0.858125 and parameters: {'n_layers': 2, 'u_units_l0': 48, 'dropout_l0': 0.2575208064971408, 'u_units_l1': 54, 'dropout_l1': 0.30592960151814863, 'optimizer': 'Adam', 'lr': 0.0015827071774023975}. Best is trial 20 with value: 0.858125.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  21\n",
            "  Number of pruned trials:  14\n",
            "  Number of complete trials:  7\n",
            "Best trial:\n",
            "  Value:  0.858125\n",
            "  Params: \n",
            "    n_layers: 2\n",
            "    u_units_l0: 48\n",
            "    dropout_l0: 0.2575208064971408\n",
            "    u_units_l1: 54\n",
            "    dropout_l1: 0.30592960151814863\n",
            "    optimizer: Adam\n",
            "    lr: 0.0015827071774023975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model"
      ],
      "metadata": {
        "id": "N7GqrOlz__zU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model(trial)"
      ],
      "metadata": {
        "id": "89ftzNv_iR_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_criteria = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = trial.params['lr'])\n",
        "optimizer.zero_grad()\n",
        "\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "epochs = 40"
      ],
      "metadata": {
        "id": "p-CVBWUU3mEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    '''\n",
        "    Train model through data loader and optimizer\n",
        "    Args:\n",
        "      model: model to train\n",
        "      data_loader: data loader to manage batch loading\n",
        "      optimizer: control update gradient descent\n",
        "    '''\n",
        "    # enable train mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        # reset optimizer into zero\n",
        "        optimizer.zero_grad()\n",
        "        # feed forward to compute output and loss\n",
        "        out = model(data)\n",
        "        loss = loss_criteria(out, target)\n",
        "        # accumulate loss\n",
        "        train_loss += loss.item()\n",
        "        # compute gradient descent\n",
        "        loss.backward()\n",
        "        # update into weight\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "            "
      ],
      "metadata": {
        "id": "LG2Y5MCQ39nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader):\n",
        "  # Switch the model to evaluation mode\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    batch_count = 0\n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "      batch_count += 1\n",
        "      data, target = tensor\n",
        "      # Get the predictions\n",
        "      out = model(data)\n",
        "      # Calculate the loss\n",
        "      test_loss += loss_criteria(out, target).item()\n",
        "      # Calculate the accuracy\n",
        "      # _, predicted = torch.max(out.data, 1)\n",
        "      predicted = out.data > 0.5\n",
        "      correct += torch.sum(target==predicted).item()\n",
        "\n",
        "  # Calculate the average loss and total accuarcy for this epoch\n",
        "  avg_loss = test_loss / batch_count\n",
        "  print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "  return avg_loss"
      ],
      "metadata": {
        "id": "z8xzUivN5Gps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training through epoch\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, test_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-13GO1D4CAj",
        "outputId": "c27bbd45-5eaf-4258-b78e-a67d6dc1d803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 0.285559\n",
            "Validation set: Average loss: 0.316554, Accuracy: 6449/7500 (86%)\n",
            "\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.286198\n",
            "Validation set: Average loss: 0.314157, Accuracy: 6448/7500 (86%)\n",
            "\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.284789\n",
            "Validation set: Average loss: 0.316271, Accuracy: 6437/7500 (86%)\n",
            "\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.286365\n",
            "Validation set: Average loss: 0.315783, Accuracy: 6442/7500 (86%)\n",
            "\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.283224\n",
            "Validation set: Average loss: 0.316776, Accuracy: 6441/7500 (86%)\n",
            "\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.283643\n",
            "Validation set: Average loss: 0.317750, Accuracy: 6435/7500 (86%)\n",
            "\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.284083\n",
            "Validation set: Average loss: 0.318052, Accuracy: 6437/7500 (86%)\n",
            "\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.281116\n",
            "Validation set: Average loss: 0.318582, Accuracy: 6435/7500 (86%)\n",
            "\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.283331\n",
            "Validation set: Average loss: 0.318718, Accuracy: 6432/7500 (86%)\n",
            "\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.281550\n",
            "Validation set: Average loss: 0.317744, Accuracy: 6437/7500 (86%)\n",
            "\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.282411\n",
            "Validation set: Average loss: 0.317781, Accuracy: 6435/7500 (86%)\n",
            "\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.281188\n",
            "Validation set: Average loss: 0.317192, Accuracy: 6442/7500 (86%)\n",
            "\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.284723\n",
            "Validation set: Average loss: 0.320390, Accuracy: 6440/7500 (86%)\n",
            "\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.280016\n",
            "Validation set: Average loss: 0.318907, Accuracy: 6438/7500 (86%)\n",
            "\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.279313\n",
            "Validation set: Average loss: 0.321617, Accuracy: 6434/7500 (86%)\n",
            "\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.279008\n",
            "Validation set: Average loss: 0.318719, Accuracy: 6430/7500 (86%)\n",
            "\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.276890\n",
            "Validation set: Average loss: 0.321380, Accuracy: 6432/7500 (86%)\n",
            "\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.278633\n",
            "Validation set: Average loss: 0.320534, Accuracy: 6440/7500 (86%)\n",
            "\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.276962\n",
            "Validation set: Average loss: 0.318777, Accuracy: 6428/7500 (86%)\n",
            "\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.274552\n",
            "Validation set: Average loss: 0.321055, Accuracy: 6435/7500 (86%)\n",
            "\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.276448\n",
            "Validation set: Average loss: 0.323538, Accuracy: 6430/7500 (86%)\n",
            "\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.278051\n",
            "Validation set: Average loss: 0.320075, Accuracy: 6436/7500 (86%)\n",
            "\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.276968\n",
            "Validation set: Average loss: 0.319421, Accuracy: 6435/7500 (86%)\n",
            "\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.274849\n",
            "Validation set: Average loss: 0.324022, Accuracy: 6433/7500 (86%)\n",
            "\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.275921\n",
            "Validation set: Average loss: 0.322072, Accuracy: 6431/7500 (86%)\n",
            "\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.276828\n",
            "Validation set: Average loss: 0.321960, Accuracy: 6431/7500 (86%)\n",
            "\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.274233\n",
            "Validation set: Average loss: 0.327372, Accuracy: 6432/7500 (86%)\n",
            "\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.275255\n",
            "Validation set: Average loss: 0.322268, Accuracy: 6422/7500 (86%)\n",
            "\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.274964\n",
            "Validation set: Average loss: 0.324648, Accuracy: 6420/7500 (86%)\n",
            "\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.275843\n",
            "Validation set: Average loss: 0.320544, Accuracy: 6416/7500 (86%)\n",
            "\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.273550\n",
            "Validation set: Average loss: 0.323073, Accuracy: 6423/7500 (86%)\n",
            "\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.274263\n",
            "Validation set: Average loss: 0.323827, Accuracy: 6429/7500 (86%)\n",
            "\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.274482\n",
            "Validation set: Average loss: 0.322220, Accuracy: 6409/7500 (85%)\n",
            "\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.273632\n",
            "Validation set: Average loss: 0.324625, Accuracy: 6423/7500 (86%)\n",
            "\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.274520\n",
            "Validation set: Average loss: 0.321939, Accuracy: 6426/7500 (86%)\n",
            "\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.271321\n",
            "Validation set: Average loss: 0.323226, Accuracy: 6426/7500 (86%)\n",
            "\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.272416\n",
            "Validation set: Average loss: 0.324932, Accuracy: 6419/7500 (86%)\n",
            "\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.271326\n",
            "Validation set: Average loss: 0.326125, Accuracy: 6422/7500 (86%)\n",
            "\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.273699\n",
            "Validation set: Average loss: 0.324514, Accuracy: 6411/7500 (85%)\n",
            "\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.272719\n",
            "Validation set: Average loss: 0.324657, Accuracy: 6429/7500 (86%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "yLkCJDCNAQcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_test, predictions):\n",
        "  print('ACCURACY_SCORE: ', accuracy_score(y_test, predictions))\n",
        "  print('F1_SCORE: ', f1_score(y_test, predictions))\n",
        "  print('CONFUSION MATRIX: \\n', confusion_matrix(y_test, predictions))\n",
        "  print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "v6Q5aIsU9_RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _evaluate(model, x_test):\n",
        "  model.eval()\n",
        "  x = torch.Tensor(x_test).float()\n",
        "  predictions = [1 if i>0.5 else 0 for i in model(x).data]\n",
        "  predictions = torch.tensor(predictions)\n",
        "  print('Evaluation on test dataset')\n",
        "  get_metrics(y_test, predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  classes=['0','1']\n",
        "  cm = confusion_matrix(y_test, predictions.numpy())\n",
        "  plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(2)\n",
        "  plt.xticks(tick_marks, classes, rotation=85)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Actual\")\n",
        "  plt.show()\n",
        "\n",
        "_evaluate(model, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "pOvXYUyJ4G16",
        "outputId": "d1d61a55-a9b7-433a-8c5a-e6406460c519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on test dataset\n",
            "ACCURACY_SCORE:  0.8572\n",
            "F1_SCORE:  0.6652078774617067\n",
            "CONFUSION MATRIX: \n",
            " [[5365  339]\n",
            " [ 732 1064]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91      5704\n",
            "           1       0.76      0.59      0.67      1796\n",
            "\n",
            "    accuracy                           0.86      7500\n",
            "   macro avg       0.82      0.77      0.79      7500\n",
            "weighted avg       0.85      0.86      0.85      7500\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy model"
      ],
      "metadata": {
        "id": "CAyX4tk1Al5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to review and check for solutions"
      ],
      "metadata": {
        "id": "vD0GM2CkFgJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm save và load file\n",
        "import pickle\n",
        "def _save_pkl(path, obj):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "\n",
        "def _load_pkl(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    obj = pickle.load(f)\n",
        "  return obj"
      ],
      "metadata": {
        "id": "F98DnUeu9LpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "_save_pkl('model.pkl',  model)\n",
        "_save_pkl('scaler.pkl', scaler)"
      ],
      "metadata": {
        "id": "owOs3H6bDEO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = _load_pkl('knn.pkl')\n",
        "scaler = _load_pkl('scaler.pkl')"
      ],
      "metadata": {
        "id": "MtZPJOMGDNL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding numpy to json\n",
        "import json\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    '''\n",
        "    Encoding numpy into json\n",
        "    '''\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        if isinstance(obj, np.int32):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.int64):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.float32):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.float64):\n",
        "            return float(obj)\n",
        "        return json.JSONEncoder.default(self, obj)"
      ],
      "metadata": {
        "id": "V0s4ky6IDrik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from flask import Flask, request\n",
        "import flask\n",
        "import json\n",
        "\n",
        "# Khởi tạo model.\n",
        "global model \n",
        "model = None\n",
        "# Khởi tạo flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Khai báo các route 1 cho API\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "# Khai báo hàm xử lý dữ liệu.\n",
        "def _hello_world():\n",
        "  return \"Hello world\"\n",
        "\n",
        "# Khai báo các route 2 cho API\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "# Khai báo hàm xử lý dữ liệu.\n",
        "def _predict():\n",
        "  data = {\"success\": False}\n",
        "  request_body = request.json()\n",
        "  if request_body:\n",
        "    # Lấy sepal_length\n",
        "    sepal_length = request_body['sp_len']\n",
        "    # Lấy sepal_width\n",
        "    sepal_width = request_body['sp_wid']\n",
        "    # Lấy petal_length\n",
        "    petal_length = request_body['pen_len']\n",
        "    # Lấy petal_width\n",
        "    petal_width = request_body['pen_wid']\n",
        "    # Convert sang numpy array input\n",
        "    X_input = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
        "    # Dự báo nhãn và xác suất.\n",
        "    label = model.predict(X_input)\n",
        "    # Dự báo phân phối xác suất\n",
        "    dist_probs = model.predict_proba(X_input)\n",
        "    # Truyền vào data form response\n",
        "    data[\"probability\"] = dist_probs\n",
        "    data[\"success\"] = True\n",
        "    return json.dumps(data, ensure_ascii=False, cls=NumpyEncoder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"App run!\")\n",
        "  # Load model và scaler\n",
        "  model = _load_pkl('knn.pkl')\n",
        "  scaler = _load_pkl('scaler.pkl')\n",
        "  app.run(debug=False, host='localhost', threaded=False)"
      ],
      "metadata": {
        "id": "1ft_FSG0DvC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chưa thực hijen 6,7,8,10"
      ],
      "metadata": {
        "id": "JCJS0gvi6Z12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XqLpoZvz6eWv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}