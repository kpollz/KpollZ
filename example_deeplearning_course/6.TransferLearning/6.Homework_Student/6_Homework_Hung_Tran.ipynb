{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oII0r_lpubh"
      },
      "source": [
        "# I. Lý thuyết"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Ty0elJpzS9"
      },
      "source": [
        "1) Transfer Learning thường được thực hiện trên hai dữ liệu nguồn (huấn luyện mô hình nguồn) và dữ liệu đích (huấn luyện mô hình đích) thế nào ?\n",
        "\n",
        "\n",
        "**A. Dữ liệu nguồn và dữ liệu đích có sự liên quan tới nhau. Những đặc trưng trong dữ liệu đích xuất hiện ở những dữ liệu nguồn.**\n",
        "\n",
        "B. Dữ liệu nguồn có số lượng classes lớn hơn dữ liệu đích.\n",
        "\n",
        "C. Kích thước của dữ liệu nguồn rất nhỏ.\n",
        "\n",
        "D. Dữ liệu đích ít liên quan tới dữ liệu nguồn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHXvMCwaxlyf"
      },
      "source": [
        "2) Khi nào thì chúng ta nên thực hiện fine tuning trên toàn bộ các layers của mô hình đích ?\n",
        "\n",
        "**A. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước lớn.**\n",
        "\n",
        "B. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước nhỏ.\n",
        "\n",
        "C. Dữ liệu đích có kích thước nhỏ và dữ liệu mục tiêu có kích thước lớn.\n",
        "\n",
        "D. Cả hai dữ liệu đích và mục tiêu đều có kích thước nhỏ.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOweiRmVrNeB"
      },
      "source": [
        "3) Các phương pháp augmentation nào sẽ kết hợp nội dung từ hai ảnh lẫn nhau và tạo ra một nhãn mềm (_soft label_) cho ảnh?\n",
        "\n",
        "A. Rotation, Random Crop, MixUp\n",
        "\n",
        "B. Bright Constrast, Color Shift, Addition Noise\n",
        "\n",
        "**C. CutMix, MixUp**\n",
        "\n",
        "D. Flip, Information Loss \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_mh5GpdtA6y"
      },
      "source": [
        "4) Quá trình xây dựng một mô hình AI trong dự án là một chu trình Machine Learning Cycle kế hợp giữa huấn luyện và gán nhãn dữ liệu. Để tiết kiệm chi phí gán nhãn chúng ta nên sử dụng phương pháp nào ?\n",
        "\n",
        "A. Lấy mẫu ngẫu nhiên từ tập unlabeled dataset để thực hiện gán nhãn.\n",
        "\n",
        "**B. Sử dụng Active Learning để lựa chọn mẫu mang lại thông tin giúp cải thiện nhiều nhất cho hiệu suất mô hình.**\n",
        "\n",
        "C. Lựa chọn mô hình pretrained lớn nhất có thể.\n",
        "\n",
        "D. Chỉ lựa các dữ liệu có thông tin rõ ràng, có thể phân biệt được bởi con người."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVBcCa80uqaU"
      },
      "source": [
        "5) Mô hình lớn thường đạt độ chính xác cao nhưng không deploy được trên các thiết bị edge device, IoT,... Trong khi mô hình nhỏ có thể deploy được nhưng thường có độ chính xác thấp. Phương pháp nào có thể giúp mô hình nhỏ cải thiện được độ chính xác ? Có thể lựa chọn nhiều đáp án.\n",
        "\n",
        "A. Sử dụng active learning để lựa chọn các mẫu đại diện cho tổng thể để huấn luyện mô hình nhỏ.\n",
        "\n",
        "**B. Áp dụng augmentation để huấn luyện mô hình nhỏ.**\n",
        "\n",
        "**C. Fine tuning các layers của mô hình lớn sang mô hình nhỏ.**\n",
        "\n",
        "**D. Sử dụng knowledge distillation để chuyển giao tri thức từ mô hình lớn sang mô hình nhỏ.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLNVdWEupwu5"
      },
      "source": [
        "# II. Thực hành"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiNt8X4zxsvc"
      },
      "source": [
        "6) Từ bộ dữ liệu [Dog and Cat](https://www.kaggle.com/c/dog-vs-cat-classification/data), hãy huấn luyện một mô hình large (chẳng hạn ResNet50) bằng cách fine-tuning lại các trọng số từ pretrained model của bộ dữ liệu ImageNet. Huấn luyện trên 5 epochs.\n",
        "\n",
        "7) Hãy huấn luyện một mô hình small (chẳng hạn MobileNetV3) không sử dụng pretrained model trên 1 epochs.\n",
        "\n",
        "8) Sử dụng mô hình large làm teacher để cải thiện mô hình small là student theo phương pháp knowledge distillation.\n",
        "\n",
        "9) Áp dụng thêm các kĩ thuật data augmentation kết hợp ảnh khác nhãn để tạo thành nhãn mềm và huấn luyện cải thiện tiếp model student.\n",
        "\n",
        "10) Giả định cần huấn luyện tiếp mô hình student với các dữ liệu mới chưa được gán nhãn. Hãy xây dựng một kĩ thuật lựa chọn mẫu dựa trên đánh giá uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG5n5yw3d42v",
        "outputId": "c939d02f-bb43-4916-b5f9-a587a173f22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsMb77cXd49R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Kaggle/CatVsDog')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhBFsFEwz0GK"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Other libraries we'll use\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-kiHwNBaCy9"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import random\n",
        "import glob\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpmbPaOFZxof",
        "outputId": "fbb8b3d9-d99f-45c6-d55a-2578fb87fd05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSFdiI86ZxrV"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/Kaggle/CatVsDog/train/train'\n",
        "TEST_DIR = '/content/drive/MyDrive/Kaggle/CatVsDog/test/test'\n",
        "train_images = glob.glob(TRAIN_DIR + \"/**/**.jpg\")\n",
        "test_images = glob.glob(TEST_DIR + \"/**.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I0fEMAmZxuv",
        "outputId": "8d60f728-c748-41cf-cf97-f44167273697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dog Iamges:  12500\n",
            "Cat Iamges:  12500\n"
          ]
        }
      ],
      "source": [
        "dog_list = [img for img in train_images if img.split(\"/\")[-2] == 'dogs']\n",
        "cat_list = [img for img in train_images if img.split(\"/\")[-2] == 'cats']\n",
        "\n",
        "print('Dog Iamges: ', len(dog_list))\n",
        "print('Cat Iamges: ', len(cat_list))\n",
        "\n",
        "class_to_int = {'dogs': 0, 'cats': 1}\n",
        "int_to_class = {0: 'dogs', 1: 'cats'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HhhpznOc_oB"
      },
      "outputs": [],
      "source": [
        "def get_train_transform():\n",
        "    return T.Compose([\n",
        "        T.RandomHorizontalFlip(p=0.5), # Random flip with probability = 0.5\n",
        "        T.RandomRotation(15), # Random rotation with angle <= 15\n",
        "        # T.ColorJitter(brightness=.5, hue=.3), # Bright contrast\n",
        "        T.Resize((256, 256)),\n",
        "        T.RandomResizedCrop(224), # Random crop Image with shape 224\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)), # Normalize according to ImageNet distribution\n",
        "    ])\n",
        "    \n",
        "def get_val_transform():\n",
        "    return T.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P30-vqcAeSo4"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "class CatDogDataset(Dataset):\n",
        "    def __init__(self, imgs, class_to_int, mode = \"train\", \n",
        "                 transforms = None):\n",
        "        super().__init__()\n",
        "        self.imgs = imgs\n",
        "        self.class_to_int = class_to_int\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.imgs[idx]\n",
        "        if self.mode == \"train\" or self.mode == \"val\":\n",
        "            img = Image.open(image_name)\n",
        "            # img = img.resize((256, 256))\n",
        "            ### Preparing class label\n",
        "            label = self.class_to_int[image_name.split(\"/\")[-2]]\n",
        "            label = torch.tensor(label, dtype = torch.float32)\n",
        "            ### Apply Transforms on image\n",
        "            img = self.transforms(img)\n",
        "            return img, label\n",
        "        elif self.mode == \"test\":\n",
        "            img = Image.open(image_name)\n",
        "            # img = img.resize((256, 256))\n",
        "            ### Apply Transforms on image\n",
        "            img = self.transforms(img)\n",
        "            return img, image_name\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae2NiZO9gM_m"
      },
      "outputs": [],
      "source": [
        "train_imgs, val_imgs = train_test_split(train_images, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR9eWpjEgZtC"
      },
      "outputs": [],
      "source": [
        "train_dataset = CatDogDataset(train_imgs, class_to_int, mode = \"train\", \n",
        "                              transforms = get_train_transform())\n",
        "val_dataset = CatDogDataset(val_imgs, class_to_int, mode = \"val\", \n",
        "                            transforms = get_val_transform())\n",
        "test_dataset = CatDogDataset(test_images, class_to_int, mode = \"test\", \n",
        "                             transforms = get_val_transform())\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    num_workers = 2,\n",
        "    batch_size = 32,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    dataset = val_dataset,\n",
        "    num_workers = 2,\n",
        "    batch_size = 16,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_data_loader = DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    num_workers = 2,\n",
        "    batch_size = 1,\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1saOM5h357yi"
      },
      "source": [
        "## Train and eval function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTSDnm6ihTPz"
      },
      "outputs": [],
      "source": [
        "def accuracy(preds, trues):\n",
        "    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n",
        "    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n",
        "    acc = np.sum(acc) / len(preds)\n",
        "    return (acc * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-7D1EGkiD9q"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(train_data_loader, model, optimizer):\n",
        "    epoch_loss = []\n",
        "    epoch_acc = []\n",
        "    start_time = time.time()\n",
        "    # model.to(device)\n",
        "    model.train()\n",
        "    \n",
        "    for images, labels in train_data_loader:\n",
        "        \n",
        "        #Loading images and labels to device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
        "        \n",
        "        #Reseting Gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #Forward\n",
        "        preds = model(images)\n",
        "        \n",
        "        #Calculating Loss\n",
        "        _loss = criterion(preds, labels)\n",
        "        loss = _loss.item()\n",
        "        epoch_loss.append(loss)\n",
        "        \n",
        "        #Calculating Accuracy\n",
        "        acc = accuracy(preds, labels)\n",
        "        epoch_acc.append(acc)\n",
        "        \n",
        "        #Backward\n",
        "        _loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    ###Overall Epoch Results\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    \n",
        "    ###Acc and Loss\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "    epoch_acc = np.mean(epoch_acc)\n",
        "    \n",
        "    ###Storing results to logs\n",
        "    train_logs[\"loss\"].append(epoch_loss)\n",
        "    train_logs[\"accuracy\"].append(epoch_acc)\n",
        "    train_logs[\"time\"].append(total_time)\n",
        "        \n",
        "    return epoch_loss, epoch_acc, total_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0MSeYCtiSsD"
      },
      "outputs": [],
      "source": [
        "def val_one_epoch(val_data_loader, model, best_val_acc, model_name):\n",
        "    epoch_loss = []\n",
        "    epoch_acc = []\n",
        "    start_time = time.time()\n",
        "    # model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    for images, labels in val_data_loader:\n",
        "        \n",
        "        #Loading images and labels to device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n",
        "        \n",
        "        #Forward\n",
        "        preds = model(images)\n",
        "        \n",
        "        #Calculating Loss\n",
        "        _loss = criterion(preds, labels)\n",
        "        loss = _loss.item()\n",
        "        epoch_loss.append(loss)\n",
        "        \n",
        "        #Calculating Accuracy\n",
        "        acc = accuracy(preds, labels)\n",
        "        epoch_acc.append(acc)\n",
        "    \n",
        "    ###Overall Epoch Results\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    \n",
        "    ###Acc and Loss\n",
        "    epoch_loss = np.mean(epoch_loss)\n",
        "    epoch_acc = np.mean(epoch_acc)\n",
        "    \n",
        "    ###Storing results to logs\n",
        "    val_logs[\"loss\"].append(epoch_loss)\n",
        "    val_logs[\"accuracy\"].append(epoch_acc)\n",
        "    val_logs[\"time\"].append(total_time)\n",
        "    \n",
        "    ###Saving best model\n",
        "    if epoch_acc > best_val_acc:\n",
        "        best_val_acc = epoch_acc\n",
        "        torch.save(model.state_dict(),model_name+\"_best.pth\")\n",
        "        \n",
        "    return epoch_loss, epoch_acc, total_time, best_val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3C0y7Gjl7rZ"
      },
      "source": [
        "##Build my model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrP7XAwHiaRv"
      },
      "outputs": [],
      "source": [
        "class cnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cnn,self).__init__()\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=7, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(128,256, kernel_size=5, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "            )\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256,512, kernel_size=3, padding=0, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        \n",
        "        self.fc1 = nn.Linear(2048,1000)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(1000,1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcOkMZXl0Mno"
      },
      "source": [
        "To check output shape and number of parameters you have to use `summary` function of `torchsummary` package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZK3t2nNBFN-",
        "outputId": "3c1abea0-df80-4052-c09d-0bfc53b31ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 128, 109, 109]          18,944\n",
            "       BatchNorm2d-2        [-1, 128, 109, 109]             256\n",
            "              ReLU-3        [-1, 128, 109, 109]               0\n",
            "         MaxPool2d-4          [-1, 128, 54, 54]               0\n",
            "            Conv2d-5          [-1, 256, 25, 25]         819,456\n",
            "       BatchNorm2d-6          [-1, 256, 25, 25]             512\n",
            "              ReLU-7          [-1, 256, 25, 25]               0\n",
            "         MaxPool2d-8          [-1, 256, 12, 12]               0\n",
            "            Conv2d-9            [-1, 512, 5, 5]       1,180,160\n",
            "      BatchNorm2d-10            [-1, 512, 5, 5]           1,024\n",
            "             ReLU-11            [-1, 512, 5, 5]               0\n",
            "        MaxPool2d-12            [-1, 512, 2, 2]               0\n",
            "           Linear-13                 [-1, 1000]       2,049,000\n",
            "             ReLU-14                 [-1, 1000]               0\n",
            "           Linear-15                    [-1, 1]           1,001\n",
            "          Sigmoid-16                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 4,070,353\n",
            "Trainable params: 4,070,353\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 41.92\n",
            "Params size (MB): 15.53\n",
            "Estimated Total Size (MB): 58.02\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "model=cnn()\n",
        "model.to(device)\n",
        "summary(model, (3, 224, 224), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9hYyTboA-GX",
        "outputId": "0705b7eb-7a1e-4ecd-d953-a38005cd0c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cnn(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=1000, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM6Z88OsmW5y"
      },
      "outputs": [],
      "source": [
        "# Reset gradient\n",
        "model.zero_grad()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.33)\n",
        "\n",
        "#Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Logs - Helpful for plotting after training finishes\n",
        "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "\n",
        "# Loading model to device\n",
        "model.to(device)\n",
        "\n",
        "# No of epochs \n",
        "epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "J73ONQYcmdGh",
        "outputId": "3f82eb72-99c9-476a-9eba-90a31e08328b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-16bab7c9728f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m###Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Print Epoch Details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-0812890124ab>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_data_loader, model, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#Loading images and labels to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_val_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    ###Training\n",
        "    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nTraining\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    \n",
        "    ###Validation\n",
        "    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"mymodel\")\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nValidating\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgoDleOBif9q"
      },
      "source": [
        "##Restnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "68658954e8774f569c88b8c3a11e59d3",
            "66f63d4ccadd464e9b3e27c40990aedb",
            "fedd1b1f27ed402e939162e638abd742",
            "4d5242045a254bed80a5d22587dcb269",
            "2b909e9be3b546f7877ab67e24129e09",
            "a727d2a331b243f1b7d85409f01fa062",
            "3cf3f6789b4148b3a536617c3127e5ea",
            "d1f1b238a0fc432881b3e6ccef683c11",
            "492e5e1e2ac44cd488a6c6303f641572",
            "97469e2473754effb7fef3bdb090f19c",
            "260d6cd2611d4b4896b94fe66c6d9ace"
          ]
        },
        "id": "qXbqWo36ihSr",
        "outputId": "2a362c05-0799-4524-a359-1e6795064e03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68658954e8774f569c88b8c3a11e59d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torchvision.models import resnet50\n",
        "model = resnet50(pretrained = True)\n",
        "\n",
        "# Modifying Head - classifier\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 1, bias = True),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m54keavimrQ"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
        "\n",
        "#Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Logs - Helpful for plotting after training finishes\n",
        "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "\n",
        "# Loading model to device\n",
        "model.to(device)\n",
        "\n",
        "# No of epochs \n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyx0I_hdit2T",
        "outputId": "ca2b7ce2-db85-499b-99df-70fda3603d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training\n",
            "Epoch 1\n",
            "Loss : 0.7004\n",
            "Acc : 55.735\n",
            "Time : 13327.7685\n",
            "\n",
            "Validating\n",
            "Epoch 1\n",
            "Loss : 0.6627\n",
            "Acc : 62.48\n",
            "Time : 1010.0667\n"
          ]
        }
      ],
      "source": [
        "best_val_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    ###Training\n",
        "    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nTraining\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    \n",
        "    ###Validation\n",
        "    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"resnet50\")\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nValidating\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNUKraexbZ7N"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNWjyatutuRK"
      },
      "source": [
        "##Mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_yASV1gtwp8"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import mobilenet_v2\n",
        "model=mobilenet_v2()\n",
        "model.classifier._modules['1'] = nn.Sequential(\n",
        "    nn.Linear(1280, 1, bias = True),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_D_AFqOuFpO"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
        "\n",
        "#Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Logs - Helpful for plotting after training finishes\n",
        "train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n",
        "\n",
        "# Loading model to device\n",
        "model.to(device)\n",
        "\n",
        "# No of epochs \n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y39foSRuGVG"
      },
      "outputs": [],
      "source": [
        "best_val_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    ###Training\n",
        "    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nTraining\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    \n",
        "    ###Validation\n",
        "    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"mobilenet_v2\")\n",
        "    \n",
        "    #Print Epoch Details\n",
        "    print(\"\\nValidating\")\n",
        "    print(\"Epoch {}\".format(epoch+1))\n",
        "    print(\"Loss : {}\".format(round(loss, 4)))\n",
        "    print(\"Acc : {}\".format(round(acc, 4)))\n",
        "    print(\"Time : {}\".format(round(_time, 4)))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0scM1YPbZ9b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "6.Homework_Hung Tran.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "260d6cd2611d4b4896b94fe66c6d9ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b909e9be3b546f7877ab67e24129e09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf3f6789b4148b3a536617c3127e5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "492e5e1e2ac44cd488a6c6303f641572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d5242045a254bed80a5d22587dcb269": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97469e2473754effb7fef3bdb090f19c",
            "placeholder": "​",
            "style": "IPY_MODEL_260d6cd2611d4b4896b94fe66c6d9ace",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 141MB/s]"
          }
        },
        "66f63d4ccadd464e9b3e27c40990aedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a727d2a331b243f1b7d85409f01fa062",
            "placeholder": "​",
            "style": "IPY_MODEL_3cf3f6789b4148b3a536617c3127e5ea",
            "value": "100%"
          }
        },
        "68658954e8774f569c88b8c3a11e59d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66f63d4ccadd464e9b3e27c40990aedb",
              "IPY_MODEL_fedd1b1f27ed402e939162e638abd742",
              "IPY_MODEL_4d5242045a254bed80a5d22587dcb269"
            ],
            "layout": "IPY_MODEL_2b909e9be3b546f7877ab67e24129e09"
          }
        },
        "97469e2473754effb7fef3bdb090f19c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a727d2a331b243f1b7d85409f01fa062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f1b238a0fc432881b3e6ccef683c11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedd1b1f27ed402e939162e638abd742": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f1b238a0fc432881b3e6ccef683c11",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_492e5e1e2ac44cd488a6c6303f641572",
            "value": 102530333
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}