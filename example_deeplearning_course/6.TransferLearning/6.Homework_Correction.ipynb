{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6.Homework_Correction.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# I. Lý thuyết"],"metadata":{"id":"3oII0r_lpubh"}},{"cell_type":"markdown","source":["1) Transfer Learning thường được thực hiện trên hai dữ liệu nguồn (huấn luyện mô hình nguồn) và dữ liệu đích (huấn luyện mô hình đích) thế nào ?\n","\n","\n","A. Dữ liệu nguồn và dữ liệu đích có sự liên quan tới nhau. Những đặc trưng trong dữ liệu đích xuất hiện ở những dữ liệu nguồn.\n","\n","B. Dữ liệu nguồn có số lượng classes lớn hơn dữ liệu đích.\n","\n","C. Kích thước của dữ liệu nguồn rất nhỏ.\n","\n","D. Dữ liệu đích ít liên quan tới dữ liệu nguồn.\n","\n","ĐA: A\n"],"metadata":{"id":"l5Ty0elJpzS9"}},{"cell_type":"markdown","source":["2) Khi nào thì chúng ta nên thực hiện fine tuning trên toàn bộ các layers của mô hình đích ?\n","\n","A. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước lớn.\n","\n","B. Khi hai dữ liệu nguồn và đích có mức độ tương đồng cao và dữ liệu đích có kích thước nhỏ.\n","\n","C. Dữ liệu đích có kích thước nhỏ và dữ liệu nguồn có kích thước lớn.\n","\n","D. Cả hai dữ liệu đích và nguồn đều có kích thước nhỏ.\n","\n","\n","ĐA: A\n"],"metadata":{"id":"wHXvMCwaxlyf"}},{"cell_type":"markdown","source":["3) Các phương pháp augmentation nào sẽ kết hợp nội dung từ hai ảnh lẫn nhau và tạo ra một nhãn mềm (_soft label_) cho ảnh?\n","\n","A. Rotation, Random Crop, MixUp\n","\n","B. Bright Constrast, Color Shift, Addition Noise\n","\n","C. CutMix, MixUp\n","\n","D. Flip, Information Loss \n","\n","\n","ĐA: C\n"],"metadata":{"id":"NOweiRmVrNeB"}},{"cell_type":"markdown","source":["4) Quá trình xây dựng một mô hình AI trong dự án là một chu trình Machine Learning Cycle kế hợp giữa huấn luyện và gán nhãn dữ liệu. Để tiết kiệm chi phí gán nhãn chúng ta nên sử dụng phương pháp nào ?\n","\n","A. Lấy mẫu ngẫu nhiên từ tập unlabeled dataset để thực hiện gán nhãn.\n","\n","B. Sử dụng Active Learning để lựa chọn mẫu mang lại thông tin giúp cải thiện nhiều nhất cho hiệu suất mô hình.\n","\n","C. Lựa chọn mô hình pretrained lớn nhất có thể.\n","\n","D. Chỉ lựa các dữ liệu có thông tin rõ ràng, có thể phân biệt được bởi con người.\n","\n","\n","ĐA: B"],"metadata":{"id":"D_mh5GpdtA6y"}},{"cell_type":"markdown","source":["5) Mô hình lớn thường đạt độ chính xác cao nhưng không deploy được trên các thiết bị edge device, IoT,... Trong khi mô hình nhỏ có thể deploy được nhưng thường có độ chính xác thấp. Phương pháp nào có thể giúp mô hình nhỏ cải thiện được độ chính xác ? Có thể lựa chọn nhiều đáp án.\n","\n","A. Sử dụng active learning để lựa chọn các mẫu đại diện cho tổng thể để huấn luyện mô hình nhỏ.\n","\n","B. Áp dụng augmentation để huấn luyện mô hình nhỏ.\n","\n","C. Fine tuning các layers của mô hình lớn sang mô hình nhỏ.\n","\n","D. Sử dụng knowledge distillation để chuyển giao tri thức từ mô hình lớn sang mô hình nhỏ.\n","\n","ĐA: B, C, D"],"metadata":{"id":"aVBcCa80uqaU"}},{"cell_type":"markdown","source":["# II. Thực hành"],"metadata":{"id":"RLNVdWEupwu5"}},{"cell_type":"markdown","source":["# 6) Từ bộ dữ liệu [Dog and Cat](https://www.kaggle.com/c/dog-vs-cat-classification/data), hãy huấn luyện một mô hình large (chẳng hạn ResNet50) bằng cách fine-tuning lại các trọng số từ pretrained model của bộ dữ liệu ImageNet. Huấn luyện trên 5 epochs.\n"],"metadata":{"id":"j8-yIiHdbe7e"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount(\"/content/gdrive\")"],"metadata":{"id":"WE-TMbvrvNmb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"558421c8-6747-430e-91ee-b4c780291dd2","executionInfo":{"status":"ok","timestamp":1646547824958,"user_tz":-420,"elapsed":22611,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/Colab Notebooks/DeepLearning2/6.TransferLearning"],"metadata":{"id":"K7-5vtMhvWNC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ebf1e896-4b88-4444-c7f1-c419f9f888d2","executionInfo":{"status":"ok","timestamp":1646547882383,"user_tz":-420,"elapsed":1233,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/DeepLearning2/6.TransferLearning\n"]}]},{"cell_type":"code","source":["import os\n","import zipfile\n","import glob\n","import time\n","import pickle\n","import pprint\n","import math\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import PIL\n","\n","import numpy as np\n","import pandas as pd\n","import sklearn.model_selection\n","\n","import torch\n","import torch.nn as nn\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torch.utils.data\n","from torch.utils.data import Dataset, DataLoader\n","\n","import tqdm\n","import random\n","import torchvision.transforms as T\n","\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"PzDdOtEPvhSZ","executionInfo":{"status":"ok","timestamp":1646571075933,"user_tz":-420,"elapsed":1558,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"bVcc4Mm7vjXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"FJGsbr-qvk1O","outputId":"8074d16b-38bf-4a1b-89aa-748970a22dc0","executionInfo":{"status":"ok","timestamp":1646547895700,"user_tz":-420,"elapsed":11,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cuda'"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["TRAIN_DIR = '../data/dogvscat/train/train'\n","TEST_DIR = '../data/dogvscat/test/test'\n","train_images = glob.glob(TRAIN_DIR+\"/**/**.jpg\")\n","test_images = glob.glob(TEST_DIR+\"/**.jpg\")\n","print(len(train_images), len(test_images))"],"metadata":{"id":"XiScpgArvlgi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646549877408,"user_tz":-420,"elapsed":900,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"530fcab1-79d4-4c1b-9d3e-71c74b6b7eb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25000 8000\n"]}]},{"cell_type":"code","source":["dogs_list = [img for img in train_images if img.split(\"/\")[-2] == \"dogs\"]\n","cats_list = [img for img in train_images if img.split(\"/\")[-2] == \"cats\"]\n","\n","print(\"Dogs Images: \",len(dogs_list))\n","print(\"Cats Images: \",len(cats_list))\n","\n","class_to_int = {\"dogs\" : 0, \"cats\" : 1}\n","int_to_class = {0 : \"dogs\", 1 : \"cats\"}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-nol8e9vzT8","outputId":"b3cbefb3-eafd-46b8-aff3-9be3a8f6b0df","executionInfo":{"status":"ok","timestamp":1646549892359,"user_tz":-420,"elapsed":392,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dogs Images:  12500\n","Cats Images:  12500\n"]}]},{"cell_type":"code","source":["def get_train_transform():\n","    return T.Compose([\n","        T.RandomHorizontalFlip(p=0.5),\n","        T.RandomRotation(15),\n","        T.Resize((256, 256)),\n","        T.RandomResizedCrop(224),\n","        T.ToTensor(),\n","        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n","    ])\n","    \n","def get_val_transform():\n","    return T.Compose([\n","        T.Resize((224, 224)),\n","        T.ToTensor(),\n","        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n","    ])"],"metadata":{"id":"EMaKfrXGv4K2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","class CatDogDataset(Dataset):\n","    def __init__(self, imgs, class_to_int, mode = \"train\", \n","                 transforms = None):\n","        super().__init__()\n","        self.imgs = imgs\n","        self.class_to_int = class_to_int\n","        self.mode = mode\n","        self.transforms = transforms\n","    def __getitem__(self, idx):\n","        image_name = self.imgs[idx]\n","        if self.mode == \"train\" or self.mode == \"val\":\n","            img = Image.open(image_name)\n","            # img = img.resize((256, 256))\n","            ### Preparing class label\n","            label = self.class_to_int[image_name.split(\"/\")[-2]]\n","            label = torch.tensor(label, dtype = torch.float32)\n","            ### Apply Transforms on image\n","            img = self.transforms(img)\n","            return img, label\n","        elif self.mode == \"test\":\n","            img = Image.open(image_name)\n","            # img = img.resize((256, 256))\n","            ### Apply Transforms on image\n","            img = self.transforms(img)\n","            return img, image_name\n","    def __len__(self):\n","        return len(self.imgs)"],"metadata":{"id":"-XGLlVVev-5G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_imgs, val_imgs = train_test_split(train_images, test_size = 0.2)"],"metadata":{"id":"quMRnhBcwA3n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CatDogDataset(train_imgs, class_to_int, mode = \"train\", transforms = get_train_transform())\n","val_dataset = CatDogDataset(val_imgs, class_to_int, mode = \"val\", transforms = get_val_transform())\n","test_dataset = CatDogDataset(test_images, class_to_int, mode = \"test\", transforms = get_val_transform())\n","\n","train_data_loader = DataLoader(\n","    dataset = train_dataset,\n","    num_workers = 4,\n","    batch_size = 32,\n","    shuffle = True\n",")\n","\n","val_data_loader = DataLoader(\n","    dataset = val_dataset,\n","    num_workers = 4,\n","    batch_size = 32,\n","    shuffle = True\n",")\n","\n","test_data_loader = DataLoader(\n","    dataset = test_dataset,\n","    num_workers = 4,\n","    batch_size = 1,\n","    shuffle = False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bz_J4DeewDQT","outputId":"967fbdc6-9f0d-4a97-9587-11a5d4230598","executionInfo":{"status":"ok","timestamp":1646551563342,"user_tz":-420,"elapsed":347,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["def accuracy(preds, trues):\n","    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n","    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n","    acc = np.sum(acc) / len(preds)\n","    return (acc * 100)"],"metadata":{"id":"ikKcgDRYwFn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(train_data_loader):\n","    epoch_loss = []\n","    epoch_acc = []\n","    start_time = time.time()\n","\n","    model.train()\n","    \n","    for images, labels in train_data_loader:\n","        \n","        #Loading images and labels to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n","        \n","        #Reseting Gradients\n","        optimizer.zero_grad()\n","        \n","        #Forward\n","        preds = model(images)\n","        \n","        #Calculating Loss\n","        _loss = criterion(preds, labels)\n","        loss = _loss.item()\n","        epoch_loss.append(loss)\n","        \n","        #Calculating Accuracy\n","        acc = accuracy(preds, labels)\n","        epoch_acc.append(acc)\n","        \n","        #Backward\n","        _loss.backward()\n","        optimizer.step()\n","    \n","    ###Overall Epoch Results\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    \n","    ###Acc and Loss\n","    epoch_loss = np.mean(epoch_loss)\n","    epoch_acc = np.mean(epoch_acc)\n","    \n","    ###Storing results to logs\n","    train_logs[\"loss\"].append(epoch_loss)\n","    train_logs[\"accuracy\"].append(epoch_acc)\n","    train_logs[\"time\"].append(total_time)\n","        \n","    return epoch_loss, epoch_acc, total_time"],"metadata":{"id":"5mRhbnJQwew1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def val_one_epoch(val_data_loader, best_val_acc, model_name):\n","    epoch_loss = []\n","    epoch_acc = []\n","    start_time = time.time()\n","\n","    model.eval()\n","    \n","    for images, labels in val_data_loader:\n","        \n","        #Loading images and labels to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n","        \n","        #Forward\n","        preds = model(images)\n","        \n","        #Calculating Loss\n","        _loss = criterion(preds, labels)\n","        loss = _loss.item()\n","        epoch_loss.append(loss)\n","        \n","        #Calculating Accuracy\n","        acc = accuracy(preds, labels)\n","        epoch_acc.append(acc)\n","    \n","    ###Overall Epoch Results\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    \n","    ###Acc and Loss\n","    epoch_loss = np.mean(epoch_loss)\n","    epoch_acc = np.mean(epoch_acc)\n","    \n","    ###Storing results to logs\n","    val_logs[\"loss\"].append(epoch_loss)\n","    val_logs[\"accuracy\"].append(epoch_acc)\n","    val_logs[\"time\"].append(total_time)\n","    \n","    ###Saving best model\n","    if epoch_acc > best_val_acc:\n","        best_val_acc = epoch_acc\n","        torch.save(model.state_dict(),model_name+\"_best.pth\")\n","        \n","    return epoch_loss, epoch_acc, total_time, best_val_acc"],"metadata":{"id":"0fDtBzRfwiA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.models import resnet18\n","teacher = resnet18(pretrained = True)\n","\n","# Modifying Head - classifier\n","\n","teacher.fc = nn.Sequential(\n","    nn.Linear(512, 1, bias = True),\n","    nn.Sigmoid()\n",")"],"metadata":{"id":"p-qvQxjPwj2c","executionInfo":{"status":"ok","timestamp":1646571300504,"user_tz":-420,"elapsed":336,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Optimizer\n","optimizer = torch.optim.Adam(teacher.parameters(), lr = 0.0005)\n","\n","# Learning Rate Scheduler: Learning rate decay double time after each 3 epochs\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.5)\n","\n","#Loss Function\n","criterion = nn.BCELoss()\n","\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","\n","# Loading model to device\n","teacher.to(device)\n","\n","# No of epochs \n","epochs = 5"],"metadata":{"id":"SWiasiAmws89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch in range(epochs):\n","    \n","    ###Training\n","    loss, acc, _time = train_one_epoch(train_data_loader)\n","    \n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    \n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc, \"resnet50\")\n","    \n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aC-gXYUawuZf","outputId":"d769b26c-e953-43dd-f7ab-98feb15800dc","executionInfo":{"status":"ok","timestamp":1646555716616,"user_tz":-420,"elapsed":878288,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training\n","Epoch 1\n","Loss : 0.5719\n","Acc : 70.215\n","Time : 157.9923\n","\n","Validating\n","Epoch 1\n","Loss : 0.5523\n","Acc : 72.0143\n","Time : 26.4719\n","\n","Training\n","Epoch 2\n","Loss : 0.568\n","Acc : 70.41\n","Time : 148.2375\n","\n","Validating\n","Epoch 2\n","Loss : 0.5517\n","Acc : 71.9347\n","Time : 26.4737\n","\n","Training\n","Epoch 3\n","Loss : 0.5729\n","Acc : 70.445\n","Time : 147.3173\n","\n","Validating\n","Epoch 3\n","Loss : 0.5505\n","Acc : 72.1736\n","Time : 26.0032\n","\n","Training\n","Epoch 4\n","Loss : 0.5721\n","Acc : 70.37\n","Time : 146.2402\n","\n","Validating\n","Epoch 4\n","Loss : 0.5522\n","Acc : 72.0342\n","Time : 26.3556\n","\n","Training\n","Epoch 5\n","Loss : 0.5706\n","Acc : 70.65\n","Time : 146.664\n","\n","Validating\n","Epoch 5\n","Loss : 0.5514\n","Acc : 71.9944\n","Time : 25.9274\n"]}]},{"cell_type":"markdown","source":["# 7) Hãy huấn luyện một mô hình small (chẳng hạn MobileNetV3) không sử dụng pretrained model trên 1 epochs.\n"],"metadata":{"id":"ZBlBw1gXbk9s"}},{"cell_type":"code","source":["from torchvision.models import mobilenet_v3_small\n","# If do not use pretrain model do not set pretrained = True\n","model=mobilenet_v3_small()\n","model.classifier._modules['3'] = nn.Sequential(\n","    nn.Linear(1024, 1, bias = True),\n","    nn.Sigmoid()\n",")"],"metadata":{"id":"bkw2atffwwuQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n","\n","# Learning Rate Scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n","\n","#Loss Function\n","criterion = nn.BCELoss()\n","\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","\n","# Loading model to device\n","model.to(device)\n","\n","# No of epochs \n","epochs = 1"],"metadata":{"id":"n9zftJFNxN5i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch in range(epochs):\n","    \n","    ###Training\n","    loss, acc, _time = train_one_epoch(train_data_loader)\n","    \n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    \n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc, \"mobilenet_v2\")\n","    \n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"geFGqv7PxQj6","outputId":"66c00cb1-6e3c-4b3f-8ffa-3dfbcfcc2521","executionInfo":{"status":"ok","timestamp":1646553164520,"user_tz":-420,"elapsed":179614,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training\n","Epoch 1\n","Loss : 0.6341\n","Acc : 63.555\n","Time : 153.0898\n","\n","Validating\n","Epoch 1\n","Loss : 0.6618\n","Acc : 63.117\n","Time : 26.1131\n"]}]},{"cell_type":"markdown","source":["# 8) Coi ResNet18 là Teacher và MobileNet là Student. Huấn luyện mô hình Student theo phương pháp Knowledge Distillation. \n","\n","Theo đó chúng ta cần sử dụng các gợi ý là giá trị dự báo $\\mathbf{y}_t$ từ mô hình teacher để hướng dẫn giá trị dự báo $\\mathbf{y}_s$ từ mô hình student thông qua hàm mất mát $\\mathcal{L}_{distill}()$. Bên cạnh đó huấn luyện song song mô hình student với nhãn thực tế $\\mathbf{y}$ thông qua $\\mathcal{L}_{student}()$.\n","\n","Kết hợp tổng của student loss và distill loss theo công thức:\n","\n","$$\\mathcal{L}_{final}(\\mathbf{y}, \\mathbf{y}_s, \\mathbf{y}_t) = \\alpha \\mathcal{L}_{student}(\\mathbf{y}, \\mathbf{y}_s) + \\beta \\mathcal{L}_{distill}(T(\\mathbf{y}_t), T(\\mathbf{y}_s))$$\n"," "],"metadata":{"id":"QEKvA2p2Ios5"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","def loss_fn_kd(outputs, labels, teacher_outputs, alpha=0.1, temperature=3):\n","    \"\"\"\n","    Compute the knowledge-distillation (KD) loss given outputs, labels.\n","    \"Hyperparameters\": temperature and alpha\n","    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n","    and student expects the input tensor to be log probabilities!\n","    \"\"\"\n","    T = temperature\n","    student_loss = F.cross_entropy(outputs, labels)\n","    distill_loss = nn.KLDivLoss()(F.softmax(outputs/T, dim=1),\n","                             F.softmax(teacher_outputs/T, dim=1))\n","    KD_loss = student_loss * (1. - alpha) +  distill_loss * (alpha * T * T)\n","\n","    return KD_loss"],"metadata":{"id":"KMcUX4h3L5AP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch_kd(train_data_loader, teacher, student):\n","    '''\n","      train_data_loader: data loader of knowledge distillation\n","      teacher: teacher model that is bigger one and needs to transfer knowledge to student. \n","      student: student model that is smaller one and get knowledge from teacher.\n","    '''\n","    epoch_loss = []\n","    epoch_acc = []\n","    start_time = time.time()\n","\n","    student.train()\n","    teacher.eval()\n","    for images, labels in train_data_loader:\n","        \n","        #Loading images and labels to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n","        \n","        #Reseting Gradients\n","        optimizer.zero_grad()\n","        \n","        #Forward\n","        output_teacher_batch = teacher(images)\n","        output_batch = student(images)\n","        #Calculating Loss\n","        _loss = loss_fn_kd(output_batch, labels, output_teacher_batch)\n","        loss = _loss.item()\n","        epoch_loss.append(loss)\n","        \n","        #Calculating Accuracy on student\n","        acc = accuracy(output_batch, labels)\n","        epoch_acc.append(acc)\n","        \n","        #Backward\n","        _loss.backward()\n","        optimizer.step()\n","    \n","    ###Overall Epoch Results\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    \n","    ###Acc and Loss\n","    epoch_loss = np.mean(epoch_loss)\n","    epoch_acc = np.mean(epoch_acc)\n","    \n","    ###Storing results to logs\n","    train_logs[\"loss\"].append(epoch_loss)\n","    train_logs[\"accuracy\"].append(epoch_acc)\n","    train_logs[\"time\"].append(total_time)\n","        \n","    return epoch_loss, epoch_acc, total_time"],"metadata":{"id":"ma43QLnQJVOd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n","\n","# Learning Rate Scheduler: Learning rate decay double time after each 3 epochs\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n","\n","#Loss Function\n","criterion = nn.BCELoss()\n","\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","\n","# No of epochs \n","epochs = 5"],"metadata":{"id":"GqoqlwOy0-ut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch in range(epochs):\n","    \n","    ###Training\n","    loss, acc, _time = train_one_epoch_kd(train_data_loader, teacher, model)\n","    \n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    \n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc, \"mobilenet_v3_small\")\n","    \n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zCWKmuBLUWm4","executionInfo":{"status":"error","timestamp":1646556665595,"user_tz":-420,"elapsed":948983,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"3fe91b37-e9f6-483e-98eb-00e742415b39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2748: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training\n","Epoch 1\n","Loss : 0.0\n","Acc : 70.705\n","Time : 170.9411\n","\n","Validating\n","Epoch 1\n","Loss : 0.552\n","Acc : 72.0541\n","Time : 25.8896\n","\n","Training\n","Epoch 2\n","Loss : 0.0\n","Acc : 70.33\n","Time : 170.6852\n","\n","Validating\n","Epoch 2\n","Loss : 0.552\n","Acc : 72.1338\n","Time : 25.813\n","\n","Training\n","Epoch 3\n","Loss : 0.0\n","Acc : 70.29\n","Time : 170.593\n","\n","Validating\n","Epoch 3\n","Loss : 0.5489\n","Acc : 72.3328\n","Time : 25.6357\n","\n","Training\n","Epoch 4\n","Loss : 0.0\n","Acc : 70.26\n","Time : 170.9058\n","\n","Validating\n","Epoch 4\n","Loss : 0.5512\n","Acc : 72.1736\n","Time : 25.7802\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-77-98978c07410b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m###Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch_kd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Print Epoch Details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-72-f80b3605843f>\u001b[0m in \u001b[0;36mtrain_one_epoch_kd\u001b[0;34m(train_data_loader, teacher, student)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m###Overall Epoch Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# 9) Áp dụng thêm các kĩ thuật data augmentation kết hợp ảnh khác nhãn để tạo thành nhãn mềm và huấn luyện cải thiện tiếp model student.\n"],"metadata":{"id":"3-tv_vr1bY1t"}},{"cell_type":"markdown","source":["There are many resource we can use CutMix and MixUp:\n","\n","* Pytorch: Package [timm](https://fastai.github.io/timmdocs/augmentation), [CutMix - clovaai](https://github.com/clovaai/CutMix-PyTorch)\n","\n","* Keras: [cutmix](https://keras.io/examples/vision/cutmix/), [mixup](https://keras.io/examples/vision/mixup/)\n"],"metadata":{"id":"RhpslvNFdoTY"}},{"cell_type":"code","source":["def rand_bbox(size = (None, 3, 224, 224), lam=0.75):\n","    '''\n","    size: input size of batch\n","    lam: ratio of image area that is remained.\n","    '''\n","    W = size[2]\n","    H = size[3]\n","    # cut with and height according to lambda\n","    cut_rat = np.sqrt(1. - lam)\n","    cut_w = np.int(W * cut_rat)\n","    cut_h = np.int(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W)\n","    cy = np.random.randint(H)\n","\n","    # bounding box return\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","\n","    return bbx1, bby1, bbx2, bby2"],"metadata":{"id":"OfIthPINgC-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch_cutmix(train_data_loader, model):\n","    epoch_loss = []\n","    epoch_acc = []\n","    start_time = time.time()\n","\n","    model.train()\n","\n","    for images, labels in train_data_loader:\n","        r = np.random.rand(1)\n","        cutmix_prob = 0.33\n","        beta = 1 # beta distribution parameters of cutmix area\n","        #Loading images and labels to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n","        #Reseting Gradients\n","        optimizer.zero_grad()\n","        if beta > 0 and r < cutmix_prob:\n","            # generate mixed sample\n","            lam = np.random.beta(beta, beta)\n","            # randomly shuffling batch\n","            rand_index = torch.randperm(images.size()[0]).cuda()\n","            labels_a = labels\n","            labels_b = labels[rand_index]\n","            bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n","            # mixture crop image into original image.\n","            images[:, :, bbx1:bbx2, bby1:bby2] = images[rand_index, :, bbx1:bbx2, bby1:bby2]\n","            # adjust lambda to exactly match pixel ratio\n","            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n","            #Forward\n","            preds = model(images)\n","            #Calculating Loss\n","            _loss = criterion(preds, labels_a) * lam + criterion(preds, labels_b) * (1. - lam)\n","        else:\n","            # compute output\n","            preds = model(images)\n","            _loss = criterion(preds, labels)\n","        \n","        loss = _loss.item()\n","        epoch_loss.append(loss)\n","        #Calculating Accuracy\n","        acc = accuracy(preds, labels)\n","        epoch_acc.append(acc)\n","        \n","        #Backward\n","        _loss.backward()\n","        optimizer.step()\n","    \n","    ###Overall Epoch Results\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    \n","    ###Acc and Loss\n","    epoch_loss = np.mean(epoch_loss)\n","    epoch_acc = np.mean(epoch_acc)\n","    \n","    ###Storing results to logs\n","    train_logs[\"loss\"].append(epoch_loss)\n","    train_logs[\"accuracy\"].append(epoch_acc)\n","    train_logs[\"time\"].append(total_time)\n","        \n","    return epoch_loss, epoch_acc, total_time"],"metadata":{"id":"9YfQGIfaig9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n","\n","# Learning Rate Scheduler: Learning rate decay double time after each 3 epochs\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n","\n","#Loss Function\n","criterion = nn.BCELoss()\n","\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","\n","# No of epochs \n","epochs = 5"],"metadata":{"id":"QauI2NWclb1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch in range(epochs):\n","    \n","    ###Training\n","    loss, acc, _time = train_one_epoch_cutmix(train_data_loader, model)\n","    \n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    \n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc, \"mobilenet_v3_small\")\n","    \n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSRVCoeHe9zJ","executionInfo":{"status":"ok","timestamp":1646560355571,"user_tz":-420,"elapsed":889398,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"739db883-1c91-4538-a9e2-efcd8272ea9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training\n","Epoch 1\n","Loss : 0.5901\n","Acc : 68.24\n","Time : 156.4167\n","\n","Validating\n","Epoch 1\n","Loss : 0.5594\n","Acc : 71.258\n","Time : 26.2529\n","\n","Training\n","Epoch 2\n","Loss : 0.5567\n","Acc : 71.565\n","Time : 151.8589\n","\n","Validating\n","Epoch 2\n","Loss : 0.4728\n","Acc : 77.1099\n","Time : 26.21\n","\n","Training\n","Epoch 3\n","Loss : 0.5357\n","Acc : 73.475\n","Time : 150.3429\n","\n","Validating\n","Epoch 3\n","Loss : 0.491\n","Acc : 75.7763\n","Time : 25.8716\n","\n","Training\n","Epoch 4\n","Loss : 0.5196\n","Acc : 74.25\n","Time : 150.0774\n","\n","Validating\n","Epoch 4\n","Loss : 0.4343\n","Acc : 80.215\n","Time : 25.9817\n","\n","Training\n","Epoch 5\n","Loss : 0.4994\n","Acc : 75.32\n","Time : 150.1104\n","\n","Validating\n","Epoch 5\n","Loss : 0.4402\n","Acc : 78.0653\n","Time : 25.8289\n"]}]},{"cell_type":"markdown","source":["# 10) Giả định cần huấn luyện tiếp mô hình student với các dữ liệu mới chưa được gán nhãn. Hãy xây dựng một kĩ thuật lựa chọn mẫu dựa trên đánh giá uncertainty."],"metadata":{"id":"VMiX3QKnmKCz"}},{"cell_type":"markdown","source":["Xem thêm [Active Learning](https://colab.research.google.com/drive/1m3K9-_u468O9hA_4S-uTbbafiXAPxt86?usp=sharing)"],"metadata":{"id":"cCC1KJrgmXgJ"}}]}