{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.CNN_HomeWork_Correction.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1d939c558e2f4ce68ddb713662e43100":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d5e6a07d7f204644badb7ff88fc26f5f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5fe1a43cbee243498b58381f29093487","IPY_MODEL_24eb8907ec164029afda415d558c7a92","IPY_MODEL_13a58d74f2db4e30beba42f4a3ecb9a1"]}},"d5e6a07d7f204644badb7ff88fc26f5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5fe1a43cbee243498b58381f29093487":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_006dc13f5ee346928c64c444eb599f75","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db41bc708b994c3e9979866fa9190b41"}},"24eb8907ec164029afda415d558c7a92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_37add768cbd74890aa23ff8d1ac2a5f5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":102530333,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102530333,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_398ebd8102b849369400408a082876e4"}},"13a58d74f2db4e30beba42f4a3ecb9a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ceefb4b04a0f43b18dd081bd7c8302fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [00:00&lt;00:00, 144MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd69f887eb914ed7b5e222ed50f82cd8"}},"006dc13f5ee346928c64c444eb599f75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db41bc708b994c3e9979866fa9190b41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37add768cbd74890aa23ff8d1ac2a5f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"398ebd8102b849369400408a082876e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ceefb4b04a0f43b18dd081bd7c8302fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dd69f887eb914ed7b5e222ed50f82cd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["# I. Lý thuyết"],"metadata":{"id":"W2HWfZe5bT7u"}},{"cell_type":"markdown","source":["1) Mạng tích chập CNN sẽ được thực hiện như thế nào?\n","\n","A. Phân chia feature map thành các ma trận theo chiều channel và thực hiện tích chập giữa mỗi ma trận kernel với từng chiều.\n","\n","B. Thực hiện phép nhân ma trận kernel với chuyển vị của ma trận local receptive field để thu được giá trị feature map output.\n","\n","C. Tính trung bình các phân tử trên một ma trận local receptive field.\n","\n","D. Di chuyển vùng local receptive field theo chiều từ trái sang phải và từ trên xuống dưới và nhân tích chập với kernel để thu được ma trận feature map.\n","\n","\n","Đáp án: D\n","\n","\n","2) Thực hiện phép nhân tích chập giữa ma trận đầu vào kích thước width và height lần lượt là $(W, H)$ với bộ lọc kích thước $(F, F)$ và bước nhảy $S$ thì thu được ma trận đầu ra với kích thước width và height $(W', H')$ là bao nhiêu? Hãy lựa chọn công thức tổng quát nhất.\n","\n","A. $W' =⌊ \\frac{W-F}{S} ⌋ + 1;~ H' =⌊ \\frac{H-F}{S} ⌋ + 1$\n","\n","B. $W' =\\lceil \\frac{W-F}{S} \\rceil + 1;~ H' = \\lceil \\frac{H-F}{S} \\rceil + 1$ \n","\n","C. $W' =\\lfloor \\frac{W-F+2P}{S} \\rfloor + 1;~ H' = \\lfloor \\frac{H-F+2P}{S} \\rfloor + 1$ với $P$ là số lượng các véc tơ 0 padding ở bên ngoài đều hai phía.\n","\n","D. $W' =\\lceil \\frac{W-F+P}{S} \\rceil + 1;~ H' = \\lceil \\frac{H-F+P}{S} \\rceil + 1$ với $P$ là số lượng các véc tơ 0 padding ở bên ngoài đều hai phía.\n","\n","Đáp án: C\n","\n","3) Mạng CNN sẽ học được những gì qua các layers?\n","\n","A. Tại những layers đầu mỗi channels sẽ giúp phân biệt một loại đặc trưng, của vật thể. Những đặc trưng này sau đó được trải phẳng và đưa vào mạng MLP để phân loại vật thể.\n","\n","B. Những layers cuối cùng sẽ zoom vào từng chi tiết của vật thể để phân loại vật thể.\n","\n","C. Tại những layers đầu mạng sẽ học được các đặc trưng chung như các edge dọc, ngang, chéo,.... Các đặc trưng chi tiết và tổng quát giúp nhận diện vật thể được học tại những layers cuối cùng.\n","\n","D. Các layers đầu tiên sẽ tập trung vào các chi tiết bộ phận của vật thể.\n","\n","Đáp án: C\n","\n","\n","4) Kiến trúc chung của một mạng CNN là gì?\n","\n","A. _[Conv -> BatchNorm -> Activation -> Maxpooling] x n_\n","\n","B. _[BatchNorm -> Conv -> Activation -> Maxpooling] x n_ \n","\n","C. _[Conv -> BatchNorm -> Maxpooling -> Activation -> Maxpooling] x n_ \n","\n","D. _[Conv -> BatchNorm -> Activation -> Maxpooling] x n -> Flatten -> [FullyConnected -> Activation] x m -> Softmax_ \n","\n","Đáp án: D\n","\n","5) Thông thường đặc điểm kích thước feature map của mạng neural sẽ như thế nào ?\n","\n","A. Kích thước feature map tăng dần gấp đôi qua thời gian.\n","\n","B. Kích thước feature map sẽ duy trì không đổi qua thời gian.\n","\n","C. Kích thước mạng sẽ giảm dần gấp đôi sau mỗi một lần downsampling và sau đó tăng dần gấp đôi sau mỗi lần upsampling để khôi phục về kích thước ảnh input.\n","\n","D. Kích thước mạng thường giảm gấp đôi sau một lần downsampling và số lượng các filters tăng dần.\n","\n","Đáp án: D"],"metadata":{"id":"O6_oiMLtbZd2"}},{"cell_type":"markdown","source":["# II. Thực hành\n","\n","6) Thực hiện xây dựng và huấn luyện một mạng CNN ngẫu nhiên trên bộ dữ liệu [Dog and Cat](https://www.kaggle.com/c/dog-vs-cat-classification/data). Lưu ý cần thực hiện [chuẩn hóa dữ liệu](https://github.com/pytorch/examples/issues/112) đối với bộ dữ liệu ImageNet trước khi huấn luyện.\n","\n","7) Grid Search kiến trúc CNN dựa trên việc tổng quát hóa một thiết kế câu 6.\n","\n","8) Huấn luyện lại mô hình bằng kiến trúc ResNet và MobileNet. Đánh giá chi phí tính toán và submit kết quả độ chính xác trên các ảnh thuộc folder test.\n","\n","9) Thử nghiệm các phương pháp Augmentation như Flip, Rotation, Random Crop, Bright Contrast để cải thiện kết quả mô hình.\n","\n","10) Lập bảng kết quả các thử nghiệm đã sử dụng."],"metadata":{"id":"I4U8kdaxbW0e"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount(\"/content/gdrive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6P9ym-vMtF7Z","outputId":"8fae5f14-deb1-4715-8cd4-627a6df788fd","executionInfo":{"status":"ok","timestamp":1645967623374,"user_tz":-420,"elapsed":22136,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/Colab Notebooks/DeepLearning2/5.CNN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bb4hxsYwxEAt","outputId":"58d9c7b0-3b53-4235-ea77-b6a01bb174ad","executionInfo":{"status":"ok","timestamp":1645967627414,"user_tz":-420,"elapsed":776,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/DeepLearning2/5.CNN\n"]}]},{"cell_type":"code","source":["# !unzip ../data/dogvscat/train.zip -d ../data/dogvscat/train"],"metadata":{"id":"61D_Qi7hfDDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !unzip ../data/dogvscat/test.zip -d ../data/dogvscat/test"],"metadata":{"id":"mdJJ8_mXfXIJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls ../data/dogvscat/"],"metadata":{"id":"d52p0JOwJlYg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645967631732,"user_tz":-420,"elapsed":335,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"01828e81-0915-4221-dfe3-16c0128297da"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["test  test.zip\ttrain  train.zip\n"]}]},{"cell_type":"code","source":["import os\n","import zipfile\n","import glob\n","import time\n","import pickle\n","import pprint\n","import math\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import PIL\n","\n","import numpy as np\n","import pandas as pd\n","import sklearn.model_selection\n","\n","import torch\n","import torch.nn as nn\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torch.utils.data\n","from torch.utils.data import Dataset, DataLoader\n","\n","import tqdm\n","import random\n","import torchvision.transforms as T\n","\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"ypd-V9lkx1-D","executionInfo":{"status":"ok","timestamp":1645967644344,"user_tz":-420,"elapsed":336,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","print(device)"],"metadata":{"id":"P7dSVnonxwDw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645967645710,"user_tz":-420,"elapsed":5,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"2e6fd27b-757d-402f-f555-4f35c4255679"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["##Prepare Dataset"],"metadata":{"id":"F8nigKRO52OC"}},{"cell_type":"code","source":["TRAIN_DIR = '../data/dogvscat/train/train'\n","TEST_DIR = '../data/dogvscat/test/test'\n","train_images = glob.glob(TRAIN_DIR+\"/**/**.jpg\")\n","test_images = glob.glob(TEST_DIR+\"/**.jpg\")"],"metadata":{"id":"qQPwrcNv51Ro","executionInfo":{"status":"ok","timestamp":1645967766225,"user_tz":-420,"elapsed":118460,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_images[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjUJ0w8PUCcv","executionInfo":{"status":"ok","timestamp":1645967766225,"user_tz":-420,"elapsed":6,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"3b5efba0-1d2d-4918-be44-e69fe31dab20"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['../data/dogvscat/train/train/cats/cat.9769.jpg',\n"," '../data/dogvscat/train/train/cats/cat.9175.jpg',\n"," '../data/dogvscat/train/train/cats/cat.9741.jpg',\n"," '../data/dogvscat/train/train/cats/cat.9358.jpg',\n"," '../data/dogvscat/train/train/cats/cat.8912.jpg']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["dogs_list = [img for img in train_images if img.split(\"/\")[-2] == \"dogs\"]\n","cats_list = [img for img in train_images if img.split(\"/\")[-2] == \"cats\"]\n","\n","print(\"Dogs Images: \",len(dogs_list))\n","print(\"Cats Images: \",len(cats_list))\n","\n","class_to_int = {\"dogs\" : 0, \"cats\" : 1}\n","int_to_class = {0 : \"dogs\", 1 : \"cats\"}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rEXHo4gXg4FP","outputId":"f27b7408-4c5c-44a8-de80-2e54db5fa30b","executionInfo":{"status":"ok","timestamp":1645967766225,"user_tz":-420,"elapsed":4,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Dogs Images:  0\n","Cats Images:  10902\n"]}]},{"cell_type":"markdown","source":["9) Thử nghiệm các phương pháp Augmentation như Flip, Rotation, Random Crop, Bright Contrast để cải thiện kết quả mô hình."],"metadata":{"id":"vxN0WOtiynq5"}},{"cell_type":"code","source":["def get_train_transform():\n","    return T.Compose([\n","        T.RandomHorizontalFlip(p=0.5), # Random flip with probability = 0.5\n","        T.RandomRotation(15), # Random rotation with angle <= 15\n","        # T.ColorJitter(brightness=.5, hue=.3), # Bright contrast\n","        T.Resize((256, 256)),\n","        T.RandomResizedCrop(224), # Random crop Image with shape 224\n","        T.ToTensor(),\n","        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)), # Normalize according to ImageNet distribution\n","    ])\n","    \n","def get_val_transform():\n","    return T.Compose([\n","        T.Resize((224, 224)),\n","        T.ToTensor(),\n","        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n","    ])"],"metadata":{"id":"7HhhpznOc_oB","executionInfo":{"status":"ok","timestamp":1645967766225,"user_tz":-420,"elapsed":2,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","class CatDogDataset(Dataset):\n","    def __init__(self, imgs, class_to_int, mode = \"train\", \n","                 transforms = None):\n","        super().__init__()\n","        self.imgs = imgs\n","        self.class_to_int = class_to_int\n","        self.mode = mode\n","        self.transforms = transforms\n","    def __getitem__(self, idx):\n","        image_name = self.imgs[idx]\n","        if self.mode == \"train\" or self.mode == \"val\":\n","            img = Image.open(image_name)\n","            # img = img.resize((256, 256))\n","            ### Preparing class label\n","            label = self.class_to_int[image_name.split(\"/\")[-2]]\n","            label = torch.tensor(label, dtype = torch.float32)\n","            ### Apply Transforms on image\n","            img = self.transforms(img)\n","            return img, label\n","        elif self.mode == \"test\":\n","            img = Image.open(image_name)\n","            # img = img.resize((256, 256))\n","            ### Apply Transforms on image\n","            img = self.transforms(img)\n","            return img, image_name\n","    def __len__(self):\n","        return len(self.imgs)"],"metadata":{"id":"P30-vqcAeSo4","executionInfo":{"status":"ok","timestamp":1645967988412,"user_tz":-420,"elapsed":307,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train_imgs, val_imgs = train_test_split(train_images, test_size = 0.2)"],"metadata":{"id":"Ae2NiZO9gM_m","executionInfo":{"status":"ok","timestamp":1645968106677,"user_tz":-420,"elapsed":303,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["train_dataset = CatDogDataset(train_imgs, class_to_int, mode = \"train\", \n","                              transforms = get_train_transform())\n","val_dataset = CatDogDataset(val_imgs, class_to_int, mode = \"val\", \n","                            transforms = get_val_transform())\n","test_dataset = CatDogDataset(test_images, class_to_int, mode = \"test\", \n","                             transforms = get_val_transform())\n","\n","train_data_loader = DataLoader(\n","    dataset = train_dataset,\n","    num_workers = 2,\n","    batch_size = 32,\n","    shuffle = True\n",")\n","\n","val_data_loader = DataLoader(\n","    dataset = val_dataset,\n","    num_workers = 2,\n","    batch_size = 16,\n","    shuffle = True\n",")\n","\n","test_data_loader = DataLoader(\n","    dataset = test_dataset,\n","    num_workers = 2,\n","    batch_size = 1,\n","    shuffle = False\n",")"],"metadata":{"id":"VR9eWpjEgZtC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train and eval function"],"metadata":{"id":"1saOM5h357yi"}},{"cell_type":"code","source":["def accuracy(preds, trues):\n","    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n","    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n","    acc = np.sum(acc) / len(preds)\n","    return (acc * 100)"],"metadata":{"id":"lTSDnm6ihTPz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(train_data_loader, model, optimizer):\n","    epoch_loss = []\n","    epoch_acc = []\n","    start_time = time.time()\n","    # model.to(device)\n","    model.train()\n","    \n","    for images, labels in train_data_loader:\n","        \n","        #Loading images and labels to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n","        \n","        #Reseting Gradients\n","        optimizer.zero_grad()\n","        \n","        #Forward\n","        preds = model(images)\n","        \n","        #Calculating Loss\n","        _loss = criterion(preds, labels)\n","        loss = _loss.item()\n","        epoch_loss.append(loss)\n","        \n","        #Calculating Accuracy\n","        acc = accuracy(preds, labels)\n","        epoch_acc.append(acc)\n","        \n","        #Backward\n","        _loss.backward()\n","        optimizer.step()\n","    \n","    ###Overall Epoch Results\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    \n","    ###Acc and Loss\n","    epoch_loss = np.mean(epoch_loss)\n","    epoch_acc = np.mean(epoch_acc)\n","    \n","    ###Storing results to logs\n","    train_logs[\"loss\"].append(epoch_loss)\n","    train_logs[\"accuracy\"].append(epoch_acc)\n","    train_logs[\"time\"].append(total_time)\n","        \n","    return epoch_loss, epoch_acc, total_time"],"metadata":{"id":"5-7D1EGkiD9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def val_one_epoch(val_data_loader, model, best_val_acc, model_name):\n","    epoch_loss = []\n","    epoch_acc = []\n","    start_time = time.time()\n","    # model.to(device)\n","    model.eval()\n","    \n","    for images, labels in val_data_loader:\n","        \n","        #Loading images and labels to device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = labels.reshape((labels.shape[0], 1)) # [N, 1] - to match with preds shape\n","        \n","        #Forward\n","        preds = model(images)\n","        \n","        #Calculating Loss\n","        _loss = criterion(preds, labels)\n","        loss = _loss.item()\n","        epoch_loss.append(loss)\n","        \n","        #Calculating Accuracy\n","        acc = accuracy(preds, labels)\n","        epoch_acc.append(acc)\n","    \n","    ###Overall Epoch Results\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    \n","    ###Acc and Loss\n","    epoch_loss = np.mean(epoch_loss)\n","    epoch_acc = np.mean(epoch_acc)\n","    \n","    ###Storing results to logs\n","    val_logs[\"loss\"].append(epoch_loss)\n","    val_logs[\"accuracy\"].append(epoch_acc)\n","    val_logs[\"time\"].append(total_time)\n","    \n","    ###Saving best model\n","    if epoch_acc > best_val_acc:\n","        best_val_acc = epoch_acc\n","        torch.save(model.state_dict(),model_name+\"_best.pth\")\n","        \n","    return epoch_loss, epoch_acc, total_time, best_val_acc"],"metadata":{"id":"X0MSeYCtiSsD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Build my model"],"metadata":{"id":"t3C0y7Gjl7rZ"}},{"cell_type":"code","source":["class cnn(nn.Module):\n","    def __init__(self):\n","        super(cnn,self).__init__()\n","        \n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 128, kernel_size=7, padding=0, stride=2),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2)\n","        )\n","        \n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(128,256, kernel_size=5, padding=0, stride=2),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2)\n","            )\n","        \n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(256,512, kernel_size=3, padding=0, stride=2),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2)\n","        )\n","        \n","        \n","        self.fc1 = nn.Linear(2048,1000)\n","        self.dropout = nn.Dropout()\n","        self.fc2 = nn.Linear(1000,1)\n","        self.relu = nn.ReLU()\n","        self.sigmoid=nn.Sigmoid()\n","        \n","        \n","    def forward(self,x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = out.view(out.size(0),-1)\n","        out = self.relu(self.fc1(out))\n","        out = self.fc2(out)\n","        out = self.sigmoid(out)\n","        return out"],"metadata":{"id":"ZrP7XAwHiaRv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To check output shape and number of parameters you have to use `summary` function of `torchsummary` package"],"metadata":{"id":"GcOkMZXl0Mno"}},{"cell_type":"code","source":["from torchvision import models\n","from torchsummary import summary\n","\n","model=cnn()\n","model.to(device)\n","summary(model, (3, 224, 224), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZK3t2nNBFN-","executionInfo":{"status":"ok","timestamp":1645943097338,"user_tz":-420,"elapsed":3045,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"13ae1342-9201-45f9-ef09-7f2ef3adbeea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1        [-1, 128, 109, 109]          18,944\n","       BatchNorm2d-2        [-1, 128, 109, 109]             256\n","              ReLU-3        [-1, 128, 109, 109]               0\n","         MaxPool2d-4          [-1, 128, 54, 54]               0\n","            Conv2d-5          [-1, 256, 25, 25]         819,456\n","       BatchNorm2d-6          [-1, 256, 25, 25]             512\n","              ReLU-7          [-1, 256, 25, 25]               0\n","         MaxPool2d-8          [-1, 256, 12, 12]               0\n","            Conv2d-9            [-1, 512, 5, 5]       1,180,160\n","      BatchNorm2d-10            [-1, 512, 5, 5]           1,024\n","             ReLU-11            [-1, 512, 5, 5]               0\n","        MaxPool2d-12            [-1, 512, 2, 2]               0\n","           Linear-13                 [-1, 1000]       2,049,000\n","             ReLU-14                 [-1, 1000]               0\n","           Linear-15                    [-1, 1]           1,001\n","          Sigmoid-16                    [-1, 1]               0\n","================================================================\n","Total params: 4,070,353\n","Trainable params: 4,070,353\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 41.92\n","Params size (MB): 15.53\n","Estimated Total Size (MB): 58.02\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9hYyTboA-GX","executionInfo":{"status":"ok","timestamp":1645943101669,"user_tz":-420,"elapsed":491,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"90d2db27-d75b-4521-f218-fc93928d6f25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cnn(\n","  (layer1): Sequential(\n","    (0): Conv2d(3, 128, kernel_size=(7, 7), stride=(2, 2))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc1): Linear(in_features=2048, out_features=1000, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=1000, out_features=1, bias=True)\n","  (relu): ReLU()\n","  (sigmoid): Sigmoid()\n",")\n"]}]},{"cell_type":"code","source":["# Reset gradient\n","model.zero_grad()\n","\n","# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","\n","# Learning Rate Scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.33)\n","\n","#Loss Function\n","criterion = nn.BCELoss()\n","\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","\n","# Loading model to device\n","model.to(device)\n","\n","# No of epochs \n","epochs = 15"],"metadata":{"id":"NM6Z88OsmW5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch in range(epochs):\n","    \n","    ###Training\n","    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n","    \n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    \n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"mymodel\")\n","    \n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    "],"metadata":{"id":"J73ONQYcmdGh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7) Grid Search kiến trúc CNN dựa trên việc tổng quát hóa một thiết kế câu 6.\n","\n","Xem tại [Buổi 4. Deep Neural Network](https://drive.google.com/file/d/1j6eR_g2BXFn2Ml2cpsIQq-sgkn4nV1TL/view?usp=sharing)"],"metadata":{"id":"TGiPaRvXx1nP"}},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRDibEdI7uM4","executionInfo":{"status":"ok","timestamp":1645943331163,"user_tz":-420,"elapsed":4573,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"89156c1a-31bb-4d39-fda6-67489ff37e8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n","Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n","Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n","Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n","Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.6)\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.1)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.6)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n","Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.1.1)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.8.1)\n","Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.0)\n","Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n","Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"]}]},{"cell_type":"code","source":["import optuna\n","from optuna.trial import TrialState\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import models\n","from torchsummary import summary"],"metadata":{"id":"vhHcq6OF7qPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def define_model(trial):\n","#     # We optimize the number of layers, hidden units and dropout ratio in each layer.\n","#     class CNN_NAS(nn.Module):\n","#       def __init__(self):\n","#           super(CNN_NAS,self).__init__()\n","#           n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n","#           self.layers = []\n","#           act_layers = {\n","#               'relu': nn.ReLU(),\n","#               'sigmoid': nn.Sigmoid(),\n","#               'gelu': nn.GELU(),\n","#           }\n","#           # in_features = len(features)\n","#           in_chan = trial.suggest_int(\"depth\", 20, 100)\n","#           pre_kernel_size = 7\n","#           x = torch.randn(2, 3, 224, 224) # [b, c, w, h]\n","#           first_layer = True\n","#           w = 224\n","#           for i in range(n_layers):\n","#             # create search for each cnn block\n","#             scale_chan = trial.suggest_float(\"scale\", 1.1, 2.5)\n","#             out_chan = int(in_chan*scale_chan)\n","#             scale_kernel_size = trial.suggest_float(\"scale_kernel_size\", 1, 2)\n","#             kernel_size = 2*int((pre_kernel_size-1)/(2*scale_kernel_size))+1\n","#             stride = trial.suggest_int(\"stride\", 1, 2)\n","#             act_type = trial.suggest_categorical(\"act_type\", ['relu', 'sigmoid', 'gelu'])\n","#             p = trial.suggest_float('p', 0, 0.2)\n","#             if first_layer:\n","#               in_chan = 3\n","#               kernel_size = pre_kernel_size\n","#             if w >= 2:\n","#               layer = nn.Sequential(\n","#                 nn.Conv2d(in_chan, out_chan, kernel_size=kernel_size, padding=0, stride=stride),\n","#                 nn.BatchNorm2d(out_chan),\n","#                 act_layers[act_type],\n","#                 nn.MaxPool2d(2),\n","#                 nn.Dropout(p)\n","#               )\n","#               self.layers.append(layer)\n","#               first_layer = False\n","#               in_chan = out_chan\n","#               pre_kernel_size = kernel_size\n","#               x = layer(x)\n","#               dim = x.shape\n","#               w = dim[3]\n","#           in_features = dim[1]*dim[2]*dim[3]\n","#           self.fc1 = nn.Linear(in_features,2048)\n","#           self.dropout = nn.Dropout()\n","#           self.fc2 = nn.Linear(2048, 1)\n","#           self.relu = nn.ReLU()\n","#           self.sigmoid=nn.Sigmoid()\n","          \n","#       def forward(self,x):\n","#           for layer in self.layers:\n","#             x = layer(x)\n","#           print('cnn output: ', x.shape)\n","#           x = x.view(x.size(0),-1)\n","#           print('x flatten: ', x.shape)\n","#           x = self.relu(self.fc1(x))\n","#           x = self.fc2(x)\n","#           print('x fc2: ', x.shape)\n","#           x = self.sigmoid(x)\n","#           return x\n","#     return CNN_NAS()\n","\n","#     # in_features = dim[1]*dim[2]*dim[3]\n","#     # print('dim: ', dim)\n","#     # print('in_features: ', in_features)\n","#     # layers.append(nn.Flatten())\n","#     # layers.append(nn.Linear(in_features, 1000))\n","#     # layers.append(nn.Dropout(0.5))\n","#     # layers.append(nn.Linear(1000, 1))\n","#     # layers.append(nn.ReLU())\n","#     # layers.append(nn.Sigmoid())\n","#     # return nn.Sequential(*layers)"],"metadata":{"id":"uC5ueDKP0xLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def define_model(trial):\n","    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n","    n_layers = trial.suggest_int(\"n_layers\", 3, 5)\n","    layers = []\n","    act_layers = {\n","        'relu': nn.ReLU(),\n","        'sigmoid': nn.Sigmoid(),\n","        'gelu': nn.GELU(),\n","    }\n","    # in_features = len(features)\n","    in_chan = trial.suggest_int(\"depth\", 20, 100)\n","    pre_kernel_size = 7\n","    x = torch.randn(2, 3, 224, 224) # [b, c, w, h]\n","    first_layer = True\n","    w = 224\n","    for i in range(n_layers):\n","      # create search for each CNN block\n","      scale_chan = trial.suggest_float(\"scale\", 1.1, 2.5)\n","      out_chan = int(in_chan*scale_chan)\n","      scale_kernel_size = trial.suggest_float(\"scale_kernel_size\", 1, 2)\n","      kernel_size = 2*int((pre_kernel_size-1)/(2*scale_kernel_size))+1\n","      stride = trial.suggest_int(\"stride\", 1, 2)\n","      act_type = trial.suggest_categorical(\"act_type\", ['relu', 'sigmoid', 'gelu'])\n","      p = trial.suggest_float('p', 0, 0.2)\n","      if first_layer:\n","        in_chan = 3\n","        kernel_size = pre_kernel_size\n","      if w >= 2:\n","        layer = nn.Sequential(\n","          nn.Conv2d(in_chan, out_chan, kernel_size=kernel_size, padding=0, stride=stride),\n","          nn.BatchNorm2d(out_chan),\n","          act_layers[act_type],\n","          nn.MaxPool2d(2),\n","          nn.Dropout(p)\n","        )\n","        layers.append(layer)\n","        first_layer = False\n","        in_chan = out_chan\n","        pre_kernel_size = kernel_size\n","        x = layer(x)\n","        dim = x.shape\n","        w = dim[3]    \n","    in_features = dim[1]*dim[2]*dim[3]\n","    layers.append(nn.Flatten())\n","    layers.append(nn.Linear(in_features, 1000))\n","    layers.append(nn.Dropout(0.5))\n","    layers.append(nn.Linear(1000, 1))\n","    layers.append(nn.ReLU())\n","    layers.append(nn.Sigmoid())\n","    return nn.Sequential(*layers)"],"metadata":{"id":"cFQ8eSMv5OdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 15\n","def objective(trial):\n","\n","    # Generate the model.\n","    model = define_model(trial)\n","    model.to(device)\n","    print(model)\n","\n","    # Optimizer\n","    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","\n","    # Learning Rate Scheduler\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.33)\n","\n","    #Loss Function\n","    criterion = nn.BCELoss()\n","\n","    best_val_acc = 0\n","    for epoch in range(epochs):\n","        \n","        ###Training\n","        loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n","        \n","        #Print Epoch Details\n","        print(\"\\nTraining\")\n","        print(\"Epoch {}\".format(epoch+1))\n","        print(\"Loss : {}\".format(round(loss, 4)))\n","        print(\"Acc : {}\".format(round(acc, 4)))\n","        print(\"Time : {}\".format(round(_time, 4)))\n","        \n","        ###Validation\n","        loss, val_acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"mymodel\")\n","        \n","        #Print Epoch Details\n","        print(\"\\nValidating\")\n","        print(\"Epoch {}\".format(epoch+1))\n","        print(\"Loss : {}\".format(round(loss, 4)))\n","        print(\"Acc : {}\".format(round(acc, 4)))\n","        print(\"Time : {}\".format(round(_time, 4)))\n","        \n","        trial.report(val_acc, epoch)\n","\n","        # Handle pruning based on the intermediate value.\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","    return val_acc"],"metadata":{"id":"5J33Hq-JuHcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=100, timeout=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FL96szVs8KpM","outputId":"ddb203e2-4d27-4072-cc6c-8430c9d7dc99","executionInfo":{"status":"error","timestamp":1645944171606,"user_tz":-420,"elapsed":275507,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2022-02-27 06:38:15,449]\u001b[0m A new study created in memory with name: no-name-7c270ca4-725b-4cf7-a12b-7a050016e6ae\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["dim:  torch.Size([2, 82, 13, 13])\n","in_features:  13858\n","Sequential(\n","  (0): Sequential(\n","    (0): Conv2d(3, 47, kernel_size=(7, 7), stride=(2, 2))\n","    (1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): GELU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Dropout(p=0.19391328367873598, inplace=False)\n","  )\n","  (1): Sequential(\n","    (0): Conv2d(47, 82, kernel_size=(3, 3), stride=(2, 2))\n","    (1): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): GELU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Dropout(p=0.19391328367873598, inplace=False)\n","  )\n","  (2): Flatten(start_dim=1, end_dim=-1)\n","  (3): Linear(in_features=13858, out_features=1000, bias=True)\n","  (4): Dropout(p=0.5, inplace=False)\n","  (5): Linear(in_features=1000, out_features=1, bias=True)\n","  (6): ReLU()\n","  (7): Sigmoid()\n",")\n","\n","Training\n","Epoch 1\n","Loss : 0.0023\n","Acc : 100.0\n","Time : 72.5289\n","\n","Validating\n","Epoch 1\n","Loss : 0.0\n","Acc : 100.0\n","Time : 13.5455\n","\n","Training\n","Epoch 2\n","Loss : 0.0\n","Acc : 100.0\n","Time : 70.6414\n","\n","Validating\n","Epoch 2\n","Loss : 0.0\n","Acc : 100.0\n","Time : 13.5887\n","\n","Training\n","Epoch 3\n","Loss : 0.0\n","Acc : 100.0\n","Time : 68.8939\n","\n","Validating\n","Epoch 3\n","Loss : 0.0\n","Acc : 100.0\n","Time : 13.1372\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-9393379ee642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-070c116bc086>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m###Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#Print Epoch Details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-0812890124ab>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_data_loader, model, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#Loading images and labels to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n","complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n","\n","print(\"Study statistics: \")\n","print(\"  Number of finished trials: \", len(study.trials))\n","print(\"  Number of pruned trials: \", len(pruned_trials))\n","print(\"  Number of complete trials: \", len(complete_trials))\n","\n","print(\"Best trial:\")\n","trial = study.best_trial\n","\n","print(\"  Value: \", trial.value)\n","\n","print(\"  Params: \")\n","for key, value in trial.params.items():\n","    print(\"    {}: {}\".format(key, value))"],"metadata":{"id":"I2U8HMSVKoBD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import models\n","from torchsummary import summary\n","\n","model = define_model(trial).to(device)\n","summary(model, (3, 224, 224), device=device)"],"metadata":{"id":"F0a_QBIzK-QR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YFBnUyOKxkL","executionInfo":{"status":"ok","timestamp":1645814341277,"user_tz":-420,"elapsed":521,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"1218bdae-092e-4277-e253-c14b7c644f70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=68750, out_features=2048, bias=True)\n","  (1): Dropout(p=0.5, inplace=False)\n","  (2): Linear(in_features=2048, out_features=1, bias=True)\n","  (3): ReLU()\n","  (4): Sigmoid()\n",")"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","source":["##Restnet50"],"metadata":{"id":"GgoDleOBif9q"}},{"cell_type":"code","source":["from torchvision.models import resnet50\n","model = resnet50(pretrained = True)\n","\n","# Modifying Head - classifier\n","\n","model.fc = nn.Sequential(\n","    nn.Linear(2048, 1, bias = True),\n","    nn.Sigmoid()\n",")"],"metadata":{"id":"qXbqWo36ihSr","colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["1d939c558e2f4ce68ddb713662e43100","d5e6a07d7f204644badb7ff88fc26f5f","5fe1a43cbee243498b58381f29093487","24eb8907ec164029afda415d558c7a92","13a58d74f2db4e30beba42f4a3ecb9a1","006dc13f5ee346928c64c444eb599f75","db41bc708b994c3e9979866fa9190b41","37add768cbd74890aa23ff8d1ac2a5f5","398ebd8102b849369400408a082876e4","ceefb4b04a0f43b18dd081bd7c8302fb","dd69f887eb914ed7b5e222ed50f82cd8"]},"executionInfo":{"status":"error","timestamp":1645807745368,"user_tz":-420,"elapsed":8071,"user":{"displayName":"khanhblog AI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64","userId":"06481533334230032014"}},"outputId":"0c251819-57f7-41af-8a09-b5374cade41f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d939c558e2f4ce68ddb713662e43100","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-914b72fc2b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Modifying Head - classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model.fc = nn.Sequential(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"cell_type":"code","source":["# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n","\n","# Learning Rate Scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n","\n","#Loss Function\n","criterion = nn.BCELoss()\n","\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","\n","# Loading model to device\n","model.to(device)\n","\n","# No of epochs \n","epochs = 5"],"metadata":{"id":"3m54keavimrQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch in range(epochs):\n","    \n","    ###Training\n","    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n","    \n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    \n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"resnet50\")\n","    \n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyx0I_hdit2T","outputId":"143d1a7b-05f2-4797-8570-8b041362f0f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training\n","Epoch 1\n","Loss : 0.1442\n","Acc : 93.905\n","Time : 550.3182\n","\n","Validating\n","Epoch 1\n","Loss : 0.0447\n","Acc : 98.4674\n","Time : 46.7776\n","\n","Training\n","Epoch 2\n","Loss : 0.1121\n","Acc : 95.375\n","Time : 549.4432\n","\n","Validating\n","Epoch 2\n","Loss : 0.0438\n","Acc : 98.1489\n","Time : 46.1721\n","\n","Training\n","Epoch 3\n","Loss : 0.1136\n","Acc : 95.24\n","Time : 549.9613\n","\n","Validating\n","Epoch 3\n","Loss : 0.0392\n","Acc : 98.6664\n","Time : 46.1564\n","\n","Training\n","Epoch 4\n","Loss : 0.0999\n","Acc : 95.81\n","Time : 548.7609\n","\n","Validating\n","Epoch 4\n","Loss : 0.0395\n","Acc : 98.3479\n","Time : 45.8418\n","\n","Training\n","Epoch 5\n","Loss : 0.0981\n","Acc : 95.795\n","Time : 548.4862\n","\n","Validating\n","Epoch 5\n","Loss : 0.0565\n","Acc : 97.8105\n","Time : 45.8208\n"]}]},{"cell_type":"markdown","source":["##Mobilenet"],"metadata":{"id":"DNWjyatutuRK"}},{"cell_type":"code","source":["from torchvision.models import mobilenet_v2\n","model=mobilenet_v2(pretrained=True)\n","model.classifier._modules['1'] = nn.Sequential(\n","    nn.Linear(1280, 1, bias = True),\n","    nn.Sigmoid()\n",")"],"metadata":{"id":"k_yASV1gtwp8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n","\n","# Learning Rate Scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n","\n","#Loss Function\n","criterion = nn.BCELoss()\n","\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","\n","# Loading model to device\n","model.to(device)\n","\n","# No of epochs \n","epochs = 5"],"metadata":{"id":"M_D_AFqOuFpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_acc = 0\n","for epoch in range(epochs):\n","    \n","    ###Training\n","    loss, acc, _time = train_one_epoch(train_data_loader, model, optimizer)\n","    \n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    \n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, model, best_val_acc, \"mobilenet_v2\")\n","    \n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0y39foSRuGVG","outputId":"b15bd5f9-b293-4516-89e4-06f5c91fa3c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training\n","Epoch 1\n","Loss : 0.1475\n","Acc : 93.85\n","Time : 211.3811\n","\n","Validating\n","Epoch 1\n","Loss : 0.0463\n","Acc : 98.6465\n","Time : 40.5227\n","\n","Training\n","Epoch 2\n","Loss : 0.1124\n","Acc : 95.215\n","Time : 209.3682\n","\n","Validating\n","Epoch 2\n","Loss : 0.0418\n","Acc : 98.5669\n","Time : 45.9461\n","\n","Training\n","Epoch 3\n","Loss : 0.1017\n","Acc : 95.675\n","Time : 208.8129\n","\n","Validating\n","Epoch 3\n","Loss : 0.0378\n","Acc : 98.6266\n","Time : 40.8667\n","\n","Training\n","Epoch 4\n","Loss : 0.095\n","Acc : 95.99\n","Time : 209.7385\n","\n","Validating\n","Epoch 4\n","Loss : 0.0446\n","Acc : 98.5271\n","Time : 45.0689\n","\n","Training\n","Epoch 5\n","Loss : 0.0906\n","Acc : 96.275\n","Time : 213.2981\n","\n","Validating\n","Epoch 5\n","Loss : 0.0461\n","Acc : 98.3479\n","Time : 40.9497\n"]}]},{"cell_type":"markdown","source":["##Predict"],"metadata":{"id":"OAvgVtcvnwlA"}},{"cell_type":"code","source":["model_file=\"resnet50_best.pth\"\n","model_name=model_file.split(\".\")[0]\n","# model=mobilenet_v2(pretrained=False)\n","# model.classifier._modules['1'] = nn.Sequential(\n","#     nn.Linear(1280, 1, bias = True),\n","#     nn.Sigmoid()\n","# )\n","model = resnet50(pretrained = True)\n","model.fc = nn.Sequential(\n","    nn.Linear(2048, 1, bias = True),\n","    nn.Sigmoid()\n",")\n","model.load_state_dict(torch.load(model_file))\n","model.to(device)\n","model.eval()  # ensure we're in eval mode\n","\n","test_predictions = []\n","test_idx = []\n","print('Testing...')\n","for X,id_ in test_data_loader:\n","    with torch.no_grad():\n","        X = X.to(device)\n","        predictions = model(X)\n","        test_idx.extend(list(id_))\n","        test_predictions.extend([1 if predictions[i] < 0.5 else 0 for i in range(len(predictions))])  \n","\n","submission = pd.DataFrame({'id': test_idx, 'labels': test_predictions}).sort_values(by='id')\n","submission.to_csv(f'submission_'+model_name+'.csv', index=False)\n","print(f'Submission saved')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhE5KR5yuwOC","outputId":"5f77a48c-21d2-4a90-a06f-a48db277f640"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["Submission saved\n"]}]},{"cell_type":"markdown","source":["## Result\n","\n","\n","*   My mode: 0.81853. \n","*   Mobilenet: 0.98666\n","*   Resnet: 0.98958\n","\n"],"metadata":{"id":"o9bd4H1eERMm"}},{"cell_type":"code","source":[""],"metadata":{"id":"L0zTVmIqxHqe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Augmentation"],"metadata":{"id":"EO8qiIvf8QRM"}},{"cell_type":"code","source":["def get_train_transform_new():\n","    return T.Compose([\n","        T.RandomHorizontalFlip(p=0.5),\n","        T.RandomVerticalFlip(p=0.2),\n","        T.RandomAutocontrast(p=0.2),\n","        T.ColorJitter(brightness=0.2,\n","            contrast=0.2,\n","            saturation=0.2),\n","        T.RandomPerspective(p=0.2),\n","        T.RandomRotation(15),\n","        T.Resize((256, 256)),\n","        T.RandomResizedCrop(224),\n","        T.ToTensor(),\n","        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n","    ])\n","    \n","def get_val_transform():\n","    return T.Compose([\n","        T.Resize((224, 224)),\n","        T.ToTensor(),\n","        T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n","    ])"],"metadata":{"id":"IMFVoRKs8SHC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Example with mobilenet"],"metadata":{"id":"WAUjT9cdHJv6"}},{"cell_type":"code","source":["train_dataset = CatDogDataset(train_imgs, class_to_int, mode = \"train\", transforms = get_train_transform_new())\n","train_data_loader = DataLoader(\n","    dataset = train_dataset,\n","    num_workers = 4,\n","    batch_size = 32,\n","    shuffle = True\n",")\n","from torchvision.models import mobilenet_v2\n","model=mobilenet_v2(pretrained=True)\n","model.classifier._modules['1'] = nn.Sequential(\n","    nn.Linear(1280, 1, bias = True),\n","    nn.Sigmoid()\n",")\n","# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n","# Learning Rate Scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n","#Loss Function\n","criterion = nn.BCELoss()\n","# Logs - Helpful for plotting after training finishes\n","train_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","val_logs = {\"loss\" : [], \"accuracy\" : [], \"time\" : []}\n","# Loading model to device\n","model.to(device)\n","# No of epochs \n","epochs = 5\n","best_val_acc = 0\n","for epoch in range(epochs):\n","    ###Training\n","    loss, acc, _time = train_one_epoch(train_data_loader)\n","    #Print Epoch Details\n","    print(\"\\nTraining\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    ###Validation\n","    loss, acc, _time, best_val_acc = val_one_epoch(val_data_loader, best_val_acc, \"mobilenet_v2_augment\")\n","    #Print Epoch Details\n","    print(\"\\nValidating\")\n","    print(\"Epoch {}\".format(epoch+1))\n","    print(\"Loss : {}\".format(round(loss, 4)))\n","    print(\"Acc : {}\".format(round(acc, 4)))\n","    print(\"Time : {}\".format(round(_time, 4)))\n","    "],"metadata":{"id":"E26dpVLrHV4o"},"execution_count":null,"outputs":[]}]}