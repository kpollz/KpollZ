{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_LeAnhThang.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "z8u_LA7006Hc",
        "d497EFa1IyA_",
        "v1PQsr0bXY0A",
        "1Jc8kMhHdASe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết"
      ],
      "metadata": {
        "id": "qllFktAY3dgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Mạng tích chập CNN sẽ được thực hiện như thế nào?\n",
        "\n",
        "  D. Di chuyển vùng local receptive field theo chiều từ trái sang phải và từ trên xuống dưới và nhân tích chập với kernel để thu được ma trận feature map."
      ],
      "metadata": {
        "id": "Eh331_Rl33xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Thực hiện phép nhân tích chập giữa ma trận đầu vào kích thước width và height lần lượt là (W,H) với bộ lọc kích thước (F,F) và bước nhảy S thì thu được ma trận đầu ra với kích thước width và height (W′,H′) là bao nhiêu? Hãy lựa chọn công thức tổng quát nhất.\n",
        " \n",
        "  C. W′=⌊W−F+2PS⌋+1; H′=⌊H−F+2PS⌋+1 với P là số lượng các véc tơ 0 padding ở bên ngoài đều hai phía."
      ],
      "metadata": {
        "id": "tAi-IROm4Zm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Mạng CNN sẽ học được những gì qua các layers?\n",
        "\n",
        "  C. Tại những layers đầu mạng sẽ học được các đặc trưng chung như các edge dọc, ngang, chéo,.... Các đặc trưng chi tiết và tổng quát giúp nhận diện vật thể được học tại những layers cuối cùng."
      ],
      "metadata": {
        "id": "gsojwlKb4LtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Kiến trúc chung của một mạng CNN là gì?\n",
        "\n",
        "  D. [Conv -> BatchNorm -> Maxpooling -> Activation -> Maxpooling] x n -> Flatten -> [FullyConnected -> Activation] x m -> Softmax"
      ],
      "metadata": {
        "id": "L54xLGJM9Fil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Thông thường đặc điểm kích thước feature map của mạng neural sẽ như thế nào ?\n",
        "\n",
        "  D. Kích thước mạng thường giảm gấp đôi sau một lần downsampling và số lượng các filters tăng dần.\n",
        "  "
      ],
      "metadata": {
        "id": "8C9G_rwW9Tt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành"
      ],
      "metadata": {
        "id": "XZF1LZK-QhT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 6. Thực hiện xây dựng và huấn luyện một mạng CNN ngẫu nhiên trên bộ dữ liệu Dog and Cat. Lưu ý cần thực hiện chuẩn hóa dữ liệu đối với bộ dữ liệu ImageNet trước khi huấn luyện."
      ],
      "metadata": {
        "id": "TJPFQ15OQm_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install kaggle\n",
        "#! pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "#! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "_mGAd6J0AP80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt install unzip\n",
        "#!unzip  dog-vs-cat-classification.zip -d dog-vs-cat-classification"
      ],
      "metadata": {
        "id": "O-mlxjFQLPBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/Deep_Learning_Hand_On/Day 5\"\n",
        "# OS.chdir(path)\n",
        "%cd {path}"
      ],
      "metadata": {
        "id": "xx6J6N_93pjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Other libraries we'll use\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
      ],
      "metadata": {
        "id": "ojSBCYKgJBl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = './dog-vs-cat-classification/train/train'\n",
        "# Get the class names\n",
        "classes = os.listdir(data_path)\n",
        "classes.sort()\n",
        "print(len(classes), 'classes:')\n",
        "print(classes)\n",
        "\n",
        "# Show the first image in each folder\n",
        "fig = plt.figure(figsize=(8, 12))\n",
        "i = 0\n",
        "for sub_dir in os.listdir(data_path):\n",
        "    i+=1\n",
        "    img_file = os.listdir(os.path.join(data_path,sub_dir))[0]\n",
        "    img_path = os.path.join(data_path, sub_dir, img_file)\n",
        "    img = mpimg.imread(img_path)\n",
        "    a=fig.add_subplot(1, len(classes),i)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(img_file)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E67MT_KdRWfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ingest data using training and test loaders\n",
        "def load_dataset(data_path):\n",
        "    # Load all of the images\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load all of the images, transforming them\n",
        "    full_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transformation\n",
        "    )\n",
        "\n",
        "    print(\"full dataset: {}\".format(full_dataset))\n",
        "    \n",
        "    \n",
        "    # Split into training (70% and testing (30%) datasets)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    # define a loader for the training data we can iterate through in 50-image batches\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # define a loader for the testing data we can iterate through in 50-image batches\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "        \n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# Get the iterative dataloaders for test and training data\n",
        "train_loader, test_loader = load_dataset(data_path)\n",
        "print('Data loaders ready')"
      ],
      "metadata": {
        "id": "wEqvatvY63ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a neural net class\n",
        "class Net(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Our images are RGB, so input channels = 3. We'll apply 12 filters in the first convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        # We'll apply max pooling with a kernel size of 2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        # A second convolutional layer takes 12 input channels, and generates 12 outputs\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        # A third convolutional layer takes 12 inputs and generates 24 outputs\n",
        "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
        "        self.drop = nn.Dropout2d(p=0.2)\n",
        "        \n",
        "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
        "        # So our feature tensors are now 32 x 32, and we've generated 24 of them\n",
        "        # We need to flatten these and feed them to a fully-connected layer\n",
        "        # to map them to  the probability for each class\n",
        "        self.fc = nn.Linear(in_features=64 * 64 * 24, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use a relu activation function after layer 1 (convolution 1 and pool)\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "      \n",
        "        # Use a relu activation function after layer 2 (convolution 2 and pool)\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        \n",
        "        # Select some features to drop after the 3rd convolution to prevent overfitting\n",
        "        x = F.relu(self.drop(self.conv3(x)))\n",
        "        \n",
        "        # Only drop the features if this is a training pass\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(-1, 64 * 64 * 24)\n",
        "        # Feed to fully-connected layer to predict class\n",
        "        x = self.fc(x)\n",
        "        # Return log_softmax tensor \n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "print(\"CNN model class defined!\")"
      ],
      "metadata": {
        "id": "tNhaJb9N7vrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    print(\"Epoch:\", epoch)\n",
        "    # Process the images in batches\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "      # Use the CPU or GPU as appropriate\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      \n",
        "      # Reset the optimizer\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Push the data forward through the model layers\n",
        "      output = model(data)\n",
        "      \n",
        "      # Get the loss\n",
        "      loss = loss_criteria(output, target)\n",
        "      \n",
        "      # Keep a running total\n",
        "      train_loss += loss.item()\n",
        "      \n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Print metrics for every 10 batches so we see some progress\n",
        "      if batch_idx % 10 == 0:\n",
        "          print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
        "              batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "    # return average loss for the epoch\n",
        "    avg_loss = train_loss / (batch_idx+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "            \n",
        "            \n",
        "def test(model, device, test_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for data, target in test_loader:\n",
        "            batch_count += 1\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            # Get the predicted classes for this batch\n",
        "            output = model(data)\n",
        "            \n",
        "            # Calculate the loss for this batch\n",
        "            test_loss += loss_criteria(output, target).item()\n",
        "            \n",
        "            # Calculate the accuracy for this batch\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "\n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss\n",
        "    \n",
        "    \n",
        "# Now use the train and test functions to train and test the model    \n",
        "\n",
        "device = \"cpu\"\n",
        "if (torch.cuda.is_available()):\n",
        "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
        "    device = \"cuda\"\n",
        "print('Training on', device)\n",
        "\n",
        "# Create an instance of the model class and allocate it to the device\n",
        "model = Net(num_classes=len(classes)).to(device)\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Specify the loss criteria\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Track metrics in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 5 epochs (in a real scenario, you'd likely use many more)\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
        "        test_loss = test(model, device, test_loader)\n",
        "        epoch_nums.append(epoch)\n",
        "        training_loss.append(train_loss)\n",
        "        validation_loss.append(test_loss)"
      ],
      "metadata": {
        "id": "2kxCsYrv8DAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 7. Grid Search kiến trúc CNN dựa trên việc tổng quát hóa một thiết kế câu 6."
      ],
      "metadata": {
        "id": "z8u_LA7006Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "q0nI6kIB09t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H114Uwym30w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 8. Huấn luyện lại mô hình bằng kiến trúc ResNet và MobileNet. Đánh giá chi phí tính toán và submit kết quả độ chính xác trên các ảnh thuộc folder test."
      ],
      "metadata": {
        "id": "d497EFa1IyA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yfhkRKHXL5ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 9. Thử nghiệm các phương pháp Augmentation như Flip, Rotation, Random Crop, Bright Contrast để cải thiện kết quả mô hình."
      ],
      "metadata": {
        "id": "v1PQsr0bXY0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ingest data using training and test loaders\n",
        "def load_dataset1(data_path):\n",
        "    # Load all of the images\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load all of the images, transforming them\n",
        "    full_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transformation\n",
        "    )\n",
        "\n",
        "    print(\"full dataset: {}\".format(full_dataset))\n",
        "    \n",
        "    \n",
        "    # Split into training (70% and testing (30%) datasets)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    # define a loader for the training data we can iterate through in 50-image batches\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # define a loader for the testing data we can iterate through in 50-image batches\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "        \n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# Get the iterative dataloaders for test and training data\n",
        "train_loader1, test_loader1 = load_dataset1(data_path)\n",
        "print('Data loaders ready')"
      ],
      "metadata": {
        "id": "sAelIte5Xjf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ingest data using training and test loaders\n",
        "def load_dataset2(data_path):\n",
        "    # Load all of the images\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomRotation(degrees=(0, 15)),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load all of the images, transforming them\n",
        "    full_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transformation\n",
        "    )\n",
        "\n",
        "    print(\"full dataset: {}\".format(full_dataset))\n",
        "    \n",
        "    \n",
        "    # Split into training (70% and testing (30%) datasets)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    # define a loader for the training data we can iterate through in 50-image batches\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # define a loader for the testing data we can iterate through in 50-image batches\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "        \n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# Get the iterative dataloaders for test and training data\n",
        "train_loader2, test_loader2 = load_dataset2(data_path)\n",
        "print('Data loaders ready')"
      ],
      "metadata": {
        "id": "ryPbiH2saC53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ingest data using training and test loaders\n",
        "def load_dataset3(data_path):\n",
        "    # Load all of the images\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomCrop(size=(128, 128)),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load all of the images, transforming them\n",
        "    full_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transformation\n",
        "    )\n",
        "\n",
        "    print(\"full dataset: {}\".format(full_dataset))\n",
        "    \n",
        "    \n",
        "    # Split into training (70% and testing (30%) datasets)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    # define a loader for the training data we can iterate through in 50-image batches\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # define a loader for the testing data we can iterate through in 50-image batches\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "        \n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# Get the iterative dataloaders for test and training data\n",
        "train_loader3, test_loader3 = load_dataset3(data_path)\n",
        "print('Data loaders ready')"
      ],
      "metadata": {
        "id": "nkzUbUX0assY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ingest data using training and test loaders\n",
        "def load_dataset4(data_path):\n",
        "    # Load all of the images\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ColorJitter(brightness=.5, hue=.3),\n",
        "        # transform to tensors\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the pixel values (in R, G, and B channels)\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load all of the images, transforming them\n",
        "    full_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transformation\n",
        "    )\n",
        "\n",
        "    print(\"full dataset: {}\".format(full_dataset))\n",
        "    \n",
        "    \n",
        "    # Split into training (70% and testing (30%) datasets)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    # define a loader for the training data we can iterate through in 50-image batches\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # define a loader for the testing data we can iterate through in 50-image batches\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=100,\n",
        "        num_workers=2,\n",
        "        shuffle=False\n",
        "    )\n",
        "        \n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# Get the iterative dataloaders for test and training data\n",
        "train_loader4, test_loader4 = load_dataset4(data_path)\n",
        "print('Data loaders ready')"
      ],
      "metadata": {
        "id": "opYJpsZba6CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a neural net class\n",
        "class Net(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Our images are RGB, so input channels = 3. We'll apply 12 filters in the first convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        # We'll apply max pooling with a kernel size of 2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        # A second convolutional layer takes 12 input channels, and generates 12 outputs\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        # A third convolutional layer takes 12 inputs and generates 24 outputs\n",
        "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
        "        self.drop = nn.Dropout2d(p=0.2)\n",
        "        \n",
        "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
        "        # So our feature tensors are now 32 x 32, and we've generated 24 of them\n",
        "        # We need to flatten these and feed them to a fully-connected layer\n",
        "        # to map them to  the probability for each class\n",
        "        self.fc = nn.Linear(in_features=64 * 64 * 24, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use a relu activation function after layer 1 (convolution 1 and pool)\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "      \n",
        "        # Use a relu activation function after layer 2 (convolution 2 and pool)\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        \n",
        "        # Select some features to drop after the 3rd convolution to prevent overfitting\n",
        "        x = F.relu(self.drop(self.conv3(x)))\n",
        "        \n",
        "        # Only drop the features if this is a training pass\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(-1, 64 * 64 * 24)\n",
        "        # Feed to fully-connected layer to predict class\n",
        "        x = self.fc(x)\n",
        "        # Return log_softmax tensor \n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "print(\"CNN model class defined!\")"
      ],
      "metadata": {
        "id": "qktAtU-nYcAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    print(\"Epoch:\", epoch)\n",
        "    # Process the images in batches\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "      # Use the CPU or GPU as appropriate\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      \n",
        "      # Reset the optimizer\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Push the data forward through the model layers\n",
        "      output = model(data)\n",
        "      \n",
        "      # Get the loss\n",
        "      loss = loss_criteria(output, target)\n",
        "      \n",
        "      # Keep a running total\n",
        "      train_loss += loss.item()\n",
        "      \n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Print metrics for every 10 batches so we see some progress\n",
        "      if batch_idx % 10 == 0:\n",
        "          print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
        "              batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "    # return average loss for the epoch\n",
        "    avg_loss = train_loss / (batch_idx+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "            \n",
        "            \n",
        "def test(model, device, test_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for data, target in test_loader:\n",
        "            batch_count += 1\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            # Get the predicted classes for this batch\n",
        "            output = model(data)\n",
        "            \n",
        "            # Calculate the loss for this batch\n",
        "            test_loss += loss_criteria(output, target).item()\n",
        "            \n",
        "            # Calculate the accuracy for this batch\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "\n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss\n",
        "    \n"
      ],
      "metadata": {
        "id": "OtU6jBCRYcfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Flip"
      ],
      "metadata": {
        "id": "2TKIBJmKcnXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "if (torch.cuda.is_available()):\n",
        "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
        "    device = \"cuda\"\n",
        "print('Training on', device)\n",
        "\n",
        "# Create an instance of the model class and allocate it to the device\n",
        "model = Net(num_classes=len(classes)).to(device)\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Specify the loss criteria\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Track metrics in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 5 epochs (in a real scenario, you'd likely use many more)\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, device, train_loader1, optimizer, epoch)\n",
        "        test_loss = test(model, device, test_loader1)\n",
        "        epoch_nums.append(epoch)\n",
        "        training_loss.append(train_loss)\n",
        "        validation_loss.append(test_loss)"
      ],
      "metadata": {
        "id": "afdC58f7bWMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Rotation"
      ],
      "metadata": {
        "id": "ooyUMvI9crif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "if (torch.cuda.is_available()):\n",
        "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
        "    device = \"cuda\"\n",
        "print('Training on', device)\n",
        "\n",
        "# Create an instance of the model class and allocate it to the device\n",
        "model = Net(num_classes=len(classes)).to(device)\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Specify the loss criteria\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Track metrics in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 5 epochs (in a real scenario, you'd likely use many more)\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, device, train_loader2, optimizer, epoch)\n",
        "        test_loss = test(model, device, test_loader2)\n",
        "        epoch_nums.append(epoch)\n",
        "        training_loss.append(train_loss)\n",
        "        validation_loss.append(test_loss)"
      ],
      "metadata": {
        "id": "rL2gmOhgcRGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Bright Contrast "
      ],
      "metadata": {
        "id": "xcwYdBv6c2WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "if (torch.cuda.is_available()):\n",
        "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
        "    device = \"cuda\"\n",
        "print('Training on', device)\n",
        "\n",
        "# Create an instance of the model class and allocate it to the device\n",
        "model = Net(num_classes=len(classes)).to(device)\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Specify the loss criteria\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "# Track metrics in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "# Train over 5 epochs (in a real scenario, you'd likely use many more)\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, device, train_loader4, optimizer, epoch)\n",
        "        test_loss = test(model, device, test_loader4)\n",
        "        epoch_nums.append(epoch)\n",
        "        training_loss.append(train_loss)\n",
        "        validation_loss.append(test_loss)"
      ],
      "metadata": {
        "id": "t2Z9p71gcVrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 10. Lập bảng kết quả các thử nghiệm đã sử dụng."
      ],
      "metadata": {
        "id": "1Jc8kMhHdASe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(3)\n",
        "acc_value = [5869/7500, 5591/7500, 5588/7500]\n",
        "plt.bar(x, acc_value)\n",
        "plt.xticks(x, ('Flip', 'Rotation', 'Bright Contrast'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mdguzM4Cz1tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Augmentation flip có kết quả tốt nhất"
      ],
      "metadata": {
        "id": "Mp8ydqUU0qXk"
      }
    }
  ]
}